BayesianTrees[1:3, ]
BayesianTrees[, "tree"]
RevBayesOutput <- read.table("/Users/eargtl/Documents/Publications/in prep/Strat congruence - April/Aguirre-Fernandez_etal_2009a.nex.trees", header = TRUE)#
#
BayesianTrees <- ape::read.tree(text = RevBayesOutput[, "tree"])
RevBayesOutput <- read.table("/Users/eargtl/Documents/Publications/in prep/Strat congruence - April/Aguirre-Fernandez_etal_2009a.nex.trees", header = TRUE, stringsAsFactors=FALSE)#
#
BayesianTrees <- ape::read.tree(text = RevBayesOutput[, "tree"])#
)
RevBayesOutput <- read.table("/Users/eargtl/Documents/Publications/in prep/Strat congruence - April/Aguirre-Fernandez_etal_2009a.nex.trees", header = TRUE, stringsAsFactors=FALSE)#
#
BayesianTrees <- ape::read.tree(text = RevBayesOutput[, "tree"])
BayesianTrees
BayesianTrees[[1]]
names(BayesianTrees[[1]])
library(metatree)
MRPDirectory <- "/Users/eargtl/Documents/Homepage/www.graemetlloyd.com/mrp"#
  XMLDirectory <- "/Users/eargtl/Documents/Homepage/www.graemetlloyd.com/xml"#
  TargetClade <- "Ichthyopterygia"#
  InclusiveDataList <- sort(c(GetFilesForClade("matricht.html"), "Bickelmann_etal_2009a", "Caldwell_1996a", "Chen_etal_2014ba", "Chen_etal_2014bb", "deBraga_et_Rieppel_1997a", "Gauthier_etal_1988b", "Laurin_et_Reisz_1995a", "Muller_2004a", "Reisz_etal_2011a", "Rieppel_et_Reisz_1999a", "Rieppel_et_deBraga_1996a", "Young_2003a"))#
  ExclusiveDataList <- c("Averianov_inpressa", "Bravo_et_Gaete_2015a", "Brocklehurst_etal_2013a", "Brocklehurst_etal_2015aa", "Brocklehurst_etal_2015ab", "Brocklehurst_etal_2015ac", "Brocklehurst_etal_2015ad", "Brocklehurst_etal_2015ae", "Brocklehurst_etal_2015af", "Bronzati_etal_2012a", "Bronzati_etal_2015ab", "Brusatte_etal_2009ba", "Campbell_etal_2016ab", "Carr_et_Williamson_2004a", "Carr_etal_2017ab", "Frederickson_et_Tumarkin-Deratzian_2014aa", "Frederickson_et_Tumarkin-Deratzian_2014ab", "Frederickson_et_Tumarkin-Deratzian_2014ac", "Frederickson_et_Tumarkin-Deratzian_2014ad", "Garcia_etal_2006a", "Gatesy_etal_2004ab", "Grellet-Tinner_2006a", "Grellet-Tinner_et_Chiappe_2004a", "Grellet-Tinner_et_Makovicky_2006a", "Knoll_2008a", "Kurochkin_1996a", "Lopez-Martinez_et_Vicens_2012a", "Lu_etal_2014aa", "Norden_etal_inpressa", "Pisani_etal_2002a", "Ruiz-Omenaca_etal_1997a", "Ruta_etal_2003ba", "Ruta_etal_2003bb", "Ruta_etal_2007a", "Selles_et_Galobart_2016a", "Sereno_1993a", "Sidor_2001a", "Skutschas_etal_in
pressa", "Tanaka_etal_2011a", "Toljagic_et_Butler_2013a", "Tsuihiji_etal_2011aa", "Varricchio_et_Jackson_2004a", "Vila_etal_2017a", "Wilson_2005aa", "Wilson_2005ab", "Zelenitsky_et_Therrien_2008a")#
  HigherTaxaToCollapse = c()#
  MissingSpecies = "exclude"#
  Interval = NULL#
  VeilLine = TRUE#
  SpeciesToExclude = c()#
  IncludeSpecimenLevelOTUs = TRUE#
  BackboneConstraint = NULL#
  MonophylyConstraint = NULL#
  InclusiveDataList = c()#
  ExclusiveDataList = c()#
  # New Options (requires code to actually use them)#
  ##
  # HigherTaxaToCollapse Vector can be empty.#
  # VeilLine TRUE/FALSE (will be in output)#
  # SpeciesToExclude Vector of any species to be excluded from the final metatree. E.g., Eshanosaurus, Ricardoestesia.#
  # BackboneConstraint Newick string of backbone constraint (allows taxa not in topology). NULL as default.#
  # MonophylyConstraint Newick string of monophyly constraint (excludes taxa not in topology). NULL as default.#
  # CHECK PARENT IS A DATA SET AND NOT A REFERENCE, E.G., IF ENTER A REFERENCE AS PARENT THEN PARENT TURNS OUT TO HAVE TWO DATA SETS#
  # CHECK FOR SPECIES THAT BELONG TO A GENUS DIFFERENT TO THE ONE IN THEIR NAME!#
  # NEED TO CATCH ISSUE WHERE GENUS NUMBER IS USED FOR A SPECIES (HARD TO CHECK SO FAR DUE TO INDETERMINATES CONTINGENCY)#
  # NEED SOME TEST THAT HELPS CHECK ROOT IS SENSIBLE#
  # NEED SOME TEST THAT HELPS DETERMINE IF MULTIPLE OCCURRENCES OF SAME TAXON AFTER RECONCILIATION IS CORRECT OR AN ERROR#
  # ADD MORE COMPLEX WEIGHTS BY USING ADDITIONAL CHARACTER STATES! (EACH DATASET TOTAL WEIGHT DETERMINED BY YEAR AND DEPENDENCE THEN SUBDIVIDED ACROSS CHARACTER?) - BUT THIS SEEMS TO SLOW THINGS DRAMATICALLY MAYBE DO BY DUPLICATING CHARACTERS INSTEAD#
  # MAKE STR OPTIONAL (SAVES A LITTLE TIME)#
  # CHECK THERE ARE MULTIPLE TAXA PRE-RECONCILIATION#
  # CHECK INDETS DO NOT GIVE MULTIPLE MATCHES#
  # HOW TO DELETE DATA SETS THAT STILL CONTRIBUTE TO DEPENDENCE?#
  # Subfunction that gives just MRPs where matrix is still intact (has rows and columns):#
  ActiveMRP <- function(MRPList) unname(which(unlist(lapply(MRPList, function(x) prod(dim(x$Matrix)))) > 0))#
#
  # Check MRPDirectory is formatted correctly adn stop and warn user if not:#
  if(!all(is.character(MRPDirectory)) || length(MRPDirectory) != 1) stop("MRPDirectory must be a single character string indicating the path to the folder containing the MRP files.")#
  # Check XMLDirectory is formatted correctly adn stop and warn user if not:#
  if(!all(is.character(XMLDirectory)) || length(XMLDirectory) != 1) stop("XMLDirectory must be a single character string indicating the path to the folder containing the XML files.")#
  # Check TargetClade is formatted correctly adn stop and warn user if not:#
  if(!all(is.character(TargetClade)) || length(TargetClade) != 1) stop("TargetClade must be a single character string indicating the desired clade the metatree will represent.")#
  # Check MissingSpecies respresents a valid option:#
  if(length(setdiff(MissingSpecies, c("all", "exclude", "genus"))) > 0) stop("MissingSpecies must be one of \"all\", \"exclude\", or \"genus\".")#
  # Check VeilLine is a logical and stop and warn user if not:#
  if(!is.logical(VeilLine)) stop("VeilLine must be a logical (TRUE or FALSE).")#
  # Check IncludeSpecimenLevelOTUs is a logical and stop and warn user if not:#
  if(!is.logical(IncludeSpecimenLevelOTUs)) stop("IncludeSpecimenLevelOTUs must be a logical (TRUE or FALSE).")#
  # If not a NULL read backbone constraint (checks it is a valid Newick format):#
  if(!is.null(BackboneConstraint)) BackboneConstraintTree <- ape::read.tree(text = BackboneConstraint)#
  # If not a NULL read monophyly constraint (checks it is a valid Newick format):#
  if(!is.null(MonophylyConstraint)) MonophylyConstraintTree <- ape::read.tree(text = MonophylyConstraint)#
  # List of types of resolution that require finding a senior synonym:#
  synonyms <- c("corrected to", "misspelling of", "objective synonym of", "obsolete variant of", "recombined as", "replaced by", "subjective synonym of")#
  # List of types of resolution that require changing reconciliation to DELETE:#
  deletes <- c("nomen dubium", "nomen vanum", "nomen nudum", "nomen oblitum", "invalid subgroup of")#
  # Print current processing status:#
  cat("Reading MRP data...")#
  # Set working directory as MRP directory:#
  setwd(MRPDirectory)#
  # List MRP files (or just use inclusivedatalist if set):#
  MRPFileList <- strsplit(ifelse(length(InclusiveDataList) > 0, paste(setdiff(sort(unique(InclusiveDataList)), sort(unique(ExclusiveDataList))), "mrp.nex", sep = "", collapse = "%%"), paste(setdiff(gsub("mrp\\.nex", "", list.files()), sort(unique(ExclusiveDataList))), "mrp.nex", sep = "", collapse = "%%")), "%%")[[1]]#
  # Read in all MRP files and store in a list (include duplicate headers to store parent sibling info later):#
  MRPList <- lapply(lapply(as.list(MRPFileList), Claddis::ReadMorphNexus), function(x) {y <- list(x$Matrix_1$Matrix, x$Matrix_1$Weights, "", "", ""); names(y) <- c("Matrix", "Weights", "FileName", "Parent", "Sibling"); y})#
  # Set names of MRP files:#
  names(MRPList) <- gsub("mrp.nex", "", MRPFileList)#
  # Print current processing status:#
  cat("Done\nReading XML data...")#
  # Set working directory as XML (i.e., metadata) directory:#
  setwd(XMLDirectory)#
  # List MRP files (or just use inslusivedatalist if set):#
  XMLFileList <- strsplit(ifelse(length(InclusiveDataList) > 0, paste(setdiff(sort(unique(InclusiveDataList)), sort(unique(ExclusiveDataList))), ".xml", sep = "", collapse = "%%"), paste(setdiff(gsub("\\.xml", "", list.files()), sort(unique(ExclusiveDataList))), ".xml", sep = "", collapse = "%%")), "%%")[[1]]#
  XMLFileList <- setdiff(XMLFileList, "Hartman_etal_2019a.xml")#
  # Check there are no MRPs not listed as XMLs and vice versa (should return empty vector):#
  MRPXMLunion <- c(setdiff(gsub("\\.xml", "", XMLFileList), gsub("mrp\\.nex", "", MRPFileList)), setdiff(gsub("mrp\\.nex", "", MRPFileList), gsub("\\.xml", "", XMLFileList)))#
  # Stop if MRP datasets not listed as XMLs and vice versa:#
  if(length(MRPXMLunion) > 0) stop(paste("Datasets do not match (MRP and XML)!:", MRPXMLunion, collapse = " "))#
  # Read in all XML files and store in a list:#
  XMLList <- lapply(as.list(XMLFileList), function(x) ReadMetatreeXML(x))#
  # Add names to XML list:#
  names(XMLList) <- gsub(".xml", "", XMLFileList)#
  # Collapse to just pertinent information:#
  XMLList <- lapply(XMLList, function(x) {y <- list(); y[["TaxonMatrix"]] <- x$SourceTree$Taxa$TagContents; y[["FileName"]] <- unname(unlist(x$SourceTree$Filename)); y[["Parent"]] <- unname(unlist(x$SourceTree$Parent)); y[["Sibling"]] <- unname(unlist(x$SourceTree$Sibling)); y})#
  # Find any files that contain duplicated taxon names:#
  FilesWithDuplicatedTaxonNames <- names(XMLList)[which(unlist(lapply(XMLList, function(x) any(duplicated(x$TaxonMatrix[, "ListValue"])))))]#
  # If duplicate names were found stop and warn user:#
  if(length(FilesWithDuplicatedTaxonNames) > 0) stop(paste("The following files contain duplicate taxon names: ", paste(FilesWithDuplicatedTaxonNames, collapse = ", "), ". Ensure all taxon names are unique and try again.", sep = ""))#
  # Find any taxon names that do not match between MRP and XML:#
  TaxonMismatches <- mapply(function(x, y) {MRPNames <- rownames(x$Matrix); XMLNames <- y$TaxonMatrix[, "ListValue"]; c(setdiff(MRPNames, XMLNames), setdiff(XMLNames, MRPNames))}, x = MRPList[names(MRPList)], y = XMLList[names(MRPList)])#
  # Find any files with mismatching taxon names between MRP and XML:#
  FilesWithTaxonMismatches <- names(TaxonMismatches)[which(unlist(lapply(TaxonMismatches, function(x) length(x))) > 0)]#
  # If such files are found then stop and warn user:#
  if(length(FilesWithTaxonMismatches) > 0) stop(paste("The following files contain mismatching taxon names between the MRP and XML versions: ", paste(FilesWithTaxonMismatches, collapse = ", "), ". Ensure all taxon names match and try again.", sep = ""))#
  # Compile any name issues:#
  NameIssues <- lapply(XMLList, function(x) {TaxonMatrix <- x$TaxonMatrix; SpacesFound <- c(grep(" ", TaxonMatrix[, "recon_name"]), grep(" ", TaxonMatrix[, "recon_no"]), grep(" ", TaxonMatrix[, "ListValue"])); EmptyValuesFound <- c(which(TaxonMatrix[, "recon_name"] == ""), which(TaxonMatrix[, "recon_no"] == ""), which(TaxonMatrix[, "ListValue"] == "")); RogueNumberCharacters <- setdiff(unique(unlist(strsplit(TaxonMatrix[, "recon_no"], ""))), c(0:9, ";", "-")); RogueNameCharacters <- setdiff(unique(c(unlist(strsplit(TaxonMatrix[, "recon_name"], "")), unlist(strsplit(TaxonMatrix[, "ListValue"], "")))), c(LETTERS, letters, 0:9, "_", ",")); y <- list(SpacesFound, EmptyValuesFound, RogueNumberCharacters, RogueNameCharacters); names(y) <- c("SpacesFound", "EmptyValuesFound", "RogueNumberCharacters", "RogueNameCharacters"); y})#
  # Find any files with spaces in taxon names:#
  FilesWithSpaces <- names(NameIssues)[unlist(lapply(NameIssues, function(x) length(x$SpacesFound))) > 0]#
  # Find any values with empty values for taxon names:#
  FilesWithEmptyValues <- names(NameIssues)[unlist(lapply(NameIssues, function(x) length(x$EmptyValuesFound))) > 0]#
  # Files with rogue values in the recon number field:#
  FilesWithRogueTaxonNumbers <- names(NameIssues)[unlist(lapply(NameIssues, function(x) length(x$RogueNumberCharacters))) > 0]#
  # Files with rogue values in the name fields:#
  FilesWithRogueTaxonNames <- names(NameIssues)[unlist(lapply(NameIssues, function(x) length(x$RogueNameCharacters))) > 0]#
  # If issues with spaces in names stop and warn user:#
  if(length(FilesWithSpaces) > 0) stop(paste("The following files contain spaces in the taxonomic reconciliation (names or numbers): ", paste(FilesWithSpaces, collapse = ", "), ". Remove spaces and try again.", sep = ""))#
  # If issues with empty names stop and warn user:#
  if(length(FilesWithEmptyValues) > 0) stop(paste("The following files contain empty values in the taxonomic reconciliation (names or numbers): ", paste(FilesWithEmptyValues, collapse = ", "), ". Ensure all values are filled and try again.", sep = ""))#
  # If issues with rogue characters in number field stop and warn user:#
  if(length(FilesWithRogueTaxonNumbers) > 0) stop(paste("The following files contain rogue values in the taxonomic reconciliation (numbers): ", paste(FilesWithRogueTaxonNumbers, collapse = ", "), ". Ensure all taxon numbers only include semicolon(s) (the separating character) or dashes (for negative values) and try again.", sep = ""))#
  # If issues with rogue characters in name field stop and warn user:#
  if(length(FilesWithRogueTaxonNames) > 0) stop(paste("The following files contain rogue values in the taxonomic reconciliation (names): ", paste(FilesWithRogueTaxonNames, collapse = ", "), ". Ensure all taxon names are formed from alphanumerics, commas (the separating character) or underscores and try again.", sep = ""))#
  # Reconcile OTU names with XML version:#
  MRPList <- mapply(function(x, y) {rownames(x$Matrix)[unlist(lapply(as.list(rownames(x$Matrix)), function(z) which(y$TaxonMatrix[, "ListValue"] == z)))] <- paste(y$TaxonMatrix[, "recon_no"], y$TaxonMatrix[, "recon_name"], sep = "%%%%"); x$FileName <- y$FileName; if(!is.null(y$Parent)) x$Parent <- y$Parent; if(!is.null(y$Sibling)) x$Sibling <- y$Sibling; x}, x = MRPList[names(MRPList)], y = XMLList[names(MRPList)], SIMPLIFY = FALSE)#
#
  # Print current processing status:#
  cat("Done\nChecking for unsampled parents and siblings...")#
  # Extract parent and sibling names:#
  ParentAndSiblingNames <- sort(unlist(lapply(as.list(unique(unname(unlist(lapply(MRPList, '[', c("Parent", "Sibling")))))), function(x) x[nchar(x) > 0])))#
  # Warn user about any unsampled parents and/or siblings:#
  if(length(setdiff(ParentAndSiblingNames, names(MRPList))) > 0) print(paste("The following parents and siblings are not in the sample (check they are correct or add them into the sample): ", paste(setdiff(ParentAndSiblingNames, names(MRPList)), collapse = ", "), sep = ""))#
  # Print current processing status:#
  cat("Done\nFinding initial multiple-taxon reconciliations...")#
  # Subfunction to make multi-taxon reconciliations unique OTUs:#
  SeparateMultiTaxonReconciliations <- function(ListBlock) {#
    # Find comma rows (multiple taxa in initial reconciliation):#
    commarows <- grep(",", rownames(ListBlock$Matrix))#
    # If there is at least one multiple-taxon reconciliation:#
    if(length(commarows) > 0) {#
      # For each multiple-taxon reconciliation in reverse order (to avoid later rows not matching):#
      for(j in rev(commarows)) {#
        # Get multiple names of reconciliation:#
        multiplenames <- strsplit(rownames(ListBlock$Matrix)[j], "%%%%")[[1]]#
        # Get multiple-taxon numbers:#
        multitaxonnumbers <- strsplit(multiplenames[1], ";")[[1]]#
        # Get multiple-taxon names:#
        multitaxonnames <- strsplit(multiplenames[2], ",")[[1]]#
        # Check data integrity with respect to multiple-taxon values:#
        if(length(multitaxonnumbers) != length(multitaxonnames)) stop(paste("Problem with multiple-taxon reconciliation(s) in ", ListBlock$FileName, " (check commas and semi-colons are correct; i.e., of same length).", sep = ""))#
        # Add new rows at base of matrix:#
        ListBlock$Matrix <- rbind(ListBlock$Matrix, matrix(rep(ListBlock$Matrix[j, ], length(multitaxonnumbers)), nrow = length(multitaxonnumbers), byrow = TRUE, dimnames = list(paste(multitaxonnumbers, multitaxonnames, sep = "%%%%"), c())))#
        # Remove now redundant row from matrix:#
        ListBlock$Matrix <- ListBlock$Matrix[-j, , drop = FALSE]#
      }#
    }#
    # Return updated list block:#
    return(ListBlock)#
  }#
  # Separate out multi-taxon reconcilations:#
  MRPList <- lapply(MRPList, SeparateMultiTaxonReconciliations)#
  # If excluding specimen-level OTUs:#
  if(!IncludeSpecimenLevelOTUs) {#
    # Print current processing status:#
    cat("Done\nRemoving specimen-level OTUs...")#
    # Convert specimen-level OTUs to taxa to DELETE:#
    MRPList <- lapply(MRPList, function(x) {RowNamesToDelete <- which(unlist(lapply(strsplit(rownames(x$Matrix), split = ""), function(y) sum(y == "_") > 2))); if(length(RowNamesToDelete) > 0) rownames(x$Matrix)[RowNamesToDelete] <- "0%%%%DELETE"; x})#
  }#
  # Print current processing status:#
  cat("Done\nRemoving taxa with initial reconciliations of \"DELETE\"...")#
  # Remove any taxa reconciled as DELETE:#
  MRPList <- lapply(MRPList, function(x) {DeleteRows <- which(unlist(lapply(strsplit(rownames(x$Matrix), split = "%%%%"), function(y) y[2])) == "DELETE"); if(length(DeleteRows) > 0) x$Matrix <- x$Matrix[-DeleteRows, , drop = FALSE]; x})#
  # Prune matrices following deletion:#
  MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {y <- PisaniMRPPrune(Claddis::MakeMorphMatrix(x$Matrix, weights = x$Weights, ignore.duplicate.taxa = TRUE)); x$Matrix <- y$Matrix_1$Matrix; x$Weights <- y$Matrix_1$Weights; x})#
#
  # Print current processing status:#
  cat("Done\nSearching for and collapsing pre-reconciliation duplicated taxa...")#
  # Collapse any duplicate taxon names:#
  MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {y <- Claddis::MakeMorphMatrix(x$Matrix, weights = x$Weights, ignore.duplicate.taxa = TRUE); if(any(duplicated(rownames(y$Matrix_1$Matrix)))) {DuplicateNames <- setdiff(unlist(lapply(strsplit(rownames(y$Matrix_1$Matrix)[duplicated(rownames(y$Matrix_1$Matrix))], split = "%%%%"), '[', 2)), "DELETE"); if(length(DuplicateNames) > 0) cat(paste("\nDuplicate resolved OTU name(s) found in ", x$FileName, ": ", paste(DuplicateNames, collapse = ", "), ". Check this is correct.", sep = "")); y <- CollapseDuplicateTaxonMRP(y)}; x$Matrix <- y$Matrix_1$Matrix; x$Weights <- y$Weights; x})#
  # Print current processing status:#
  cat("Done\nBuilding initial taxonomy matrix...")#
  # Create taxonomy matrix to store all taxon resolution data:#
  TaxonomyMatrix <- do.call(rbind, strsplit(unique(unname(unlist(lapply(MRPList[ActiveMRP(MRPList)], function(x) rownames(x$Matrix))))), split ="%%%%"))#
  # Add column names:#
  colnames(TaxonomyMatrix) <- c("TaxonNo", "TaxonName")#
  # Print current processing status:#
  cat("Done\nChecking for missing taxon numbers...")#
  # If any "-1" taxa found stop and tell user:#
  if(any(TaxonomyMatrix[, "TaxonNo"] == "-1")) stop(paste("The following taxa have the reconciliation number \"-1\": ", paste(TaxonomyMatrix[TaxonomyMatrix[, "TaxonNo"] == "-1", "TaxonName"], collapse = ", "), sep = ""))#
  # Print current processing status:#
  cat("Done\nChecking for combined taxon numbers (&)...")#
  # If any "&" taxa found stop and tell user:#
  if(length(grep("&", TaxonomyMatrix[, "TaxonNo"]))) stop(paste("The following taxa have multiple reconciliation numbers: ", paste(TaxonomyMatrix[grep("&", TaxonomyMatrix[, "TaxonNo"]), "TaxonName"], collapse = ", "), sep = ""))
ReadMetatreeXML("~/Documents/Homepage/www.graemetlloyd.com/xml/Cau_etal_inpressa.xml")
x <- ReadMetatreeXML("~/Documents/Homepage/www.graemetlloyd.com/xml/Cau_etal_inpressa.xml")
names(x)
names(x$SourceTree)
names(x$SourceTree$Taxa)
names(x$SourceTree$Taxa$TagContents)
x$SourceTree$Taxa$TagSupplement
x$SourceTree$Taxa$TagContents
x$SourceTree$Taxa$TagContents[, "ListValue"]
CauXMLNames <- x$SourceTree$Taxa$TagContents[, "ListValue"]
rownames(ReadMorphNexus("~/Documents/Homepage/www.graemetlloyd.com/mrp/Cau_etal_inpressamrp.nex")$Matrix_1$Matrix)
setdiff(CauXMLNames, rownames(ReadMorphNexus("~/Documents/Homepage/www.graemetlloyd.com/mrp/Cau_etal_inpressamrp.nex")$Matrix_1$Matrix))
setdiff(rownames(ReadMorphNexus("~/Documents/Homepage/www.graemetlloyd.com/mrp/Cau_etal_inpressamrp.nex")$Matrix_1$Matrix), CauXMLNames)
ReadMorphNexus("~/Documents/Homepage/www.graemetlloyd.com/nexus/Brocklehurst_etal_2013a.nex")
ReadMorphNexus("~/Documents/Homepage/www.graemetlloyd.com/mrp/Brocklehurst_etal_2013amrp.nex")
rownames(ReadMorphNexus("~/Documents/Homepage/www.graemetlloyd.com/mrp/Brocklehurst_etal_2013amrp.nex")$Matrix_1$Matrix)
x <- rownames(ReadMorphNexus("~/Documents/Homepage/www.graemetlloyd.com/mrp/Brocklehurst_etal_2013amrp.nex")$Matrix_1$Matrix)
x[duplicated(X)]
x[duplicated(x)]
ReadMetatreeXML("~/Documents/Homepage/www.graemetlloyd.com/xml/Brocklehurst_etal_2013a.xml")
x <- ReadMetatreeXML("~/Documents/Homepage/www.graemetlloyd.com/xml/Brocklehurst_etal_2013a.xml")
x$SourceTree$Taxa
x$SourceTree$Taxa$TagContents
x$SourceTree$Taxa$TagContents[, "ListValue"]
x <- x$SourceTree$Taxa$TagContents[, "ListValue"]
x[duplicated(x)]
MRPDirectory <- "/Users/eargtl/Documents/Homepage/www.graemetlloyd.com/mrp"#
  XMLDirectory <- "/Users/eargtl/Documents/Homepage/www.graemetlloyd.com/xml"#
  TargetClade <- "Ichthyopterygia"#
  InclusiveDataList <- sort(c(GetFilesForClade("matricht.html"), "Bickelmann_etal_2009a", "Caldwell_1996a", "Chen_etal_2014ba", "Chen_etal_2014bb", "deBraga_et_Rieppel_1997a", "Gauthier_etal_1988b", "Laurin_et_Reisz_1995a", "Muller_2004a", "Reisz_etal_2011a", "Rieppel_et_Reisz_1999a", "Rieppel_et_deBraga_1996a", "Young_2003a"))#
  ExclusiveDataList <- c("Averianov_inpressa", "Bravo_et_Gaete_2015a", "Brocklehurst_etal_2013a", "Brocklehurst_etal_2015aa", "Brocklehurst_etal_2015ab", "Brocklehurst_etal_2015ac", "Brocklehurst_etal_2015ad", "Brocklehurst_etal_2015ae", "Brocklehurst_etal_2015af", "Bronzati_etal_2012a", "Bronzati_etal_2015ab", "Brusatte_etal_2009ba", "Campbell_etal_2016ab", "Carr_et_Williamson_2004a", "Carr_etal_2017ab", "Frederickson_et_Tumarkin-Deratzian_2014aa", "Frederickson_et_Tumarkin-Deratzian_2014ab", "Frederickson_et_Tumarkin-Deratzian_2014ac", "Frederickson_et_Tumarkin-Deratzian_2014ad", "Garcia_etal_2006a", "Gatesy_etal_2004ab", "Grellet-Tinner_2006a", "Grellet-Tinner_et_Chiappe_2004a", "Grellet-Tinner_et_Makovicky_2006a", "Knoll_2008a", "Kurochkin_1996a", "Lopez-Martinez_et_Vicens_2012a", "Lu_etal_2014aa", "Norden_etal_inpressa", "Pisani_etal_2002a", "Ruiz-Omenaca_etal_1997a", "Ruta_etal_2003ba", "Ruta_etal_2003bb", "Ruta_etal_2007a", "Selles_et_Galobart_2016a", "Sereno_1993a", "Sidor_2001a", "Skutschas_etal_in
pressa", "Tanaka_etal_2011a", "Toljagic_et_Butler_2013a", "Tsuihiji_etal_2011aa", "Varricchio_et_Jackson_2004a", "Vila_etal_2017a", "Wilson_2005aa", "Wilson_2005ab", "Zelenitsky_et_Therrien_2008a")#
  HigherTaxaToCollapse = c()#
  MissingSpecies = "exclude"#
  Interval = NULL#
  VeilLine = TRUE#
  SpeciesToExclude = c()#
  IncludeSpecimenLevelOTUs = TRUE#
  BackboneConstraint = NULL#
  MonophylyConstraint = NULL#
  InclusiveDataList = c()#
  ExclusiveDataList = c()#
  # New Options (requires code to actually use them)#
  ##
  # HigherTaxaToCollapse Vector can be empty.#
  # VeilLine TRUE/FALSE (will be in output)#
  # SpeciesToExclude Vector of any species to be excluded from the final metatree. E.g., Eshanosaurus, Ricardoestesia.#
  # BackboneConstraint Newick string of backbone constraint (allows taxa not in topology). NULL as default.#
  # MonophylyConstraint Newick string of monophyly constraint (excludes taxa not in topology). NULL as default.#
  # CHECK PARENT IS A DATA SET AND NOT A REFERENCE, E.G., IF ENTER A REFERENCE AS PARENT THEN PARENT TURNS OUT TO HAVE TWO DATA SETS#
  # CHECK FOR SPECIES THAT BELONG TO A GENUS DIFFERENT TO THE ONE IN THEIR NAME!#
  # NEED TO CATCH ISSUE WHERE GENUS NUMBER IS USED FOR A SPECIES (HARD TO CHECK SO FAR DUE TO INDETERMINATES CONTINGENCY)#
  # NEED SOME TEST THAT HELPS CHECK ROOT IS SENSIBLE#
  # NEED SOME TEST THAT HELPS DETERMINE IF MULTIPLE OCCURRENCES OF SAME TAXON AFTER RECONCILIATION IS CORRECT OR AN ERROR#
  # ADD MORE COMPLEX WEIGHTS BY USING ADDITIONAL CHARACTER STATES! (EACH DATASET TOTAL WEIGHT DETERMINED BY YEAR AND DEPENDENCE THEN SUBDIVIDED ACROSS CHARACTER?) - BUT THIS SEEMS TO SLOW THINGS DRAMATICALLY MAYBE DO BY DUPLICATING CHARACTERS INSTEAD#
  # MAKE STR OPTIONAL (SAVES A LITTLE TIME)#
  # CHECK THERE ARE MULTIPLE TAXA PRE-RECONCILIATION#
  # CHECK INDETS DO NOT GIVE MULTIPLE MATCHES#
  # HOW TO DELETE DATA SETS THAT STILL CONTRIBUTE TO DEPENDENCE?#
  # Subfunction that gives just MRPs where matrix is still intact (has rows and columns):#
  ActiveMRP <- function(MRPList) unname(which(unlist(lapply(MRPList, function(x) prod(dim(x$Matrix)))) > 0))#
#
  # Check MRPDirectory is formatted correctly adn stop and warn user if not:#
  if(!all(is.character(MRPDirectory)) || length(MRPDirectory) != 1) stop("MRPDirectory must be a single character string indicating the path to the folder containing the MRP files.")#
  # Check XMLDirectory is formatted correctly adn stop and warn user if not:#
  if(!all(is.character(XMLDirectory)) || length(XMLDirectory) != 1) stop("XMLDirectory must be a single character string indicating the path to the folder containing the XML files.")#
  # Check TargetClade is formatted correctly adn stop and warn user if not:#
  if(!all(is.character(TargetClade)) || length(TargetClade) != 1) stop("TargetClade must be a single character string indicating the desired clade the metatree will represent.")#
  # Check MissingSpecies respresents a valid option:#
  if(length(setdiff(MissingSpecies, c("all", "exclude", "genus"))) > 0) stop("MissingSpecies must be one of \"all\", \"exclude\", or \"genus\".")#
  # Check VeilLine is a logical and stop and warn user if not:#
  if(!is.logical(VeilLine)) stop("VeilLine must be a logical (TRUE or FALSE).")#
  # Check IncludeSpecimenLevelOTUs is a logical and stop and warn user if not:#
  if(!is.logical(IncludeSpecimenLevelOTUs)) stop("IncludeSpecimenLevelOTUs must be a logical (TRUE or FALSE).")#
  # If not a NULL read backbone constraint (checks it is a valid Newick format):#
  if(!is.null(BackboneConstraint)) BackboneConstraintTree <- ape::read.tree(text = BackboneConstraint)#
  # If not a NULL read monophyly constraint (checks it is a valid Newick format):#
  if(!is.null(MonophylyConstraint)) MonophylyConstraintTree <- ape::read.tree(text = MonophylyConstraint)#
  # List of types of resolution that require finding a senior synonym:#
  synonyms <- c("corrected to", "misspelling of", "objective synonym of", "obsolete variant of", "recombined as", "replaced by", "subjective synonym of")#
  # List of types of resolution that require changing reconciliation to DELETE:#
  deletes <- c("nomen dubium", "nomen vanum", "nomen nudum", "nomen oblitum", "invalid subgroup of")#
  # Print current processing status:#
  cat("Reading MRP data...")#
  # Set working directory as MRP directory:#
  setwd(MRPDirectory)#
  # List MRP files (or just use inclusivedatalist if set):#
  MRPFileList <- strsplit(ifelse(length(InclusiveDataList) > 0, paste(setdiff(sort(unique(InclusiveDataList)), sort(unique(ExclusiveDataList))), "mrp.nex", sep = "", collapse = "%%"), paste(setdiff(gsub("mrp\\.nex", "", list.files()), sort(unique(ExclusiveDataList))), "mrp.nex", sep = "", collapse = "%%")), "%%")[[1]]#
  # Read in all MRP files and store in a list (include duplicate headers to store parent sibling info later):#
  MRPList <- lapply(lapply(as.list(MRPFileList), Claddis::ReadMorphNexus), function(x) {y <- list(x$Matrix_1$Matrix, x$Matrix_1$Weights, "", "", ""); names(y) <- c("Matrix", "Weights", "FileName", "Parent", "Sibling"); y})#
  # Set names of MRP files:#
  names(MRPList) <- gsub("mrp.nex", "", MRPFileList)#
  # Print current processing status:#
  cat("Done\nReading XML data...")#
  # Set working directory as XML (i.e., metadata) directory:#
  setwd(XMLDirectory)#
  # List MRP files (or just use inslusivedatalist if set):#
  XMLFileList <- strsplit(ifelse(length(InclusiveDataList) > 0, paste(setdiff(sort(unique(InclusiveDataList)), sort(unique(ExclusiveDataList))), ".xml", sep = "", collapse = "%%"), paste(setdiff(gsub("\\.xml", "", list.files()), sort(unique(ExclusiveDataList))), ".xml", sep = "", collapse = "%%")), "%%")[[1]]#
  XMLFileList <- setdiff(XMLFileList, "Hartman_etal_2019a.xml")#
  # Check there are no MRPs not listed as XMLs and vice versa (should return empty vector):#
  MRPXMLunion <- c(setdiff(gsub("\\.xml", "", XMLFileList), gsub("mrp\\.nex", "", MRPFileList)), setdiff(gsub("mrp\\.nex", "", MRPFileList), gsub("\\.xml", "", XMLFileList)))#
  # Stop if MRP datasets not listed as XMLs and vice versa:#
  if(length(MRPXMLunion) > 0) stop(paste("Datasets do not match (MRP and XML)!:", MRPXMLunion, collapse = " "))#
  # Read in all XML files and store in a list:#
  XMLList <- lapply(as.list(XMLFileList), function(x) ReadMetatreeXML(x))#
  # Add names to XML list:#
  names(XMLList) <- gsub(".xml", "", XMLFileList)#
  # Collapse to just pertinent information:#
  XMLList <- lapply(XMLList, function(x) {y <- list(); y[["TaxonMatrix"]] <- x$SourceTree$Taxa$TagContents; y[["FileName"]] <- unname(unlist(x$SourceTree$Filename)); y[["Parent"]] <- unname(unlist(x$SourceTree$Parent)); y[["Sibling"]] <- unname(unlist(x$SourceTree$Sibling)); y})#
  # Find any files that contain duplicated taxon names:#
  FilesWithDuplicatedTaxonNames <- names(XMLList)[which(unlist(lapply(XMLList, function(x) any(duplicated(x$TaxonMatrix[, "ListValue"])))))]#
  # If duplicate names were found stop and warn user:#
  if(length(FilesWithDuplicatedTaxonNames) > 0) stop(paste("The following files contain duplicate taxon names: ", paste(FilesWithDuplicatedTaxonNames, collapse = ", "), ". Ensure all taxon names are unique and try again.", sep = ""))#
  # Find any taxon names that do not match between MRP and XML:#
  TaxonMismatches <- mapply(function(x, y) {MRPNames <- rownames(x$Matrix); XMLNames <- y$TaxonMatrix[, "ListValue"]; c(setdiff(MRPNames, XMLNames), setdiff(XMLNames, MRPNames))}, x = MRPList[names(MRPList)], y = XMLList[names(MRPList)])#
  # Find any files with mismatching taxon names between MRP and XML:#
  FilesWithTaxonMismatches <- names(TaxonMismatches)[which(unlist(lapply(TaxonMismatches, function(x) length(x))) > 0)]#
  # If such files are found then stop and warn user:#
  if(length(FilesWithTaxonMismatches) > 0) stop(paste("The following files contain mismatching taxon names between the MRP and XML versions: ", paste(FilesWithTaxonMismatches, collapse = ", "), ". Ensure all taxon names match and try again.", sep = ""))#
  # Compile any name issues:#
  NameIssues <- lapply(XMLList, function(x) {TaxonMatrix <- x$TaxonMatrix; SpacesFound <- c(grep(" ", TaxonMatrix[, "recon_name"]), grep(" ", TaxonMatrix[, "recon_no"]), grep(" ", TaxonMatrix[, "ListValue"])); EmptyValuesFound <- c(which(TaxonMatrix[, "recon_name"] == ""), which(TaxonMatrix[, "recon_no"] == ""), which(TaxonMatrix[, "ListValue"] == "")); RogueNumberCharacters <- setdiff(unique(unlist(strsplit(TaxonMatrix[, "recon_no"], ""))), c(0:9, ";", "-")); RogueNameCharacters <- setdiff(unique(c(unlist(strsplit(TaxonMatrix[, "recon_name"], "")), unlist(strsplit(TaxonMatrix[, "ListValue"], "")))), c(LETTERS, letters, 0:9, "_", ",")); y <- list(SpacesFound, EmptyValuesFound, RogueNumberCharacters, RogueNameCharacters); names(y) <- c("SpacesFound", "EmptyValuesFound", "RogueNumberCharacters", "RogueNameCharacters"); y})#
  # Find any files with spaces in taxon names:#
  FilesWithSpaces <- names(NameIssues)[unlist(lapply(NameIssues, function(x) length(x$SpacesFound))) > 0]#
  # Find any values with empty values for taxon names:#
  FilesWithEmptyValues <- names(NameIssues)[unlist(lapply(NameIssues, function(x) length(x$EmptyValuesFound))) > 0]#
  # Files with rogue values in the recon number field:#
  FilesWithRogueTaxonNumbers <- names(NameIssues)[unlist(lapply(NameIssues, function(x) length(x$RogueNumberCharacters))) > 0]#
  # Files with rogue values in the name fields:#
  FilesWithRogueTaxonNames <- names(NameIssues)[unlist(lapply(NameIssues, function(x) length(x$RogueNameCharacters))) > 0]#
  # If issues with spaces in names stop and warn user:#
  if(length(FilesWithSpaces) > 0) stop(paste("The following files contain spaces in the taxonomic reconciliation (names or numbers): ", paste(FilesWithSpaces, collapse = ", "), ". Remove spaces and try again.", sep = ""))#
  # If issues with empty names stop and warn user:#
  if(length(FilesWithEmptyValues) > 0) stop(paste("The following files contain empty values in the taxonomic reconciliation (names or numbers): ", paste(FilesWithEmptyValues, collapse = ", "), ". Ensure all values are filled and try again.", sep = ""))#
  # If issues with rogue characters in number field stop and warn user:#
  if(length(FilesWithRogueTaxonNumbers) > 0) stop(paste("The following files contain rogue values in the taxonomic reconciliation (numbers): ", paste(FilesWithRogueTaxonNumbers, collapse = ", "), ". Ensure all taxon numbers only include semicolon(s) (the separating character) or dashes (for negative values) and try again.", sep = ""))#
  # If issues with rogue characters in name field stop and warn user:#
  if(length(FilesWithRogueTaxonNames) > 0) stop(paste("The following files contain rogue values in the taxonomic reconciliation (names): ", paste(FilesWithRogueTaxonNames, collapse = ", "), ". Ensure all taxon names are formed from alphanumerics, commas (the separating character) or underscores and try again.", sep = ""))#
  # Reconcile OTU names with XML version:#
  MRPList <- mapply(function(x, y) {rownames(x$Matrix)[unlist(lapply(as.list(rownames(x$Matrix)), function(z) which(y$TaxonMatrix[, "ListValue"] == z)))] <- paste(y$TaxonMatrix[, "recon_no"], y$TaxonMatrix[, "recon_name"], sep = "%%%%"); x$FileName <- y$FileName; if(!is.null(y$Parent)) x$Parent <- y$Parent; if(!is.null(y$Sibling)) x$Sibling <- y$Sibling; x}, x = MRPList[names(MRPList)], y = XMLList[names(MRPList)], SIMPLIFY = FALSE)#
#
  # Print current processing status:#
  cat("Done\nChecking for unsampled parents and siblings...")#
  # Extract parent and sibling names:#
  ParentAndSiblingNames <- sort(unlist(lapply(as.list(unique(unname(unlist(lapply(MRPList, '[', c("Parent", "Sibling")))))), function(x) x[nchar(x) > 0])))#
  # Warn user about any unsampled parents and/or siblings:#
  if(length(setdiff(ParentAndSiblingNames, names(MRPList))) > 0) print(paste("The following parents and siblings are not in the sample (check they are correct or add them into the sample): ", paste(setdiff(ParentAndSiblingNames, names(MRPList)), collapse = ", "), sep = ""))#
  # Print current processing status:#
  cat("Done\nFinding initial multiple-taxon reconciliations...")#
  # Subfunction to make multi-taxon reconciliations unique OTUs:#
  SeparateMultiTaxonReconciliations <- function(ListBlock) {#
    # Find comma rows (multiple taxa in initial reconciliation):#
    commarows <- grep(",", rownames(ListBlock$Matrix))#
    # If there is at least one multiple-taxon reconciliation:#
    if(length(commarows) > 0) {#
      # For each multiple-taxon reconciliation in reverse order (to avoid later rows not matching):#
      for(j in rev(commarows)) {#
        # Get multiple names of reconciliation:#
        multiplenames <- strsplit(rownames(ListBlock$Matrix)[j], "%%%%")[[1]]#
        # Get multiple-taxon numbers:#
        multitaxonnumbers <- strsplit(multiplenames[1], ";")[[1]]#
        # Get multiple-taxon names:#
        multitaxonnames <- strsplit(multiplenames[2], ",")[[1]]#
        # Check data integrity with respect to multiple-taxon values:#
        if(length(multitaxonnumbers) != length(multitaxonnames)) stop(paste("Problem with multiple-taxon reconciliation(s) in ", ListBlock$FileName, " (check commas and semi-colons are correct; i.e., of same length).", sep = ""))#
        # Add new rows at base of matrix:#
        ListBlock$Matrix <- rbind(ListBlock$Matrix, matrix(rep(ListBlock$Matrix[j, ], length(multitaxonnumbers)), nrow = length(multitaxonnumbers), byrow = TRUE, dimnames = list(paste(multitaxonnumbers, multitaxonnames, sep = "%%%%"), c())))#
        # Remove now redundant row from matrix:#
        ListBlock$Matrix <- ListBlock$Matrix[-j, , drop = FALSE]#
      }#
    }#
    # Return updated list block:#
    return(ListBlock)#
  }#
  # Separate out multi-taxon reconcilations:#
  MRPList <- lapply(MRPList, SeparateMultiTaxonReconciliations)#
  # If excluding specimen-level OTUs:#
  if(!IncludeSpecimenLevelOTUs) {#
    # Print current processing status:#
    cat("Done\nRemoving specimen-level OTUs...")#
    # Convert specimen-level OTUs to taxa to DELETE:#
    MRPList <- lapply(MRPList, function(x) {RowNamesToDelete <- which(unlist(lapply(strsplit(rownames(x$Matrix), split = ""), function(y) sum(y == "_") > 2))); if(length(RowNamesToDelete) > 0) rownames(x$Matrix)[RowNamesToDelete] <- "0%%%%DELETE"; x})#
  }#
  # Print current processing status:#
  cat("Done\nRemoving taxa with initial reconciliations of \"DELETE\"...")#
  # Remove any taxa reconciled as DELETE:#
  MRPList <- lapply(MRPList, function(x) {DeleteRows <- which(unlist(lapply(strsplit(rownames(x$Matrix), split = "%%%%"), function(y) y[2])) == "DELETE"); if(length(DeleteRows) > 0) x$Matrix <- x$Matrix[-DeleteRows, , drop = FALSE]; x})#
  # Prune matrices following deletion:#
  MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {y <- PisaniMRPPrune(Claddis::MakeMorphMatrix(x$Matrix, weights = x$Weights, ignore.duplicate.taxa = TRUE)); x$Matrix <- y$Matrix_1$Matrix; x$Weights <- y$Matrix_1$Weights; x})#
#
  # Print current processing status:#
  cat("Done\nSearching for and collapsing pre-reconciliation duplicated taxa...")#
  # Collapse any duplicate taxon names:#
  MRPList[ActiveMRP(MRPList)] <- lapply(MRPList[ActiveMRP(MRPList)], function(x) {y <- Claddis::MakeMorphMatrix(x$Matrix, weights = x$Weights, ignore.duplicate.taxa = TRUE); if(any(duplicated(rownames(y$Matrix_1$Matrix)))) {DuplicateNames <- setdiff(unlist(lapply(strsplit(rownames(y$Matrix_1$Matrix)[duplicated(rownames(y$Matrix_1$Matrix))], split = "%%%%"), '[', 2)), "DELETE"); if(length(DuplicateNames) > 0) cat(paste("\nDuplicate resolved OTU name(s) found in ", x$FileName, ": ", paste(DuplicateNames, collapse = ", "), ". Check this is correct.", sep = "")); y <- CollapseDuplicateTaxonMRP(y)}; x$Matrix <- y$Matrix_1$Matrix; x$Weights <- y$Weights; x})#
  # Print current processing status:#
  cat("Done\nBuilding initial taxonomy matrix...")#
  # Create taxonomy matrix to store all taxon resolution data:#
  TaxonomyMatrix <- do.call(rbind, strsplit(unique(unname(unlist(lapply(MRPList[ActiveMRP(MRPList)], function(x) rownames(x$Matrix))))), split ="%%%%"))#
  # Add column names:#
  colnames(TaxonomyMatrix) <- c("TaxonNo", "TaxonName")#
  # Print current processing status:#
  cat("Done\nChecking for missing taxon numbers...")#
  # If any "-1" taxa found stop and tell user:#
  if(any(TaxonomyMatrix[, "TaxonNo"] == "-1")) stop(paste("The following taxa have the reconciliation number \"-1\": ", paste(TaxonomyMatrix[TaxonomyMatrix[, "TaxonNo"] == "-1", "TaxonName"], collapse = ", "), sep = ""))#
  # Print current processing status:#
  cat("Done\nChecking for combined taxon numbers (&)...")#
  # If any "&" taxa found stop and tell user:#
  if(length(grep("&", TaxonomyMatrix[, "TaxonNo"]))) stop(paste("The following taxa have multiple reconciliation numbers: ", paste(TaxonomyMatrix[grep("&", TaxonomyMatrix[, "TaxonNo"]), "TaxonName"], collapse = ", "), sep = ""))
TaxonMismatches
TaxonMismatches[["Cau_etal_inpressa"]]
# Load Claddis library:#
library(Claddis)#
#
# Set working directory:#
setwd("~/Documents/Homepage/www.graemetlloyd.com")#
#
# Get file list:#
file.list <- list.files()#
#
# Get just the group matrix pages:#
file.list <- file.list[grep("matr[a-z]{4}.html", file.list)]#
#
# Vector for storing output:#
results <- vector(mode = "character")#
#
# Main loop:#
for(i in 1:length(file.list)) {#
  # Read in ith file:#
  X <- scan(file.list[i], what = "", sep = "\n", quiet = TRUE)#
  # Find first p tag opening:#
  begins <- grep("<p class=\"hangingindent\">", X)#
  # FInd last p tag closing:#
  ends <- grep("</p>", X)#
  # Reduce X to just the portion with references:#
  X <- X[begins[1]:ends[length(ends)]]#
  # Find where p tags open:#
  begins <- grep("<p class=\"hangingindent\">", X)#
  # Find where p tags close:#
  ends <- grep("</p>", X)#
  # Check p tags are closed and warn if not:#
  if(length(begins) != length(ends)) print(paste("Error in", file.list[i]))#
  # For each set of p tags:#
  for(j in 1:length(ends)) {#
    # Get full reference block:#
    Y <- X[begins[j]:ends[j]]#
    # Only proceed if this has not already been dealt with:#
    if(length(grep("<a href", Y)) == 0) {#
      # Remove bookmarks:#
      Y <- gsub("</p>", "", gsub("<p class=\"hangingindent\">", "", Y))#
      # Strip out leading whitespace:#
      while(length(grep("\t", Y)) > 0) Y <- gsub("\t", " ", Y)#
      # Strip out leading whitespace:#
      while(length(grep("  ", Y)) > 0) Y <- gsub("  ", " ", Y)#
      # Strip out last leading whitespace"#
      for(k in 1:length(Y)) Y[k] <- paste(strsplit(Y[k], "")[[1]][2:length(strsplit(Y[k], "")[[1]])], collapse = "")#
      # Isolate author and year:#
      authorandyear <- strsplit(gsub(" and ", "%%", gsub("\\., ", ".%%", Y[1])), "%%")[[1]]#
      # Isolate title:#
      title <- Y[2]#
      ##
      locale <- gsub("</b>", "", gsub("<b>", "", gsub("</em>", "", gsub("<em>", "", strsplit(gsub("\\.", "", gsub(", ", "%%", Y[3])), "%%")[[1]]))))#
      ##
      authorline <- paste("\t\t<Author>\n", paste("\t\t\t<List>", authorandyear[1:(length(authorandyear) - 1)], "</List>", sep = "", collapse = "\n"), "\n\t\t</Author>\n", sep = "")#
      ##
      yearline <- paste("\t\t<Year>", gsub("\\.", "", authorandyear[length(authorandyear)]), "</Year>\n", sep = "")#
      ##
      year <- gsub("</Year>\n", "", gsub("\t\t<Year>", "", yearline))#
      ##
      titleline <- strsplit(title, "")[[1]]#
      ##
      if(titleline[length(titleline)] == ".") titleline <- titleline[-length(titleline)]#
      ##
      titleline <- paste(titleline, collapse = "")#
      ##
      titleline <- paste("\t\t<Title>", titleline, "</Title>\n", sep = "")#
      # Case if a book chapter:#
      if(length(grep("In ", locale[1])) == 1) {#
        # Restore locale to original line:#
        locale <- Y[3]#
        ##
        locale <- gsub("<em>In</em> ", "", locale)#
        # Insert first (editor(s)) separator:#
        locale <- gsub(" \\(eds\\.\\) ", "%%", locale)#
        # Insert first (editor(s)) separator:#
        locale <- gsub(" \\(ed\\.\\) ", "%%", locale)#
        # Insert first (editor(s)) separator:#
        locale <- gsub(" \\(eds\\) ", "%%", locale)#
        # Insert first (editor(s)) separator:#
        locale <- gsub(" \\(ed\\) ", "%%", locale)#
        # Isolate editors#
        editors <- strsplit(locale, "%%")[[1]][1]#
        # Add "and" separator:#
        editors <- gsub(" and ", "%%", editors)#
        ##
        if(length(grep(",", editors)) > 0) {#
          # Case if single editor in correct "Surname, Initials" format:#
          if(length(grep("%%", editors)) == 0) editorsline <- paste("\t\t<Editor>\n", paste("\t\t\t<List>", editors, "</List>\n", sep = ""), "\t\t</Editor>\n", sep = "")#
          # Case if authors are in incorrect "Intitals Surname" format:#
          if(strsplit(editors, "")[[1]][2] == ".") {#
            # Add separator between names:#
            editors <- gsub(", ", "%%", editors)#
            ##
            editors <- strsplit(editors, "%%")[[1]]#
            ##
            for(k in 1:length(editors)) {#
              ##
              temp <- strsplit(editors[k], "\\. ")[[1]]#
              ##
              editors[k] <- paste(temp[length(temp)], paste(temp[1:(length(temp) - 1)], ".", sep = "", collapse = " "), sep = ", ")#
            }#
            ##
            editorsline <- paste("\t\t<Editor>\n", paste("\t\t\t<List>", editors, "</List>\n", sep = "", collapse = ""), "\t\t</Editor>\n", sep = "")#
            ##
          } else {#
            # Add separator between names:#
            editors <- gsub("\\., ", ".%%", editors)#
            ##
            editorsline <- paste("\t\t<Editor>\n", paste("\t\t\t<List>", strsplit(editors, "%%")[[1]], "</List>\n", sep = "", collapse = ""), "\t\t</Editor>\n", sep = "")#
          }#
          ##
        } else {#
          # Case if single editor in incorrect "Intitals Surname" format:#
          if(length(grep("%%",editors)) == 0) {#
            ##
            editors <- strsplit(editors, "\\. ")[[1]]#
            ##
            editors <- paste(paste(editors[length(editors)], ",", sep = ""), paste(editors[1:(length(editors) - 1)], ".", sep = "", collapse = " "), collapse = " ")#
            ##
            editorsline <- paste("\t\t<Editor>\n", paste("\t\t\t<List>", editors, "</List>\n", sep = ""), "\t\t</Editor>\n", sep = "")#
            # Case of two authors in incorrect "Intitals Surname" format:#
          } else {#
            ##
            editors <- strsplit(editors, "%%")[[1]]#
            ##
            for(k in 1:length(editors)) {#
              ##
              temp <- strsplit(editors[k], "\\. ")[[1]]#
              ##
              editors[k] <- paste(temp[length(temp)], paste(temp[1:(length(temp) - 1)], ".", sep = "", collapse = " "), sep = ", ")#
            }#
            ##
            editorsline <- paste("\t\t<Editor>\n", paste("\t\t\t<List>", editors, "</List>\n", sep = "", collapse = ""), "\t\t</Editor>\n", sep = "")#
          }#
        }#
        # Remove editors from rest of book information:#
        locale <- paste(strsplit(locale, "%%")[[1]][2:length(strsplit(locale, "%%")[[1]])], sep = "%%")#
        # Find end of book title separator:#
        locale <- gsub("\\. ", "%%", locale)#
        # Remove trailing period:#
        locale <- gsub("\\.", "", locale)#
        # Isolate booktitle:#
        booktitleline <- paste("\t\t<Booktitle>", strsplit(locale, "%%")[[1]][1], "</Booktitle>\n", sep = "")#
        # Remove booktitle from rest of book information:#
        locale <- paste(strsplit(locale, "%%")[[1]][2:length(strsplit(locale, "%%")[[1]])], sep = "%%")#
        # Remove false gaps:#
        while(length(locale) > 1) locale <- paste(locale, collapse = ". ")#
        # Separate remaining portions:#
        locale <- strsplit(locale, ", ")[[1]]#
        ##
        publisherline <- paste("\t\t<Publisher>", locale[1], "</Publisher>\n", sep = "")#
        ##
        cityline <- paste("\t\t<City>", locale[2], "</City>\n", sep = "")#
        ##
        pagesline <- paste("\t\t<Pages>", gsub("<br>", "", gsub("p", "", locale[3])), "</Pages>\n", sep = "")#
        ##
        fulllines <- paste(authorline, yearline, titleline, "\t\t<Journal/>\n", "\t\t<Volume/>\n", pagesline, booktitleline, publisherline, cityline, editorsline, sep = "")#
        # Case if a journal:#
      } else {#
        ##
        if(year == "in press") {#
          # Case if journal title with commas:#
          if(length(locale) > 2) {#
            # Collapse journal title:#
            locale[1] <- paste(locale[1], locale[2], sep = ", ")#
            # Remove redudnant second part#
            locale <- locale[-2]#
          }#
          # Delete empty volume value#
          if(locale[2] == "") locale <- locale[-2]#
        }#
        # Find journal titles with commas:#
        while(length(locale) > 3) {#
          # Collapse journal title:#
          locale[1] <- paste(locale[1], locale[2], sep = ", ")#
          # Remove redudnant second part:#
          locale <- locale[-2]#
        }#
        ##
        journalline <- paste("\t\t<Journal>", locale[1], "</Journal>\n", sep = "")#
        ##
        if(length(locale) > 1) {#
          ##
          volumeline <- paste("\t\t<Volume>", locale[2], "</Volume>\n", sep = "")#
          ##
        } else {#
          ##
          volumeline <- "\t\t<Volume/>\n"#
        }#
        ##
        if(length(locale) > 2) {#
          ##
          pagesline <- paste("\t\t<Pages>", locale[3], "</Pages>\n", sep = "")#
          ##
        } else {#
          ##
          pagesline <- "\t\t<Pages/>\n"#
        }#
        ##
        fulllines <- paste(authorline, yearline, titleline, journalline, volumeline, pagesline, "\t\t<Booktitle/>\n", "\t\t<Publisher/>\n", "\t\t<City/>\n","\t\t<Editor/>\n", sep = "")#
      }#
    }#
    ##
    results <- c(results, fulllines)#
  }#
}#
#
# Collapse to just unique references (not sure how duplicates ended up in here...):#
results <- sort(unique(results))#
#
# Create empty vector to store hypothetical file names:#
filenames <- vector(mode = "character")#
#
# For each reference:#
for(i in 1:length(results)) {#
  # Isolate authors:#
  authors <- strsplit(strsplit(gsub("\n|\t", "", results[i]), split = "<Author>|</Author>")[[1]][2], split = "<List>|</List>")[[1]][which(nchar(strsplit(strsplit(gsub("\n|\t", "", results[i]), split = "<Author>|</Author>")[[1]][2], split = "<List>|</List>")[[1]]) > 0)]#
  # Isolate surnames:#
  surnames <- unlist(lapply(strsplit(authors, split = ","), '[', 1))#
  # Get publication year:#
  year <- gsub(" ", "", strsplit(gsub("\n|\t", "", results[i]), split = "<Year>|</Year>")[[1]][2])#
  # If a single author:#
  if(length(surnames) == 1) filenames <- c(filenames, gsub("'", "", gsub(" ", "_", paste(surnames, year, sep = "_"))))#
  # If two authors:#
  if(length(surnames) == 2) filenames <- c(filenames, gsub("'", "", gsub(" ", "_", paste(paste(surnames, collapse = "_et_"), year, sep = "_"))))#
  # If more than two authors:#
  if(length(surnames) > 2) filenames <- c(filenames, gsub("'", "", gsub(" ", "_", paste(surnames[1], "etal", year, sep = "_"))))#
}#
#
# Isolate references that have multiple file names (i.e., two or more refrences could be contracted to the same name):#
duplicates <- unique(filenames[duplicated(filenames)])#
#
# Set working directory:#
setwd("/Users/eargtl/Documents/Homepage/www.graemetlloyd.com/ToAdd")#
#
# Get list of folders:#
folder.list <- list.files()[-grep("\\.", list.files())]#
#
# Get full paths for each folder:#
for(i in 1:length(folder.list)) folder.list[i] <- paste(getwd(), "/", folder.list[i], sep = "")#
#
# Vector for storing nexus file list:#
file.list <- vector(mode = "character")#
#
# Find all file paths for nexus files:#
for(i in 1:length(folder.list)) {#
  # Set working directory for current folder:#
  setwd(folder.list[i])#
  # Look for NEXUS files:#
  if(length(grep(".nex", list.files())) > 0) {#
    # Add any found to file list:#
    file.list <- c(file.list, paste(folder.list[i], "/", list.files()[grep(".nex", list.files())], sep = ""))#
  }#
}#
#
# Get just the NEXUS file names:#
nexus.files <- unlist(lapply(strsplit(file.list, "/"), '[', 9))#
#
# Reset working directory:#
setwd("/Users/eargtl/Documents/Homepage/www.graemetlloyd.com/ToAdd")#
#
# Create vector to store multiple hits:#
multi_hitters <- vector(mode = "character")#
#
# Set scratch counter:#
scratch_counter <- 1#
#
# Create nexus, tnt and xml files:#
for(i in 1:length(file.list)) {#
  # Start feedback:#
  cat("Attempting to read: ", file.list[i], "...")#
  # Get stripped verion of name (i.e., missing a, b, aa etc. ending):#
  stripped_name <- gsub(strsplit(nexus.files[i], "[:0-9:]{4}|inpress")[[1]][2], "", nexus.files[i])#
  # Get hits for stripped name in filenames:#
  hits <- grep(stripped_name, filenames)#
  # Check there is a match:#
  if(length(hits) == 0) stop("No reference with matching name.")#
  # Create reference info:#
  reference_info <- paste(results[hits], collapse = "\n\nOR\n\n")#
  # If multiple hits add to list so these can be manually checked later:#
  if(length(hits) > 1) multi_hitters <- c(multi_hitters, nexus.files[i])#
  # Read in matrix:#
  mymatrix <- ReadMorphNexus(file.list[i])}
# Load Claddis library:#
library(Claddis)#
#
# Set working directory:#
setwd("~/Documents/Homepage/www.graemetlloyd.com")#
#
# Get file list:#
file.list <- list.files()#
#
# Get just the group matrix pages:#
file.list <- file.list[grep("matr[a-z]{4}.html", file.list)]#
#
# Vector for storing output:#
results <- vector(mode = "character")#
#
# Main loop:#
for(i in 1:length(file.list)) {#
  # Read in ith file:#
  X <- scan(file.list[i], what = "", sep = "\n", quiet = TRUE)#
  # Find first p tag opening:#
  begins <- grep("<p class=\"hangingindent\">", X)#
  # FInd last p tag closing:#
  ends <- grep("</p>", X)#
  # Reduce X to just the portion with references:#
  X <- X[begins[1]:ends[length(ends)]]#
  # Find where p tags open:#
  begins <- grep("<p class=\"hangingindent\">", X)#
  # Find where p tags close:#
  ends <- grep("</p>", X)#
  # Check p tags are closed and warn if not:#
  if(length(begins) != length(ends)) print(paste("Error in", file.list[i]))#
  # For each set of p tags:#
  for(j in 1:length(ends)) {#
    # Get full reference block:#
    Y <- X[begins[j]:ends[j]]#
    # Only proceed if this has not already been dealt with:#
    if(length(grep("<a href", Y)) == 0) {#
      # Remove bookmarks:#
      Y <- gsub("</p>", "", gsub("<p class=\"hangingindent\">", "", Y))#
      # Strip out leading whitespace:#
      while(length(grep("\t", Y)) > 0) Y <- gsub("\t", " ", Y)#
      # Strip out leading whitespace:#
      while(length(grep("  ", Y)) > 0) Y <- gsub("  ", " ", Y)#
      # Strip out last leading whitespace"#
      for(k in 1:length(Y)) Y[k] <- paste(strsplit(Y[k], "")[[1]][2:length(strsplit(Y[k], "")[[1]])], collapse = "")#
      # Isolate author and year:#
      authorandyear <- strsplit(gsub(" and ", "%%", gsub("\\., ", ".%%", Y[1])), "%%")[[1]]#
      # Isolate title:#
      title <- Y[2]#
      ##
      locale <- gsub("</b>", "", gsub("<b>", "", gsub("</em>", "", gsub("<em>", "", strsplit(gsub("\\.", "", gsub(", ", "%%", Y[3])), "%%")[[1]]))))#
      ##
      authorline <- paste("\t\t<Author>\n", paste("\t\t\t<List>", authorandyear[1:(length(authorandyear) - 1)], "</List>", sep = "", collapse = "\n"), "\n\t\t</Author>\n", sep = "")#
      ##
      yearline <- paste("\t\t<Year>", gsub("\\.", "", authorandyear[length(authorandyear)]), "</Year>\n", sep = "")#
      ##
      year <- gsub("</Year>\n", "", gsub("\t\t<Year>", "", yearline))#
      ##
      titleline <- strsplit(title, "")[[1]]#
      ##
      if(titleline[length(titleline)] == ".") titleline <- titleline[-length(titleline)]#
      ##
      titleline <- paste(titleline, collapse = "")#
      ##
      titleline <- paste("\t\t<Title>", titleline, "</Title>\n", sep = "")#
      # Case if a book chapter:#
      if(length(grep("In ", locale[1])) == 1) {#
        # Restore locale to original line:#
        locale <- Y[3]#
        ##
        locale <- gsub("<em>In</em> ", "", locale)#
        # Insert first (editor(s)) separator:#
        locale <- gsub(" \\(eds\\.\\) ", "%%", locale)#
        # Insert first (editor(s)) separator:#
        locale <- gsub(" \\(ed\\.\\) ", "%%", locale)#
        # Insert first (editor(s)) separator:#
        locale <- gsub(" \\(eds\\) ", "%%", locale)#
        # Insert first (editor(s)) separator:#
        locale <- gsub(" \\(ed\\) ", "%%", locale)#
        # Isolate editors#
        editors <- strsplit(locale, "%%")[[1]][1]#
        # Add "and" separator:#
        editors <- gsub(" and ", "%%", editors)#
        ##
        if(length(grep(",", editors)) > 0) {#
          # Case if single editor in correct "Surname, Initials" format:#
          if(length(grep("%%", editors)) == 0) editorsline <- paste("\t\t<Editor>\n", paste("\t\t\t<List>", editors, "</List>\n", sep = ""), "\t\t</Editor>\n", sep = "")#
          # Case if authors are in incorrect "Intitals Surname" format:#
          if(strsplit(editors, "")[[1]][2] == ".") {#
            # Add separator between names:#
            editors <- gsub(", ", "%%", editors)#
            ##
            editors <- strsplit(editors, "%%")[[1]]#
            ##
            for(k in 1:length(editors)) {#
              ##
              temp <- strsplit(editors[k], "\\. ")[[1]]#
              ##
              editors[k] <- paste(temp[length(temp)], paste(temp[1:(length(temp) - 1)], ".", sep = "", collapse = " "), sep = ", ")#
            }#
            ##
            editorsline <- paste("\t\t<Editor>\n", paste("\t\t\t<List>", editors, "</List>\n", sep = "", collapse = ""), "\t\t</Editor>\n", sep = "")#
            ##
          } else {#
            # Add separator between names:#
            editors <- gsub("\\., ", ".%%", editors)#
            ##
            editorsline <- paste("\t\t<Editor>\n", paste("\t\t\t<List>", strsplit(editors, "%%")[[1]], "</List>\n", sep = "", collapse = ""), "\t\t</Editor>\n", sep = "")#
          }#
          ##
        } else {#
          # Case if single editor in incorrect "Intitals Surname" format:#
          if(length(grep("%%",editors)) == 0) {#
            ##
            editors <- strsplit(editors, "\\. ")[[1]]#
            ##
            editors <- paste(paste(editors[length(editors)], ",", sep = ""), paste(editors[1:(length(editors) - 1)], ".", sep = "", collapse = " "), collapse = " ")#
            ##
            editorsline <- paste("\t\t<Editor>\n", paste("\t\t\t<List>", editors, "</List>\n", sep = ""), "\t\t</Editor>\n", sep = "")#
            # Case of two authors in incorrect "Intitals Surname" format:#
          } else {#
            ##
            editors <- strsplit(editors, "%%")[[1]]#
            ##
            for(k in 1:length(editors)) {#
              ##
              temp <- strsplit(editors[k], "\\. ")[[1]]#
              ##
              editors[k] <- paste(temp[length(temp)], paste(temp[1:(length(temp) - 1)], ".", sep = "", collapse = " "), sep = ", ")#
            }#
            ##
            editorsline <- paste("\t\t<Editor>\n", paste("\t\t\t<List>", editors, "</List>\n", sep = "", collapse = ""), "\t\t</Editor>\n", sep = "")#
          }#
        }#
        # Remove editors from rest of book information:#
        locale <- paste(strsplit(locale, "%%")[[1]][2:length(strsplit(locale, "%%")[[1]])], sep = "%%")#
        # Find end of book title separator:#
        locale <- gsub("\\. ", "%%", locale)#
        # Remove trailing period:#
        locale <- gsub("\\.", "", locale)#
        # Isolate booktitle:#
        booktitleline <- paste("\t\t<Booktitle>", strsplit(locale, "%%")[[1]][1], "</Booktitle>\n", sep = "")#
        # Remove booktitle from rest of book information:#
        locale <- paste(strsplit(locale, "%%")[[1]][2:length(strsplit(locale, "%%")[[1]])], sep = "%%")#
        # Remove false gaps:#
        while(length(locale) > 1) locale <- paste(locale, collapse = ". ")#
        # Separate remaining portions:#
        locale <- strsplit(locale, ", ")[[1]]#
        ##
        publisherline <- paste("\t\t<Publisher>", locale[1], "</Publisher>\n", sep = "")#
        ##
        cityline <- paste("\t\t<City>", locale[2], "</City>\n", sep = "")#
        ##
        pagesline <- paste("\t\t<Pages>", gsub("<br>", "", gsub("p", "", locale[3])), "</Pages>\n", sep = "")#
        ##
        fulllines <- paste(authorline, yearline, titleline, "\t\t<Journal/>\n", "\t\t<Volume/>\n", pagesline, booktitleline, publisherline, cityline, editorsline, sep = "")#
        # Case if a journal:#
      } else {#
        ##
        if(year == "in press") {#
          # Case if journal title with commas:#
          if(length(locale) > 2) {#
            # Collapse journal title:#
            locale[1] <- paste(locale[1], locale[2], sep = ", ")#
            # Remove redudnant second part#
            locale <- locale[-2]#
          }#
          # Delete empty volume value#
          if(locale[2] == "") locale <- locale[-2]#
        }#
        # Find journal titles with commas:#
        while(length(locale) > 3) {#
          # Collapse journal title:#
          locale[1] <- paste(locale[1], locale[2], sep = ", ")#
          # Remove redudnant second part:#
          locale <- locale[-2]#
        }#
        ##
        journalline <- paste("\t\t<Journal>", locale[1], "</Journal>\n", sep = "")#
        ##
        if(length(locale) > 1) {#
          ##
          volumeline <- paste("\t\t<Volume>", locale[2], "</Volume>\n", sep = "")#
          ##
        } else {#
          ##
          volumeline <- "\t\t<Volume/>\n"#
        }#
        ##
        if(length(locale) > 2) {#
          ##
          pagesline <- paste("\t\t<Pages>", locale[3], "</Pages>\n", sep = "")#
          ##
        } else {#
          ##
          pagesline <- "\t\t<Pages/>\n"#
        }#
        ##
        fulllines <- paste(authorline, yearline, titleline, journalline, volumeline, pagesline, "\t\t<Booktitle/>\n", "\t\t<Publisher/>\n", "\t\t<City/>\n","\t\t<Editor/>\n", sep = "")#
      }#
    }#
    ##
    results <- c(results, fulllines)#
  }#
}#
#
# Collapse to just unique references (not sure how duplicates ended up in here...):#
results <- sort(unique(results))#
#
# Create empty vector to store hypothetical file names:#
filenames <- vector(mode = "character")#
#
# For each reference:#
for(i in 1:length(results)) {#
  # Isolate authors:#
  authors <- strsplit(strsplit(gsub("\n|\t", "", results[i]), split = "<Author>|</Author>")[[1]][2], split = "<List>|</List>")[[1]][which(nchar(strsplit(strsplit(gsub("\n|\t", "", results[i]), split = "<Author>|</Author>")[[1]][2], split = "<List>|</List>")[[1]]) > 0)]#
  # Isolate surnames:#
  surnames <- unlist(lapply(strsplit(authors, split = ","), '[', 1))#
  # Get publication year:#
  year <- gsub(" ", "", strsplit(gsub("\n|\t", "", results[i]), split = "<Year>|</Year>")[[1]][2])#
  # If a single author:#
  if(length(surnames) == 1) filenames <- c(filenames, gsub("'", "", gsub(" ", "_", paste(surnames, year, sep = "_"))))#
  # If two authors:#
  if(length(surnames) == 2) filenames <- c(filenames, gsub("'", "", gsub(" ", "_", paste(paste(surnames, collapse = "_et_"), year, sep = "_"))))#
  # If more than two authors:#
  if(length(surnames) > 2) filenames <- c(filenames, gsub("'", "", gsub(" ", "_", paste(surnames[1], "etal", year, sep = "_"))))#
}#
#
# Isolate references that have multiple file names (i.e., two or more refrences could be contracted to the same name):#
duplicates <- unique(filenames[duplicated(filenames)])#
#
# Set working directory:#
setwd("/Users/eargtl/Documents/Homepage/www.graemetlloyd.com/ToAdd")#
#
# Get list of folders:#
folder.list <- list.files()[-grep("\\.", list.files())]#
#
# Get full paths for each folder:#
for(i in 1:length(folder.list)) folder.list[i] <- paste(getwd(), "/", folder.list[i], sep = "")#
#
# Vector for storing nexus file list:#
file.list <- vector(mode = "character")#
#
# Find all file paths for nexus files:#
for(i in 1:length(folder.list)) {#
  # Set working directory for current folder:#
  setwd(folder.list[i])#
  # Look for NEXUS files:#
  if(length(grep(".nex", list.files())) > 0) {#
    # Add any found to file list:#
    file.list <- c(file.list, paste(folder.list[i], "/", list.files()[grep(".nex", list.files())], sep = ""))#
  }#
}#
#
# Get just the NEXUS file names:#
nexus.files <- unlist(lapply(strsplit(file.list, "/"), '[', 9))#
#
# Reset working directory:#
setwd("/Users/eargtl/Documents/Homepage/www.graemetlloyd.com/ToAdd")#
#
# Create vector to store multiple hits:#
multi_hitters <- vector(mode = "character")#
#
# Set scratch counter:#
scratch_counter <- 1#
#
# Create nexus, tnt and xml files:#
for(i in 1:length(file.list)) {#
  # Start feedback:#
  cat("Attempting to read: ", file.list[i], "...")#
  # Get stripped verion of name (i.e., missing a, b, aa etc. ending):#
  stripped_name <- gsub(strsplit(nexus.files[i], "[:0-9:]{4}|inpress")[[1]][2], "", nexus.files[i])#
  # Get hits for stripped name in filenames:#
  hits <- grep(stripped_name, filenames)#
  # Check there is a match:#
  if(length(hits) == 0) stop("No reference with matching name.")#
  # Create reference info:#
  reference_info <- paste(results[hits], collapse = "\n\nOR\n\n")#
  # If multiple hits add to list so these can be manually checked later:#
  if(length(hits) > 1) multi_hitters <- c(multi_hitters, nexus.files[i])#
  # Read in matrix:#
  mymatrix <- ReadMorphNexus(file.list[i])#
  # Update header text:#
  mymatrix$Topper$Header <- "File downloaded from graemetlloyd.com"#
  # Make file name:#
  file.name <- gsub(".nex", "", strsplit(file.list[i], "/")[[1]][length(strsplit(file.list[i], "/")[[1]])])#
  # Write out NEXUS data:#
  WriteMorphNexus(CladisticMatrix = mymatrix, filename = paste("/Users/eargtl/Documents/Homepage/www.graemetlloyd.com/nexus", "/", file.name, ".nex", sep = ""))#
  # Write out TNT data:#
  WriteMorphTNT(CladisticMatrix = mymatrix, filename = paste("/Users/eargtl/Documents/Homepage/www.graemetlloyd.com/tnt", "/", file.name, ".tnt", sep = ""))#
  # Write out TNT for analysis:#
  WriteMorphTNT(CladisticMatrix = mymatrix, filename = paste("/Users/eargtl", "/", file.name, ".tnt", sep = ""), add.analysis.block = TRUE)#
  TNTFA <- readLines(paste("/Users/eargtl", "/", file.name, ".tnt", sep = ""))#
  # If scratch.tre is found:#
  if(length(grep("scratch.tre", TNTFA, fixed = TRUE)) > 0) {#
    # Replace scratch.tre with numbered version:#
    TNTFA <- gsub("scratch.tre", paste("scratch", scratch_counter, ".tre", sep = ""), TNTFA, fixed = TRUE)#
    # Overwrite TNT for analysis with numbered scratch.tre:#
    write(TNTFA, paste("/Users/eargtl", "/", file.name, ".tnt", sep = ""))#
    # Increment scratch counter:#
    scratch_counter <- scratch_counter + 1#
  }#
  # Make XML file:#
  myxml <- paste(paste("<?xml version=\"1.0\" standalone=\"yes\"?>\n<SourceTree>\n\t<Source>\n", reference_info, "\t</Source>"), paste("\t<Taxa number=\"", length(mymatrix$Matrix_1$Matrix[, 1]), "\">", sep = ""), paste(paste("\t\t<List recon_name=\"DELETE\" recon_no=\"-1\">", rownames(mymatrix$Matrix_1$Matrix), "</List>", sep = ""), collapse = "\n"), "\t</Taxa>\n\t<Characters>\n\t\t<Molecular/>", paste("\t\t<Morphological number=\"", sum(unlist(lapply(lapply(mymatrix[2:length(mymatrix)], '[[', "Matrix"), ncol))), "\">", sep = ""), "\t\t\t<Type>Osteology</Type>\n\t\t</Morphological>\n\t\t<Behavioural/>\n\t\t<Other/>\n\t</Characters>\n\t<Analysis>\n\t\t<Type>Maximum Parsimony</Type>\n\t</Analysis>\n\t<Notes>Based on reanalysis of the original matrix.</Notes>", paste("\t<Filename>", gsub("\\.nex", "", strsplit(file.list[i], "/")[[1]][length(strsplit(file.list[i], "/")[[1]])]), "</Filename>", sep = ""), "\t<Parent/>\n\t<Sibling/>\n</SourceTree>", sep = "\n")#
  # Write out XML file:#
  write(myxml, paste("/Users/eargtl/Documents/Homepage/www.graemetlloyd.com/xml", "/", file.name, ".xml", sep = ""))#
  # Feedback:#
  cat("Done\n")#
}#
#
# List multiple hitters for checking:#
sort(multi_hitters)
# Open libraries:#
library(Claddis)#
library(metatree)#
#
# Set working directory:#
setwd("/Users/eargtl")#
#
# Get list of mrp files:#
mrp.list <- list.files()[grep("mrp.nex", list.files())]#
#
# Get list of mrp files:#
trees.list <- list.files()[grep("mpts_plus_strict.nex", list.files())]#
#
# Make tree files:#
for(i in 1:length(trees.list)) {#
  # Read in TNT trees and split into mpts and strict consensus:#
  mytrees <- Trees2MPTsAndStrict(trees.list[i])#
  # If the tree limit of 100000 was hit (i.e., not all MPTs are guranteed to have been sampled) or no MRP could be created due to sheer number of trees:#
  if(length(mytrees$mpts) == 100000 || sum(mrp.list == gsub("tntmpts_plus_strict.nex", "mrp.nex", trees.list[i])) == 0) {#
    # Create MRP filename:#
    mrp.filename <- gsub("tntmpts_plus_strict.nex", "mrp.nex", trees.list[i])#
    # If MRP file was generated:#
    if(length(which(mrp.list == mrp.filename)) > 0) {#
      # Remove from MRP list:#
      mrp.list <- mrp.list[-which(mrp.list == mrp.filename)]#
      # Delete raw file as likely too big anyway:#
      file.remove(mrp.filename)#
    }#
    # Create nexus file name:#
    nexus.filename <- gsub("mrp\\.nex", ".nex", mrp.filename)#
    # Read in original matrix:#
    mymatrix <- ReadMorphNexus(paste("~/Documents/Homepage/www.graemetlloyd.com/nexus", "/", nexus.filename, sep = ""))#
    # Write out regular TNT file:#
    WriteMorphTNT(mymatrix, gsub("\\.nex", ".tnt", nexus.filename))#
    # Read in TNT lines:#
    TNT.lines <- readLines(gsub("\\.nex", ".tnt", nexus.filename))#
    # Get TNT data block:#
    tnt.block <- TNT.lines[1:(grep("proc/;", TNT.lines) - 1)]#
    # Create analysis block:#
    anal.block <- paste(c("rseed*;\nhold 999;\nxmult=rss fuse 50 drift 50 ratchet 50;\nmult 50 =tbr drift;\ntsave scratch.tre;\nsave;\ntsave /;", rep("rseed*;\nhold 999;\nxmult=rss fuse 50 drift 50 ratchet 50;\nmult 50 =tbr drift;\ntsave scratch.tre +;\nsave;\ntsave /;", 4), "hold 5000;\nshortread scratch.tre;\nbbreak=tbr;"), collapse = "\n")#
    # Cretae empty vector to store final block:#
    full.block <- vector(mode = "character")#
    # Fill out all blocks for analysis:#
    for(j in 1:20) full.block <- c(full.block, paste(paste(tnt.block, collapse = "\n"), anal.block, "mrp;", paste("export ", gsub("\\.nex", "", nexus.filename), "mrp_", j, ".nex;", sep = ""), sep = "\n"))#
    # Write out TNT file:#
    write(paste(paste(full.block, collapse = "\n"), "\nproc/;\n", sep = ""), gsub("\\.nex", ".tnt", nexus.filename))#
  }#
  # Make file name:#
  file.name <- gsub("tntmpts_plus_strict.nex", "", trees.list[i])#
  # Write out MPTs:#
  write(mytrees$mpts, paste("/Users/eargtl/Documents/Homepage/www.graemetlloyd.com/mpts", "/", file.name, ".tre", sep = ""))#
  # Write out first MPT:#
  write(mytrees$mpts[1], paste("/Users/eargtl/Documents/Homepage/www.graemetlloyd.com/firstmpt", "/", file.name, ".tre", sep = ""))#
  # Write out strict consensus:#
  write(mytrees$strict, paste("/Users/eargtl/Documents/Homepage/www.graemetlloyd.com/sc", "/", file.name, ".tre", sep = ""))#
  # Delete trees file now no longer needed:#
  file.remove(trees.list[i])#
  # Spit out loop position:#
  cat(i, " ")#
}#
#
# Make mrp files:#
for(i in 1:length(mrp.list)) {#
  # Add assumptions block to MRP:#
  x <- paste(c(readLines(mrp.list[i]), "BEGIN ASSUMPTIONS;", "OPTIONS  DEFTYPE=unord PolyTcount=MINSTEPS ;", "END;"), collapse = "\n")#
  # Write out MRP file with assumptions added (can then be read in with ReadMorphNexus):#
  write(x = x, file = mrp.list[i])#
  # Read in MRP file:#
  mymrp <- ReadMorphNexus(mrp.list[i])#
  # Remove root taxon:#
  mymrp$Matrix_1$Matrix <- mymrp$Matrix_1$Matrix[-which(rownames(mymrp$Matrix_1$Matrix) == "ROOT"), ]#
  # Collapse to just unique characters:#
  mymrp <- CompactifyMatrix(mymrp)#
  # Overwrite weights (set all to one):#
  mymrp$Matrix_1$Weights <- rep(1, length(mymrp$Matrix_1$Weights))#
  # Make file name:#
  file.name <- gsub(".nex", "", mrp.list[i])#
  # Isolate MPR taxon names:#
  mrp.names <- rownames(mymrp$Matrix_1$Matrix)#
  # Isolate full names:#
  nexus.names <- rownames(ReadMorphNexus(paste("/Users/eargtl/Documents/Homepage/www.graemetlloyd.com/nexus/", gsub("mrp", "", file.name), ".nex", sep = ""))$Matrix_1$Matrix)#
  # Check to see if MRP names are contracted:#
  if(length(setdiff(mrp.names, nexus.names)) > 0) {#
    # List all contracted names:#
    contracted.names <- setdiff(mrp.names, nexus.names)#
    # For each contracted name:#
    for(j in 1:length(contracted.names)) {#
      # Get matching full name(s):#
      full.name <- nexus.names[grep(contracted.names[j], nexus.names)]#
      # Check that there are not multiple matches:#
      if(length(full.name) > 1) stop("Multiple names match contracted form. Check manually.")#
      # Overwrite contracted name with full name:#
      rownames(mymrp$Matrix_1$Matrix)[which(rownames(mymrp$Matrix_1$Matrix) == contracted.names[j])] <- full.name#
    }#
  }#
  # Write out MRP in #NEXUS format:#
  WriteMorphNexus(mymrp, paste("/Users/eargtl/Documents/Homepage/www.graemetlloyd.com/mrp", "/", file.name, ".nex", sep = ""))#
  # Delete file once finished:#
  file.remove(mrp.list[i])#
  # Spit out loop position:#
  cat(i, " ")#
}
# Load gdata library:#
library(gdata)#
#
# Set working directory:#
setwd("~/Documents/Homepage/www.graemetlloyd.com/xml")#
#
# Get list of xml file names):#
xml.list <- list.files()#
#
# Create empty list to store XML data:#
XML.data <- vector(mode = "character")#
#
# Import XML data and store in list:#
for(i in xml.list) XML.data[i] <- ifelse(length(grep("<Title>", trim(readLines(i)))) > 0, strsplit(trim(readLines)(i)[grep("<Title>", readLines(i))], "<Title>|</Title>")[[1]][2], strsplit(trim(readLines(i))[grep("<Booktitle>", trim(readLines(i)))], "<Booktitle>|</Booktitle>")[[1]][2])#
#
# Set working directory:#
setwd("~/Documents/Homepage/www.graemetlloyd.com/mpts")#
#
# Get list of tree file names (to use later in case of .zip endings):#
trees.list <- list.files()#
#
# Set working directory:#
setwd("~/Documents/Homepage/www.graemetlloyd.com")#
#
# Get file list:#
html.file.list <- list.files()[grep("matr[a-z]{4}.html", list.files())]#
#
# Create empty list to store html:#
html.data <- list()#
#
# For each set of matrices:#
for(i in 1:length(html.file.list)) {#
  # Read in the file:#
  X <- readLines(con = html.file.list[i])#
  # Get beginning sof references:#
  begins <- grep("<p class=\"hangingindent\">", X)#
  # Get endings of references:#
  ends <- grep("</p>", X)#
  # Check p tags are closed:#
  if(length(begins) != length(ends)) stop("Opening and closing paragraph marks do not match up.")#
  # For each reference add html to list (file name, title, actual text block):#
  for(j in 1:length(begins)) html.data[[(length(html.data) + 1)]] <- c(html.file.list[i], trim(X[begins[j] + 1]), X[begins[j]:ends[j]])#
}#
#
# For each html with links:#
for(i in which(unlist(lapply(html.data, length)) > 5)) {#
  # Strip down to just reference:#
  html.data[[i]] <- html.data[[i]][1:5]#
  # Remove remaining beginning of link:#
  html.data[[i]][5] <- gsub("<br><font size=\"-1\">", "</p>", html.data[[i]][5])#
}#
#
# Empty list to store matching titles from XML in HTML:#
matchedhtmldata <- list()#
#
# For each XML file:#
for(i in 1:length(XML.data)) {#
  # Store filename for ith XML file:#
  FileName <- names(XML.data)[i]#
  # Reset i as title sentence:#
  i <- XML.data[i]#
  # Get found matches (grep) for XML title in html data:#
  foundmatches <- grep(i, unlist(lapply(html.data, '[', 2)), fixed = TRUE)#
  # If length of found matcehs is zero (no matches) stop and warn:#
  if(length(foundmatches) == 0) stop("No matches!")#
  # If multiple matches find one closest in character length (most likely outcome!) and update foundmatches accordingly:#
  if(length(foundmatches) > 1) foundmatches <- foundmatches[which(abs(nchar(i) - nchar(unlist(lapply(html.data, '[', 2))[foundmatches])) == min(abs(nchar(i) - nchar(unlist(lapply(html.data, '[', 2))[foundmatches]))))]#
  # If a single match (ideal outcome):#
  if(length(foundmatches) == 1) matchedhtmldata[[(length(matchedhtmldata) + 1)]] <- foundmatches#
  # Final check that found matches do not exceed one:#
  if(length(foundmatches) > 1) {#
    # Get first names of authors on each match:#
    FirstNames <- unlist(lapply(lapply(lapply(lapply(lapply(lapply(lapply(html.data[foundmatches], '[', 3), strsplit, split = "<p class=\"hangingindent\">"), unlist), '[', 2), strsplit, split = ", "), unlist), '[', 1))#
    # Get first name of author from ith XML file:#
    FirstName <- strsplit(strsplit(FileName, split = "[:0-9:]{4}|inpress")[[1]][1], split = "_")[[1]][1]#
    # Update found matches with matching first author surname(s):#
    foundmatches <- foundmatches[which(FirstNames == FirstName)]#
    # If no matches stop and warn user:#
    if(length(foundmatches) == 0) stop("No matches found for first author name.")#
    # If a single match (ideal outcome):#
    if(length(foundmatches) == 1) matchedhtmldata[[(length(matchedhtmldata) + 1)]] <- foundmatches#
    # If multiple matches stop and warn user:#
    if(length(foundmatches) > 1) stop("Multiple matches found for title and first author.")#
  }#
}#
#
# Now only single matches convert matchedhtml to vector:#
matchedhtmldata <- unlist(matchedhtmldata)#
#
# For each HTML file that has an XML file:#
for(i in sort(unique(unlist(matchedhtmldata)))) {#
  # Get filenames for current html matches:#
  filenames <- sort(gsub(".xml", "", names(XML.data[which(matchedhtmldata == i)])))#
  # Create empty vectors to store mpt filenames and treestrings for treevector links:#
  mptsfilenames <- treestrings <- vector(mode = "character")#
  # Set working directory to strict consensus folder:#
  setwd("~/Documents/Homepage/www.graemetlloyd.com/sc")#
  # Get tree Newick strings for treevector links:#
  for(j in paste(filenames, ".tre", sep = "")) treestrings <- c(treestrings, paste("http://supfam.cs.bris.ac.uk/TreeVector/cgi-bin/maketree.cgi?topology=", gsub("\\;", "%3B", gsub("\\)", "%29", gsub("\\(", "%28", readLines(j)))), "&treetype=-clad", sep = ""))#
  # Set working directory to MPTs folder:#
  setwd("~/Documents/Homepage/www.graemetlloyd.com/mpts")#
  # Get MPTs filenames:#
  for(j in filenames) mptsfilenames <- c(mptsfilenames, list.files()[which(lapply(strsplit(list.files(), split = j), '[[', 1) == "")])#
  # Put it all together by updating html.data with links:#
  html.data[[i]] <- gsub("</p>", paste("<br><font size=\"-1\">\n                                        ", paste(paste("<a href=\"nexus/", filenames, ".nex\" target=\"_blank\">NEXUS</a> | <a href=\"tnt/", filenames, ".tnt\" target=\"_blank\">TNT</a> | <a href=\"mpts/", mptsfilenames, "\" target=\"_blank\">MPT(s)</a> <a href=\"firstmpt/", filenames, ".tre\" target=\"_blank\">(1)</a> | <a href=\"sc/", filenames, ".tre\" target=\"_blank\">SC</a> <a href=\"", treestrings, "\" target=\"_blank\">(TV)</a> | <a href=\"mrp/", filenames, "mrp.nex\" target=\"_blank\">MRP</a> | <a href=\"xml/", filenames, ".xml\" target=\"_blank\">XML</a>", sep = ""), collapse = "<br>\n                                    "), "</font></p>", sep = ""), html.data[[i]])#
}#
#
# Set working directory:#
setwd("~/Documents/Homepage/www.graemetlloyd.com")#
#
# For each html file:#
for(i in html.file.list) {#
  # Read in html for ith file:#
  fullhtml <- readLines(i)#
  # Store opening lines:#
  openinglines <- paste(fullhtml[1:max(grep("<a href=\"matr.html\">", fullhtml))], collapse = "\n")#
  # Store closing lines:#
  closinglines <- paste(fullhtml[grep("<!-- InstanceEndEditable -->", fullhtml, fixed = TRUE):length(fullhtml)], collapse = "\n")#
  # Find out which references are on the ith html page:#
  currentrefs <- which(unlist(lapply(html.data, '[', 1)) == i)#
  # Build initial references block (of html code):#
  refsblock <- html.data[currentrefs]#
  # Get publication years for each reference:#
  pubyears <- trim(gsub(".", "", unlist(lapply(lapply(strsplit(unlist(lapply(refsblock, '[', 3)), ","), rev), '[', 1)), fixed = TRUE))#
  # Little check that references are in order:#
  if(any(diff(as.numeric(setdiff(pubyears, "in press"))) > 0)) stop("References out of order!")#
  # Replace lower case in with upper case In for in press stuff:#
  pubyears <- gsub("in press", "In press", pubyears)#
  # Create new refs block (for stroing them collapsed by pub year):#
  newrefsblock <- vector(mode = "character")#
  # For each unique publication year create html block:#
  for(j in unique(pubyears)) newrefsblock <- c(newrefsblock, paste(paste("                                    <h4>", j, "</h4>\n\n", sep = ""), paste(unlist(lapply(lapply(refsblock[which(pubyears == j)], '[', 3:5), paste, collapse = "\n")), collapse = "\n\n"), sep = ""))#
  # Write html to file:#
  write(paste(c(openinglines, newrefsblock, closinglines), collapse = "\n\n"), file = i)#
}
# Load metatree library:#
library(metatree)#
#
# Setw roking directory to XML folder:#
setwd("~/Documents/Homepage/www.graemetlloyd.com/xml")#
#
# Get list of all XML files:#
XMLFiles <- list.files()#
#
# Read all XML files into a list:#
XMLs <- lapply(as.list(XMLFiles), function(x) metatree::ReadMetatreeXML(x))#
#
# Remove all taxonomic reconciliations:#
XMLs <- lapply(XMLs, function(x) {x$SourceTree$Taxa$TagContents[, "recon_name"] <- "DELETE"; x$SourceTree$Taxa$TagContents[, "recon_no"] <- "-1"; x$SourceTree$Taxa$TagContents; x})#
#
# Remove all parent-sibling tags:#
XMLs <- lapply(XMLs, function(x) {x$SourceTree$Parent <- list(NULL); x$SourceTree$Parent <- list(NULL); x})#
#
# Set working directory to release folder:#
setwd("~/Documents/Homepage/www.graemetlloyd.com/xmlrelease")#
#
# Write files to release folder:#
mapply(function(x, y) metatree::WriteMetatreeXML(x, y), x = XMLs, y = as.list(XMLFiles))
# CODE TO FILL OUT SAFE FIRST GUESSES FOR TAXON RECONCILIATION WHERE MISSING FROM XML FILES#
# I.E., USES EXACT SPECIES NAMES AND PALEOBIOLOGY DATABASE OR USES RECONCILIATION FROM PARENT DATASET FOR EXACT SAME OTU OTHERWISE OTUS ARE NOT ALTERED AT ALL#
#
# Load libraries:#
library(metatree)#
library(Claddis)#
#
# Set working directory to HTML files:#
setwd("~/Documents/Homepage/www.graemetlloyd.com")#
#
# Get list of matrix HTMLs:#
MatrixHTMLfiles <- list.files()[grep("matr[:a-z:]{4}.html", list.files())]#
#
# Create empty HTML list:#
MatrixHTML <- list()#
#
# Read in each raw HTML code into list:#
for(i in 1:length(MatrixHTMLfiles)) MatrixHTML[[i]] <- readLines(MatrixHTMLfiles[i])#
#
# Add file names to HTML list:#
names(MatrixHTML) <- gsub(",html", "", MatrixHTMLfiles)#
#
# Set working directory as XML folder:#
setwd("~/Documents/Homepage/www.graemetlloyd.com/xml")#
#
# List all XML files:#
xmlfiles <- list.files()#
#
# Create empty vector to store parent datasets:#
parentdataset <- vector(mode = "character")#
#
# For each XML file:#
for(i in xmlfiles) {#
    # Read in ith XML file:#
    currentxml <- readLines(i)#
    # If there is a parent data set (from which to draw recinciliation data from):#
    parentdataset <- c(parentdataset, ifelse(length(grep("<Parent>", currentxml)) > 0, strsplit(currentxml[grep("<Parent>", currentxml)], "<|>")[[1]][3], ""))#
}#
#
# Add file names to parent data set vector:#
names(parentdataset) <- gsub(".xml", "", xmlfiles)#
#
# Get vector of "dead" parents, i.e., those not currently present in the data pool:#
deadparents <- sort(setdiff(unique(parentdataset), names(parentdataset)))[which(nchar(sort(setdiff(unique(parentdataset), names(parentdataset)))) > 0)]#
#
# Remove dead parents from parent list:#
for(i in deadparents) parentdataset[which(parentdataset == i)] <- ""#
#
# Create empty parent depth vector (number of links to original data set):#
parentdepth <- vector(mode = "numeric")#
#
# For each data set:#
for(i in names(parentdataset)) {#
    # Set starting depth at zero (no parent at all):#
    currentdepth <- 0#
    # If there is at least an initial parent:#
    if(parentdataset[i] != "") {#
        # Increase depth by one:#
        currentdepth <- currentdepth + 1#
        # While there are further parents:#
        while(parentdataset[i] != "") {#
            # Increase depth by one#
            currentdepth <- currentdepth + 1#
            # Update new parent:#
            i <- parentdataset[i]#
        }#
    }#
    # Add parent depth to vector:#
    parentdepth <- c(parentdepth, currentdepth)#
}#
#
# Reorder xml file lists by parent depth (ensures parents are filled out before children so names can always be carried forwards):#
xmlfiles <- xmlfiles[order(parentdepth, decreasing = FALSE)]#
#
# Count of total OTUs (start with zero):#
TotalOTUs <- 0#
#
# For each XML file:#
for(i in xmlfiles) {#
    # Read in ith XML file:#
    currentxml <- readLines(i)#
    # If there is a parent data set (from which to draw recinciliation data from):#
    if(length(grep("<Parent>", currentxml)) > 0) {#
        # Get parent data set file name:#
        parentdataset <- strsplit(currentxml[grep("<Parent>", currentxml)], "<|>")[[1]][3]#
        # Check parent has been processed (has an XML file on which to draw):#
        if(!is.na(match(paste(parentdataset, ".xml", sep = ""), xmlfiles))) {#
            # Isolate taxon names block:#
            taxonnameblock <- currentxml[(grep("<Taxa", currentxml) + 1):(grep("</Taxa", currentxml) - 1)]#
            # Reformat as matrix:#
            taxonnameblock <- matrix(unlist(lapply(strsplit(taxonnameblock, "\"|>|<"), '[', c(3, 5, 7))), ncol = 3, byrow = TRUE, dimnames = list(c(), c("ReconName", "ReconNo", "OTUName")))#
            # Add number of OTUs to count:#
            TotalOTUs <- TotalOTUs + nrow(taxonnameblock)#
            # If there are unreconciled taxa:#
            if(any(taxonnameblock[, "ReconNo"] == "-1")) {#
                # Get just the unreconciled names (we don't care about ones already done):#
                unreconcilednames <- taxonnameblock[which(taxonnameblock[, "ReconNo"] == "-1"), "OTUName"]#
                # Read in ith XML file:#
                parentxml <- readLines(paste(parentdataset, ".xml", sep = ""))#
                # Isolate taxon names block:#
                parenttaxonnameblock <- parentxml[(grep("<Taxa", parentxml) + 1):(grep("</Taxa", parentxml) - 1)]#
                # Reformat as matrix:#
                parenttaxonnameblock <- matrix(unlist(lapply(strsplit(parenttaxonnameblock, "\"|>|<"), '[', c(3, 5, 7))), ncol = 3, byrow = TRUE, dimnames = list(c(), c("ReconName", "ReconNo", "OTUName")))#
                # If at least one name can be reconciled using parent data set data:#
                if(any(!is.na(match(unreconcilednames, parenttaxonnameblock[, "OTUName"])))) {#
                    # Update unreconciled names as just those also present in parent data:#
                    unreconcilednames <- unreconcilednames[!is.na(match(unreconcilednames, parenttaxonnameblock[, "OTUName"]))]#
#
                    # Update taxon names block with parent data:#
                    taxonnameblock[match(unreconcilednames, taxonnameblock[, "OTUName"]), ] <- parenttaxonnameblock[match(unreconcilednames, parenttaxonnameblock[, "OTUName"]), ]#
                }#
            }#
            # Add taxonblock back into currentxml:#
            currentxml[(grep("<Taxa", currentxml) + 1):(grep("</Taxa", currentxml) - 1)] <- paste("\t\t<List recon_name=\"", taxonnameblock[, "ReconName"], "\" recon_no=\"", taxonnameblock[, "ReconNo"], "\">", taxonnameblock[, "OTUName"], "</List>", sep = "")#
#
        }#
#
    }#
    # Write out XML:#
    write(x = paste(currentxml, collapse = "\n"), file = i)#
}#
#
# Set empty priorites matrix:#
Priorities <- matrix(nrow = 0, ncol = 4, dimnames = list(c(), c("Name", "NUnreconciled", "ParentDepth", "HTMLFile")))#
#
# For each XML file:#
for(i in xmlfiles) {#
  # Read in ith XML file:#
  currentxml <- readLines(i)#
  # Work out which html file the data set belongs to:#
  currenthtml <- names(which(unlist(lapply(lapply(MatrixHTML, grep, pattern = paste("xml/", i, sep = "")), length)) == 1))#
  # Isolate taxon names block:#
  taxonnameblock <- currentxml[(grep("<Taxa", currentxml) + 1):(grep("</Taxa", currentxml) - 1)]#
  # Reformat as matrix:#
  taxonnameblock <- matrix(unlist(lapply(strsplit(taxonnameblock, "\"|>|<"), '[', c(3, 5, 7))), ncol = 3, byrow = TRUE, dimnames = list(c(), c("ReconName", "ReconNo", "OTUName")))#
  # Add to priorities matrix:#
  Priorities <- rbind(Priorities, c(i, sum(taxonnameblock[, "ReconNo"] == "-1"), parentdepth[order(parentdepth, decreasing = FALSE)][which(xmlfiles == i)], currenthtml))#
}#
#
# Remove any XMLs where all taxa are already reconciled:#
Priorities <- Priorities[-which(Priorities[, "NUnreconciled"] == "0"), , drop = FALSE]#
#
# Number of files that still need taxa reconciled:#
paste(nrow(Priorities), " files still contain unreconciled taxa (", round(((length(xmlfiles) - nrow(Priorities)) / length(xmlfiles) * 100), 2), "% complete)", sep = "")#
#
# Number of individual OTU names that still need reconciling:#
paste(sum(as.numeric(Priorities[, "NUnreconciled"])), " OTUs are still unreconciled (", round(((TotalOTUs - sum(as.numeric(Priorities[, "NUnreconciled"]))) / TotalOTUs * 100), 2), "% complete)", sep = "")#
#
# Order by number of unreconciled OTUs:#
Priorities <- Priorities[order(as.numeric(Priorities[, "NUnreconciled"])), ]#
#
# Display priorities for archosaurs (excluding Cenozoic birds):#
Priorities[sort(c(which(Priorities[, "HTMLFile"] == "matrarch.html"), which(Priorities[, "HTMLFile"] == "matrdino.html"))), ]
# Get functions in:#
library(Claddis)#
library(ade4)#
library(foreach)#
library(doParallel)#
#
# Register parallel back end as number of cores available:#
registerDoParallel(cores = 4)#
#
# Set working directory:#
setwd("/Users/eargtl")#
#
# Get list of mrp files:#
mrp.list <- list.files()[grep("mrp_", list.files())]#
#
# For each MRP file:#
for(i in 1:length(mrp.list)) {#
  # Read in raw MRP file:#
  x <- readLines(mrp.list[i])#
  # If there is no assumptions block:#
  if(length(grep("begin assumptions", x, ignore.case = TRUE)) == 0) {#
    # Add assumptions block to MRP:#
    x <- paste(c(x, "BEGIN ASSUMPTIONS;", "OPTIONS  DEFTYPE=unord PolyTcount=MINSTEPS ;", "END;"), collapse = "\n")#
    # Write out MRP file with assumptions added (can then be read in with ReadMorphNexus):#
    write(x = x, file = mrp.list[i])#
  }#
}#
#
# Make mrp files:#
x <- foreach(i = 1:length(mrp.list), .combine = "rbind") %dopar% {#
#
  # Read in ith MRP file:#
  mymrp <- ReadMorphNexus(mrp.list[i])#
  # Compactify the matrix:#
  mymrp <- CompactifyMatrix(mymrp)#
  # To avoid non-numeric weight (e.g., 1+e05) set all weights above ten to ten:#
  if(sum(mymrp$Matrix_1$Weights > 10)) mymrp$Matrix_1$Weights[which(mymrp$Matrix_1$Weights > 10)] <- 10#
  # If any rogue NAs are found prune these from the data:#
  if(length(unique(as.vector(mymrp$Matrix_1$Matrix))) > 2) mymrp <- MatrixPruner(mymrp, characters2prune = which((apply(apply(mymrp$Matrix_1$Matrix, 2, '==', "0") + apply(mymrp$Matrix_1$Matrix, 2, '==', "1"), 2, sum)) < nrow(mymrp$Matrix_1$Matrix)))#
#
  # Overwrite original data with compactified version:#
  WriteMorphNexus(mymrp, mrp.list[i])#
}#
#
# Get unique data set names:#
data.sets <- unique(matrix(unlist(strsplit(mrp.list, "mrp_")), ncol = 2, byrow = TRUE)[, 1])#
#
# For each data set:#
for(i in 1:length(data.sets)) {#
  # Get numbers for files to read in:#
  files.to.load <- grep(data.sets[i], mrp.list)#
  # For each file in data set:#
  for(j in files.to.load) {#
    # Read in current matrix:#
    current.matrix <- ReadMorphNexus(mrp.list[j])#
    # Sort by row name to ensure taxa line up later:#
    current.matrix$Matrix_1$Matrix <- current.matrix$Matrix_1$Matrix[sort(rownames(current.matrix$Matrix_1$Matrix)), ]#
    # If first file of data set:#
    if(files.to.load[1] == j) {#
      # Set matrix using current matrix:#
      MATRIX <- current.matrix$Matrix_1$Matrix#
      # Set weights using current matrix:#
      WEIGHTS <- current.matrix$Matrix_1$Weights#
    # If not first file of data set:#
    } else {#
      # Add current matrix to data set:#
      MATRIX <- cbind(MATRIX, current.matrix$Matrix_1$Matrix)#
      # Add current weights to data set:#
      WEIGHTS <- c(WEIGHTS, current.matrix$Matrix_1$Weights)#
    }#
  }#
  # Overwrite current matrix with full data set:#
  current.matrix$Matrix_1$Matrix <- MATRIX#
  # Overwrite current matrix weights with full data set:#
  current.matrix$Matrix_1$Weights <- WEIGHTS#
  # Set ordering for full data set:#
  current.matrix$Matrix_1$Ordering <- rep("unord", ncol(current.matrix$Matrix_1$Matrix))#
  # Set maximum values for full data set:#
  current.matrix$Matrix_1$MinVals <- rep(1, ncol(current.matrix$Matrix_1$Matrix))#
  # Set minimum values for full data set:#
  current.matrix$Matrix_1$MaxVals <- rep(0, ncol(current.matrix$Matrix_1$Matrix))#
  # Collapse data set:#
  current.matrix <- CompactifyMatrix(current.matrix)#
  # To avoid non-numeric weight (e.g., 1+e05) set all weights above ten to ten:#
  if(sum(current.matrix$Matrix_1$Weights > 10)) current.matrix$Matrix_1$Weights[which(current.matrix$Matrix_1$Weights > 10)] <- 10#
  # Make file name:#
  file.name <- data.sets[i]#
  # Case if MRP is done (minimum weight is greater than 1):#
  if(min(current.matrix$Matrix_1$Weights) > 1) {#
    # Remove "ROOT" taxon if present:#
    if(sum(rownames(current.matrix$Matrix_1$Matrix) == "ROOT") > 0) current.matrix$Matrix_1$Matrix <- current.matrix$Matrix_1$Matrix[-which(rownames(current.matrix$Matrix_1$Matrix) == "ROOT"), ]#
    # Collapse matrix again:#
    current.matrix <- CompactifyMatrix(current.matrix)#
    # Overwrite all weights with 1:#
    current.matrix$Matrix_1$Weights <- rep(1, length(current.matrix$Matrix_1$Weights))#
    # Update matrix in nesting order (outgroup first):#
    current.matrix$Matrix_1$Matrix <- current.matrix$Matrix_1$Matrix[names(sort(apply(apply(current.matrix$Matrix_1$Matrix, 1, as.numeric), 2, sum))), ]#
    # Isolate MRP taxon names:#
    mrp.names <- rownames(current.matrix$Matrix_1$Matrix)#
    # Isolate full names:#
    nexus.names <- rownames(ReadMorphNexus(paste("/Users/eargtl/Documents/Homepage/www.graemetlloyd.com/nexus/", gsub("mrp", "", file.name), ".nex", sep = ""))$Matrix_1$Matrix)#
    # Check to see if MRP names are contracted:#
    if(length(setdiff(mrp.names, nexus.names)) > 0) {#
      # List all contracted names:#
      contracted.names <- setdiff(mrp.names, nexus.names)#
      # For each contracted name:#
      for(j in 1:length(contracted.names)) {#
        # Get matching full name(s):#
        full.name <- nexus.names[grep(contracted.names[j], nexus.names)]#
        # Check that there are not multiple matches:#
        if(length(full.name) > 1) stop("Multiple names match contracted form. Check manually.")#
        # Overwrite contracted name with full name:#
        rownames(current.matrix$Matrix_1$Matrix)[which(rownames(current.matrix$Matrix_1$Matrix) == contracted.names[j])] <- full.name#
      }#
    }#
    # Write out MRP in #NEXUS format:#
    WriteMorphNexus(current.matrix, paste("/Users/eargtl/Documents/Homepage/www.graemetlloyd.com/mrp", "/", file.name, "mrp.nex", sep = ""))#
    # Remove dead files:#
    file.remove(c(mrp.list[files.to.load], paste(file.name, ".tnt", sep = "")))#
  # Case if MRP needs to continue (minimum weight is 1):#
  } else {#
    # Remove dead files:#
    file.remove(mrp.list[files.to.load])#
    # Write out MRP in #NEXUS format:#
    WriteMorphNexus(current.matrix, paste("/Users/eargtl/", file.name, "mrp_0.nex", sep = ""))#
  }#
  # Output loop position:#
  cat(i, " ")#
}
library(CLaddis)
library(Claddis)
x <- ReadMorphNexus("~/Documents/Homepage/www.graemetlloyd.com/nexus/Brocklehurst_etal_2013a.nex")
STR(x)
y <- SafeTaxonomicReduction(x)
y$removed.matrix
names(y)
y$reduced.matrix
WriteMorphTNT(y$reduced.matrix, "~/Brocklehurst_etal_2013aR.tnt")
# Get functions in:#
library(Claddis)#
library(ade4)#
library(foreach)#
library(doParallel)#
#
# Register parallel back end as number of cores available:#
registerDoParallel(cores = 4)#
#
# Set working directory:#
setwd("/Users/eargtl")#
#
# Get list of mrp files:#
mrp.list <- list.files()[grep("mrp_", list.files())]#
#
# For each MRP file:#
for(i in 1:length(mrp.list)) {#
  # Read in raw MRP file:#
  x <- readLines(mrp.list[i])#
  # If there is no assumptions block:#
  if(length(grep("begin assumptions", x, ignore.case = TRUE)) == 0) {#
    # Add assumptions block to MRP:#
    x <- paste(c(x, "BEGIN ASSUMPTIONS;", "OPTIONS  DEFTYPE=unord PolyTcount=MINSTEPS ;", "END;"), collapse = "\n")#
    # Write out MRP file with assumptions added (can then be read in with ReadMorphNexus):#
    write(x = x, file = mrp.list[i])#
  }#
}#
#
# Make mrp files:#
x <- foreach(i = 1:length(mrp.list), .combine = "rbind") %dopar% {#
#
  # Read in ith MRP file:#
  mymrp <- ReadMorphNexus(mrp.list[i])#
  # Compactify the matrix:#
  mymrp <- CompactifyMatrix(mymrp)#
  # To avoid non-numeric weight (e.g., 1+e05) set all weights above ten to ten:#
  if(sum(mymrp$Matrix_1$Weights > 10)) mymrp$Matrix_1$Weights[which(mymrp$Matrix_1$Weights > 10)] <- 10#
  # If any rogue NAs are found prune these from the data:#
  if(length(unique(as.vector(mymrp$Matrix_1$Matrix))) > 2) mymrp <- MatrixPruner(mymrp, characters2prune = which((apply(apply(mymrp$Matrix_1$Matrix, 2, '==', "0") + apply(mymrp$Matrix_1$Matrix, 2, '==', "1"), 2, sum)) < nrow(mymrp$Matrix_1$Matrix)))#
#
  # Overwrite original data with compactified version:#
  WriteMorphNexus(mymrp, mrp.list[i])#
}#
#
# Get unique data set names:#
data.sets <- unique(matrix(unlist(strsplit(mrp.list, "mrp_")), ncol = 2, byrow = TRUE)[, 1])#
#
# For each data set:#
for(i in 1:length(data.sets)) {#
  # Get numbers for files to read in:#
  files.to.load <- grep(data.sets[i], mrp.list)#
  # For each file in data set:#
  for(j in files.to.load) {#
    # Read in current matrix:#
    current.matrix <- ReadMorphNexus(mrp.list[j])#
    # Sort by row name to ensure taxa line up later:#
    current.matrix$Matrix_1$Matrix <- current.matrix$Matrix_1$Matrix[sort(rownames(current.matrix$Matrix_1$Matrix)), ]#
    # If first file of data set:#
    if(files.to.load[1] == j) {#
      # Set matrix using current matrix:#
      MATRIX <- current.matrix$Matrix_1$Matrix#
      # Set weights using current matrix:#
      WEIGHTS <- current.matrix$Matrix_1$Weights#
    # If not first file of data set:#
    } else {#
      # Add current matrix to data set:#
      MATRIX <- cbind(MATRIX, current.matrix$Matrix_1$Matrix)#
      # Add current weights to data set:#
      WEIGHTS <- c(WEIGHTS, current.matrix$Matrix_1$Weights)#
    }#
  }#
  # Overwrite current matrix with full data set:#
  current.matrix$Matrix_1$Matrix <- MATRIX#
  # Overwrite current matrix weights with full data set:#
  current.matrix$Matrix_1$Weights <- WEIGHTS#
  # Set ordering for full data set:#
  current.matrix$Matrix_1$Ordering <- rep("unord", ncol(current.matrix$Matrix_1$Matrix))#
  # Set maximum values for full data set:#
  current.matrix$Matrix_1$MinVals <- rep(1, ncol(current.matrix$Matrix_1$Matrix))#
  # Set minimum values for full data set:#
  current.matrix$Matrix_1$MaxVals <- rep(0, ncol(current.matrix$Matrix_1$Matrix))#
  # Collapse data set:#
  current.matrix <- CompactifyMatrix(current.matrix)#
  # To avoid non-numeric weight (e.g., 1+e05) set all weights above ten to ten:#
  if(sum(current.matrix$Matrix_1$Weights > 10)) current.matrix$Matrix_1$Weights[which(current.matrix$Matrix_1$Weights > 10)] <- 10#
  # Make file name:#
  file.name <- data.sets[i]#
  # Case if MRP is done (minimum weight is greater than 1):#
  if(min(current.matrix$Matrix_1$Weights) > 1) {#
    # Remove "ROOT" taxon if present:#
    if(sum(rownames(current.matrix$Matrix_1$Matrix) == "ROOT") > 0) current.matrix$Matrix_1$Matrix <- current.matrix$Matrix_1$Matrix[-which(rownames(current.matrix$Matrix_1$Matrix) == "ROOT"), ]#
    # Collapse matrix again:#
    current.matrix <- CompactifyMatrix(current.matrix)#
    # Overwrite all weights with 1:#
    current.matrix$Matrix_1$Weights <- rep(1, length(current.matrix$Matrix_1$Weights))#
    # Update matrix in nesting order (outgroup first):#
    current.matrix$Matrix_1$Matrix <- current.matrix$Matrix_1$Matrix[names(sort(apply(apply(current.matrix$Matrix_1$Matrix, 1, as.numeric), 2, sum))), ]#
    # Isolate MRP taxon names:#
    mrp.names <- rownames(current.matrix$Matrix_1$Matrix)#
    # Isolate full names:#
    nexus.names <- rownames(ReadMorphNexus(paste("/Users/eargtl/Documents/Homepage/www.graemetlloyd.com/nexus/", gsub("mrp", "", file.name), ".nex", sep = ""))$Matrix_1$Matrix)#
    # Check to see if MRP names are contracted:#
    if(length(setdiff(mrp.names, nexus.names)) > 0) {#
      # List all contracted names:#
      contracted.names <- setdiff(mrp.names, nexus.names)#
      # For each contracted name:#
      for(j in 1:length(contracted.names)) {#
        # Get matching full name(s):#
        full.name <- nexus.names[grep(contracted.names[j], nexus.names)]#
        # Check that there are not multiple matches:#
        if(length(full.name) > 1) stop("Multiple names match contracted form. Check manually.")#
        # Overwrite contracted name with full name:#
        rownames(current.matrix$Matrix_1$Matrix)[which(rownames(current.matrix$Matrix_1$Matrix) == contracted.names[j])] <- full.name#
      }#
    }#
    # Write out MRP in #NEXUS format:#
    WriteMorphNexus(current.matrix, paste("/Users/eargtl/Documents/Homepage/www.graemetlloyd.com/mrp", "/", file.name, "mrp.nex", sep = ""))#
    # Remove dead files:#
    file.remove(c(mrp.list[files.to.load], paste(file.name, ".tnt", sep = "")))#
  # Case if MRP needs to continue (minimum weight is 1):#
  } else {#
    # Remove dead files:#
    file.remove(mrp.list[files.to.load])#
    # Write out MRP in #NEXUS format:#
    WriteMorphNexus(current.matrix, paste("/Users/eargtl/", file.name, "mrp_0.nex", sep = ""))#
  }#
  # Output loop position:#
  cat(i, " ")#
}
# NB: Assumes you have already sent an STR version of the data set through the full protocol to completion (min weight greater than zero)#
#
# Load libraries:#
library(Claddis)#
library(metatree)#
#
# Read in target MRP:#
MRP <- ReadMorphNexus("/Users/eargtl/Brocklehurst_etal_2013amrp.nex")#
#
# Read in source NEXUS:#
NEXUS <- ReadMorphNexus("/Users/eargtl/Brocklehurst_etal_2013a.nex")#
#
# Perform STR on NEXUS to get reinsertion list:#
STR <- SafeTaxonomicReduction(NEXUS)#
#
# Order taxa so can reinsert in order of fewest to most senior taxa:#
TaxaInOrder <- rle(sort(STR$str.list[, 1]))$values[order(rle(sort(STR$str.list[, 1]))$lengths)]#
#
# For each taxon to be reinserted:#
for(i in TaxaInOrder) {#
    # Print current loop position:#
    cat(paste("Attempting to reinsert taxon ", which(TaxaInOrder == i), " of ", length(TaxaInOrder), "\n", sep = ""))#
    # Check taxon has not already been reinserted:#
    if(sum(rownames(MRP$Matrix_1$Matrix) == i) == 1) {#
        # Report if found:#
        cat("Taxon already inserted\n")#
    # If not found continue to reinsertion step:#
    } else {#
        # Get senior taxa for current junior:#
        Senior_taxa <- STR$str.list[STR$str.list[, "Junior"] == i, "Senior"]#
        # If there are more than two senior taxa (want to "chunk" the analysis to get around memory issues:#
        if(length(Senior_taxa) > 2) {#
            # Add scores for first senior taxon to MRP matrix as a new row:#
            MRP$Matrix_1$Matrix <- rbind(MRP$Matrix_1$Matrix, MRP$Matrix_1$Matrix[Senior_taxa[1], ])#
            # Give that row the name of the current junior:#
            rownames(MRP$Matrix_1$Matrix)[nrow(MRP$Matrix_1$Matrix)] <- i#
            # Now for each subsequent senior taxon:#
            for(j in 2:length(Senior_taxa)) {#
                # Get new MRP row for current junior:#
                NewMRPRow <- c(MRP$Matrix_1$Matrix[i, ], MRP$Matrix_1$Matrix[Senior_taxa[j], ])#
#
                # Duplicate matrix:#
                DuplicatedMatrix <- matrix(rep(MRP$Matrix_1$Matrix, times = 2), nrow = nrow(MRP$Matrix_1$Matrix), dimnames = list(rownames(MRP$Matrix_1$Matrix), c()))#
                # Update junior with enw row (includes scorings for jth taxon):#
                DuplicatedMatrix[i, ] <- NewMRPRow#
                # Turn into a proper cladistic matrix:#
                DuplicatedMatrix <- MakeMorphMatrix(CTmatrix = DuplicatedMatrix)#
                # Collapse MRP to remove duplicated taxa:#
                DuplicatedMatrix <- MRPCollapse(DuplicatedMatrix)#
                # Overwrite MRP with new matrix:#
                MRP <- DuplicatedMatrix#
            }#
            # Write out new MRP:#
            WriteMorphNexus(MRP, "/Users/eargtl/Arcila_etal_2015abmrp.nex")#
        # If there are only one or two senior taxa (no easy way to chunk the task):#
        } else {#
            # Duplicate matrix for every senior taxon:#
            DuplicatedMatrix <- matrix(rep(MRP$Matrix_1$Matrix, times = length(Senior_taxa)), nrow = nrow(MRP$Matrix_1$Matrix), dimnames = list(rownames(MRP$Matrix_1$Matrix), c()))#
            # Get new MRP row for current junior:#
            NewMRPRow <- as.vector(t(MRP$Matrix_1$Matrix[Senior_taxa, ]))#
            # Add new row to duplicated matrix:#
            DuplicatedMatrix <- rbind(DuplicatedMatrix, NewMRPRow)#
            # Update last row name to current junior:#
            rownames(DuplicatedMatrix)[nrow(DuplicatedMatrix)] <- i#
            # Turn into a proper cladistic matrix:#
            DuplicatedMatrix <- MakeMorphMatrix(CTmatrix = DuplicatedMatrix)#
            # Collapse MRP to remove duplicated taxa:#
            DuplicatedMatrix <- MRPCollapse(DuplicatedMatrix)#
            # Overwrite MRP with new matrix:#
            MRP <- DuplicatedMatrix#
            # Write out new MRP:#
            WriteMorphNexus(MRP, "/Users/eargtl/Arcila_etal_2015abmrp.nex")#
        }#
    }#
}
# NB: Assumes you have already sent an STR version of the data set through the full protocol to completion (min weight greater than zero)#
#
# Load libraries:#
library(Claddis)#
library(metatree)#
#
# Read in target MRP:#
MRP <- ReadMorphNexus("/Users/eargtl/Brocklehurst_etal_2013amrp.nex")#
#
# Read in source NEXUS:#
NEXUS <- ReadMorphNexus("/Users/eargtl/Brocklehurst_etal_2013a.nex")#
#
# Perform STR on NEXUS to get reinsertion list:#
STR <- SafeTaxonomicReduction(NEXUS)#
#
# Order taxa so can reinsert in order of fewest to most senior taxa:#
TaxaInOrder <- rle(sort(STR$str.list[, 1]))$values[order(rle(sort(STR$str.list[, 1]))$lengths)]
TaxaInOrder
names(STR$str.list)
STR$str.list
?MakeMorphMatrix
# NB: Assumes you have already sent an STR version of the data set through the full protocol to completion (min weight greater than zero)#
#
# Load libraries:#
library(Claddis)#
library(metatree)#
#
# Read in target MRP:#
MRP <- ReadMorphNexus("/Users/eargtl/Brocklehurst_etal_2013amrp.nex")#
#
# Read in source NEXUS:#
NEXUS <- ReadMorphNexus("/Users/eargtl/Brocklehurst_etal_2013a.nex")#
#
# Perform STR on NEXUS to get reinsertion list:#
STR <- SafeTaxonomicReduction(NEXUS)#
#
# Order taxa so can reinsert in order of fewest to most senior taxa:#
TaxaInOrder <- rle(sort(STR$str.list[, 1]))$values[order(rle(sort(STR$str.list[, 1]))$lengths)]#
#
# For each taxon to be reinserted:#
for(i in TaxaInOrder) {#
    # Print current loop position:#
    cat(paste("Attempting to reinsert taxon ", which(TaxaInOrder == i), " of ", length(TaxaInOrder), "\n", sep = ""))#
    # Check taxon has not already been reinserted:#
    if(sum(rownames(MRP$Matrix_1$Matrix) == i) == 1) {#
        # Report if found:#
        cat("Taxon already inserted\n")#
    # If not found continue to reinsertion step:#
    } else {#
        # Get senior taxa for current junior:#
        Senior_taxa <- STR$str.list[STR$str.list[, "Junior"] == i, "Senior"]#
        # If there are more than two senior taxa (want to "chunk" the analysis to get around memory issues:#
        if(length(Senior_taxa) > 2) {#
            # Add scores for first senior taxon to MRP matrix as a new row:#
            MRP$Matrix_1$Matrix <- rbind(MRP$Matrix_1$Matrix, MRP$Matrix_1$Matrix[Senior_taxa[1], ])#
            # Give that row the name of the current junior:#
            rownames(MRP$Matrix_1$Matrix)[nrow(MRP$Matrix_1$Matrix)] <- i#
            # Now for each subsequent senior taxon:#
            for(j in 2:length(Senior_taxa)) {#
                # Get new MRP row for current junior:#
                NewMRPRow <- c(MRP$Matrix_1$Matrix[i, ], MRP$Matrix_1$Matrix[Senior_taxa[j], ])#
#
                # Duplicate matrix:#
                DuplicatedMatrix <- matrix(rep(MRP$Matrix_1$Matrix, times = 2), nrow = nrow(MRP$Matrix_1$Matrix), dimnames = list(rownames(MRP$Matrix_1$Matrix), c()))#
                # Update junior with enw row (includes scorings for jth taxon):#
                DuplicatedMatrix[i, ] <- NewMRPRow#
                # Turn into a proper cladistic matrix:#
                DuplicatedMatrix <- MakeMorphMatrix(CharacterTaxonMatrix = DuplicatedMatrix)#
                # Collapse MRP to remove duplicated taxa:#
                DuplicatedMatrix <- MRPCollapse(DuplicatedMatrix)#
                # Overwrite MRP with new matrix:#
                MRP <- DuplicatedMatrix#
            }#
            # Write out new MRP:#
            WriteMorphNexus(MRP, "/Users/eargtl/Arcila_etal_2015abmrp.nex")#
        # If there are only one or two senior taxa (no easy way to chunk the task):#
        } else {#
            # Duplicate matrix for every senior taxon:#
            DuplicatedMatrix <- matrix(rep(MRP$Matrix_1$Matrix, times = length(Senior_taxa)), nrow = nrow(MRP$Matrix_1$Matrix), dimnames = list(rownames(MRP$Matrix_1$Matrix), c()))#
            # Get new MRP row for current junior:#
            NewMRPRow <- as.vector(t(MRP$Matrix_1$Matrix[Senior_taxa, ]))#
            # Add new row to duplicated matrix:#
            DuplicatedMatrix <- rbind(DuplicatedMatrix, NewMRPRow)#
            # Update last row name to current junior:#
            rownames(DuplicatedMatrix)[nrow(DuplicatedMatrix)] <- i#
            # Turn into a proper cladistic matrix:#
            DuplicatedMatrix <- MakeMorphMatrix(CharacterTaxonMatrix = DuplicatedMatrix)#
            # Collapse MRP to remove duplicated taxa:#
            DuplicatedMatrix <- MRPCollapse(DuplicatedMatrix)#
            # Overwrite MRP with new matrix:#
            MRP <- DuplicatedMatrix#
            # Write out new MRP:#
            WriteMorphNexus(MRP, "/Users/eargtl/Arcila_etal_2015abmrp.nex")#
        }#
    }#
}
# NB: Assumes you have already sent an STR version of the data set through the full protocol to completion (min weight greater than zero)#
#
# Load libraries:#
library(Claddis)#
library(metatree)#
#
# Read in target MRP:#
MRP <- ReadMorphNexus("/Users/eargtl/Brocklehurst_etal_2013amrp.nex")#
#
# Read in source NEXUS:#
NEXUS <- ReadMorphNexus("/Users/eargtl/Brocklehurst_etal_2013a.nex")#
#
# Perform STR on NEXUS to get reinsertion list:#
STR <- SafeTaxonomicReduction(NEXUS)#
#
# Order taxa so can reinsert in order of fewest to most senior taxa:#
TaxaInOrder <- rle(sort(STR$str.list[, 1]))$values[order(rle(sort(STR$str.list[, 1]))$lengths)]#
#
# For each taxon to be reinserted:#
for(i in TaxaInOrder) {#
    # Print current loop position:#
    cat(paste("Attempting to reinsert taxon ", which(TaxaInOrder == i), " of ", length(TaxaInOrder), "\n", sep = ""))#
    # Check taxon has not already been reinserted:#
    if(sum(rownames(MRP$Matrix_1$Matrix) == i) == 1) {#
        # Report if found:#
        cat("Taxon already inserted\n")#
    # If not found continue to reinsertion step:#
    } else {#
        # Get senior taxa for current junior:#
        Senior_taxa <- STR$str.list[STR$str.list[, "Junior"] == i, "Senior"]#
        # If there are more than two senior taxa (want to "chunk" the analysis to get around memory issues:#
        if(length(Senior_taxa) > 2) {#
            # Add scores for first senior taxon to MRP matrix as a new row:#
            MRP$Matrix_1$Matrix <- rbind(MRP$Matrix_1$Matrix, MRP$Matrix_1$Matrix[Senior_taxa[1], ])#
            # Give that row the name of the current junior:#
            rownames(MRP$Matrix_1$Matrix)[nrow(MRP$Matrix_1$Matrix)] <- i#
            # Now for each subsequent senior taxon:#
            for(j in 2:length(Senior_taxa)) {#
                # Get new MRP row for current junior:#
                NewMRPRow <- c(MRP$Matrix_1$Matrix[i, ], MRP$Matrix_1$Matrix[Senior_taxa[j], ])#
#
                # Duplicate matrix:#
                DuplicatedMatrix <- matrix(rep(MRP$Matrix_1$Matrix, times = 2), nrow = nrow(MRP$Matrix_1$Matrix), dimnames = list(rownames(MRP$Matrix_1$Matrix), c()))#
                # Update junior with enw row (includes scorings for jth taxon):#
                DuplicatedMatrix[i, ] <- NewMRPRow#
                # Turn into a proper cladistic matrix:#
                DuplicatedMatrix <- MakeMorphMatrix(CharacterTaxonMatrix = DuplicatedMatrix)#
                # Collapse MRP to remove duplicated taxa:#
                DuplicatedMatrix <- MRPCollapse(DuplicatedMatrix)#
                # Overwrite MRP with new matrix:#
                MRP <- DuplicatedMatrix#
            }#
            # Write out new MRP:#
            WriteMorphNexus(MRP, "/Users/eargtl/Brocklehurst_etal_2013amrp.nex")#
        # If there are only one or two senior taxa (no easy way to chunk the task):#
        } else {#
            # Duplicate matrix for every senior taxon:#
            DuplicatedMatrix <- matrix(rep(MRP$Matrix_1$Matrix, times = length(Senior_taxa)), nrow = nrow(MRP$Matrix_1$Matrix), dimnames = list(rownames(MRP$Matrix_1$Matrix), c()))#
            # Get new MRP row for current junior:#
            NewMRPRow <- as.vector(t(MRP$Matrix_1$Matrix[Senior_taxa, ]))#
            # Add new row to duplicated matrix:#
            DuplicatedMatrix <- rbind(DuplicatedMatrix, NewMRPRow)#
            # Update last row name to current junior:#
            rownames(DuplicatedMatrix)[nrow(DuplicatedMatrix)] <- i#
            # Turn into a proper cladistic matrix:#
            DuplicatedMatrix <- MakeMorphMatrix(CharacterTaxonMatrix = DuplicatedMatrix)#
            # Collapse MRP to remove duplicated taxa:#
            DuplicatedMatrix <- MRPCollapse(DuplicatedMatrix)#
            # Overwrite MRP with new matrix:#
            MRP <- DuplicatedMatrix#
            # Write out new MRP:#
            WriteMorphNexus(MRP, "/Users/eargtl/Brocklehurst_etal_2013amrp.nex")#
        }#
    }#
}
library(phytools)
?rerootingMethod
library(metatree)
?metatree
library(Claddis)
MatrixSim1 <- ReadMorphNexus("Library/Containers/com.apple.mail/Data/Library/Mail Downloads/14895B1D-69C6-4B61-9264-87C4EA8343A5/Matrix138t.nex")
MatrixSim1
tree.nexus1<-read.nexus("Library/Containers/com.apple.mail/Data/Library/Mail Downloads/72D676F4-93AD-4521-9BD2-47EC5F919722/MCT_NEXUS_138t.nex")
tree.nexus1
is.rooted(tree.nexus1)#
tree.nexus1$root.time<-322.3#
tree.nexus1$root.time
pcoa_input1<-MorphMatrix2PCoA(MatrixSim1, Distance = "MORD",#
                              TransformDistances = "arcsine_sqrt",#
                              DistPolymorphismBehaviour = "min.difference",#
                              DistUncertaintyBehaviour = "min.difference",#
                              DistInapplicableBehaviour = "missing",#
                              correction = "cailliez",#
                              Tree = tree.nexus1,#
                              EstimateAllNodes = FALSE, EstimateTipValues = FALSE,#
                              Threshold = 0.01)
rownames(MatrixSim1$Matrix_1$Matrix)
GetNodeAges(tree.nexus1)#
tree.nexus1$node.label<-seq(139, 275, 1)#
tree.nexus1$node.label
FileToWorkOn <- "Hartman_etal_2019a"#
#
setwd("~")
system("ls")
FileToWorkOn <- "Hartman_etal_2019a"#
#
setwd("~")#
TNTCommands <- c("N=$1", "(", "for j in $(seq 0 $2); do", "((i=i%N)); ((i++==0)) && wait", "tnt mxram 1024, log tnt_log.$j.txt, run mymatrix.tnt, echo= , timeout 24:00:00, rseed0, rseed*,hold 1000,xmult= level 10, taxname=, tsave *trees_tnt.$j.tnt, save, tsave / , scores, log / , quit &", "done", ")")#
#
write(TNTCommands, "TNTCommands")
"tnt mxram 1024, log tnt_log.$j.txt, run mymatrix.tnt, echo= , timeout 24:00:00, rseed0, rseed*,hold 1000,xmult= level 10, taxname=, tsave *trees_tnt.$j.tnt, save, tsave / , scores, log / , quit &"
paste("tnt mxram 1024, log tnt_log.$j.txt, run ", FileToWorkOn, ".tnt, echo= , timeout 24:00:00, rseed0, rseed*,hold 1000,xmult= level 10, taxname=, tsave *trees_tnt.$j.tnt, save, tsave / , scores, log / , quit &", sep = "")
FileToWorkOn <- "Hartman_etal_2019a"#
#
setwd("~")#
#
TNTCommands <- c("N=$1", "(", "for j in $(seq 0 $2); do", "((i=i%N)); ((i++==0)) && wait", paste("tnt mxram 1024, log tnt_log.$j.txt, run ", FileToWorkOn, ".tnt, echo= , timeout 24:00:00, rseed0, rseed*,hold 1000,xmult= level 10, taxname=, tsave *trees_tnt.$j.tnt, save, tsave / , scores, log / , quit &", sep = ""), "done", ")")#
#
write(TNTCommands, "TNTCommands")
paste("~/Documents/Homepage/www.graemetlloyd.com/nexus/", FileToWorkOn, ".nex")
paste("~/Documents/Homepage/www.graemetlloyd.com/nexus/", FileToWorkOn, ".nex", sep = "")
paste(FileToWorkOn, ".tnt", sep = "")
library(Claddis)#
#
setwd("~")#
#
NEXUS <- Claddis::ReadMorphNexus(paste("~/Documents/Homepage/www.graemetlloyd.com/nexus/", FileToWorkOn, ".nex", sep = ""))#
#
Claddis::WriteMorphTNT(NEXUS, paste(FileToWorkOn, ".tnt", sep = ""))#
#
TNTCommands <- c("N=$1", "(", "for j in $(seq 0 $2); do", "((i=i%N)); ((i++==0)) && wait", paste("tnt mxram 1024, log tnt_log.$j.txt, run ", FileToWorkOn, ".tnt, echo= , timeout 24:00:00, rseed0, rseed*,hold 1000,xmult= level 10, taxname=, tsave *trees_tnt.$j.tnt, save, tsave / , scores, log / , quit &", sep = ""), "done", ")")#
#
write(TNTCommands, "TNTCommands")#
#
system("TNTCommands 2 2")
FileToWorkOn <- "Hartman_etal_2019a"#
#
library(Claddis)#
#
setwd("~")#
#
NEXUS <- Claddis::ReadMorphNexus(paste("~/Documents/Homepage/www.graemetlloyd.com/nexus/", FileToWorkOn, ".nex", sep = ""))#
#
Claddis::WriteMorphTNT(NEXUS, paste(FileToWorkOn, ".tnt", sep = ""))#
#
TNTCommands <- c("N=$1", "(", "for j in $(seq 0 $2); do", "((i=i%N)); ((i++==0)) && wait", paste("tnt mxram 1024, log tnt_log.$j.txt, run ", FileToWorkOn, ".tnt, echo= , timeout 24:00:00, rseed0, rseed*,hold 1000,xmult= level 10, taxname=, tsave *trees_tnt.$j.tnt, save, tsave / , scores, log / , quit &", sep = ""), "done", ")")#
#
write(TNTCommands, "TNTCommands")#
#
system("/Users/eargtl/TNTCommands 2 2")
system("bash /Users/eargtl/TNTCommands 2 2")
paste("bash /Users/eargtl/TNTCommands, NCores, NCores)
system("quit;")
14,210,141,297
system("quit;")
# Set file to work on:#
FileToWorkOn <- "Hartman_etal_2019a"#
#
# Set number of cores to use:#
NCores <- 4#
#
# Load Claddis library:#
library(Claddis)#
#
# Set working directory to user directory:#
setwd("~")#
#
# Read in NEXUS file:#
NEXUS <- Claddis::ReadMorphNexus(paste("~/Documents/Homepage/www.graemetlloyd.com/nexus/", FileToWorkOn, ".nex", sep = ""))#
#
# Write to user directory as TNT file:#
Claddis::WriteMorphTNT(NEXUS, paste(FileToWorkOn, ".tnt", sep = ""))#
#
# Build a TNT commands bash file (text):#
TNTCommands <- c("N=$1", "(", "for j in $(seq 0 $2); do", "((i=i%N)); ((i++==0)) && wait", paste("tnt mxram 1024, log tnt_log.$j.txt, run ", FileToWorkOn, ".tnt, echo= , timeout 24:00:00, rseed0, rseed*,hold 1000,xmult= level 10, taxname=, tsave *trees_tnt.$j.tnt, save, tsave / , scores, log / , quit &", sep = ""), "done", ")")#
#
# Write bash commands to user directory:#
write(TNTCommands, "TNTCommands")#
#
paste("bash /Users/eargtl/TNTCommands", NCores, NCores)
# Set file to work on:#
FileToWorkOn <- "Hartman_etal_2019a"#
#
# Set number of cores to use:#
NCores <- 4#
#
# Load Claddis library:#
library(Claddis)#
#
# Set working directory to user directory:#
setwd("~")#
#
# Read in NEXUS file:#
NEXUS <- Claddis::ReadMorphNexus(paste("~/Documents/Homepage/www.graemetlloyd.com/nexus/", FileToWorkOn, ".nex", sep = ""))#
#
# Write to user directory as TNT file:#
Claddis::WriteMorphTNT(NEXUS, paste(FileToWorkOn, ".tnt", sep = ""))#
#
# Build a TNT commands bash file (text):#
TNTCommands <- c("N=$1", "(", "for j in $(seq 0 $2); do", "((i=i%N)); ((i++==0)) && wait", paste("tnt mxram 1024, log tnt_log.$j.txt, run ", FileToWorkOn, ".tnt, echo= , timeout 24:00:00, rseed0, rseed*,hold 1000,xmult= level 10, taxname=, tsave *trees_tnt.$j.tnt, save, tsave / , scores, log / , quit &", sep = ""), "done", ")")#
#
# Write bash commands to user directory:#
write(TNTCommands, "TNTCommands")#
#
##
system(paste("bash /Users/eargtl/TNTCommands", NCores, NCores))
y
list.files()
grep("tnt_log", list.files())
list.files()[grep("tnt_log", list.files())]
TreesFiles <- list.files()[grep("trees_tnt", list.files())]
TreesFiles
# Set file to work on:#
FileToWorkOn <- "Hartman_etal_2019a"#
#
# Set number of cores to use:#
NCores <- 2#
#
# Load Claddis library:#
library(Claddis)#
#
# Set working directory to user directory:#
setwd("~")#
#
# Read in NEXUS file:#
NEXUS <- Claddis::ReadMorphNexus(paste("~/Documents/Homepage/www.graemetlloyd.com/nexus/", FileToWorkOn, ".nex", sep = ""))#
#
# Write to user directory as TNT file:#
Claddis::WriteMorphTNT(NEXUS, paste(FileToWorkOn, ".tnt", sep = ""))#
#
# Build a TNT commands bash file (text):#
TNTCommands <- c("N=$1", "(", "for j in $(seq 0 $2); do", "((i=i%N)); ((i++==0)) && wait", paste("tnt mxram 1024, log tnt_log.$j.txt, run ", FileToWorkOn, ".tnt, echo= , timeout 24:00:00, rseed0, rseed*,hold 1000,xmult= level 10, taxname=, tsave *trees_tnt.$j.tnt, save, tsave / , scores, log / , quit &", sep = ""), "done", ")")#
#
# Write bash commands to user directory:#
write(TNTCommands, "TNTCommands")#
#
# Execute TNTCommands in terminal:#
system(paste("bash /Users/eargtl/TNTCommands", NCores, NCores))#
LogFiles <- list.files()[grep("tnt_log", list.files())]#
#
TreesFiles <- list.files()[grep("trees_tnt", list.files())]
y
# Set file to work on:#
FileToWorkOn <- "Hartman_etal_2019a"#
#
# Set number of cores to use:#
NCores <- 2#
#
# Load Claddis library:#
library(Claddis)#
#
# Set working directory to user directory:#
setwd("~")#
#
# Read in NEXUS file:#
NEXUS <- Claddis::ReadMorphNexus(paste("~/Documents/Homepage/www.graemetlloyd.com/nexus/", FileToWorkOn, ".nex", sep = ""))#
#
# Write to user directory as TNT file:#
Claddis::WriteMorphTNT(NEXUS, paste(FileToWorkOn, ".tnt", sep = ""))#
#
# Build a TNT commands bash file (text):#
TNTCommands <- c("N=$1", "(", "for j in $(seq 0 $2); do", "((i=i%N)); ((i++==0)) && wait", paste("tnt mxram 1024, log tnt_log.$j.txt, run ", FileToWorkOn, ".tnt, echo= , timeout 24:00:00, rseed0, rseed*,hold 1000,xmult= level 10, taxname=, tsave *trees_tnt.$j.tnt, save, tsave / , scores, log / , quit &", sep = ""), "done", ")")#
#
# Write bash commands to user directory:#
write(TNTCommands, "TNTCommands")#
#
# Execute TNTCommands in terminal:#
system(paste("bash /Users/eargtl/TNTCommands", NCores, NCores))#
LogFiles <- list.files()[grep("tnt_log", list.files())]#
#
TreesFiles <- list.files()[grep("trees_tnt", list.files())]
y
y#
y
y#
y#
y
y#
y#
y#
y
y#
y#
y#
y#
y
y#
y#
y#
y#
y#
y
y#
y#
y#
y#
y#
y#
y
y#
y#
y#
y#
y#
y#
y#
y
y#
y#
y#
y#
y#
y#
y#
y#
y
y#
y#
y#
y#
y#
y#
y#
y#
y#
y
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
y#
I agree
?system
# Set file to work on:#
FileToWorkOn <- "Hartman_etal_2019a"#
#
# Set number of cores to use:#
NCores <- 2#
#
# Load Claddis library:#
library(Claddis)#
#
# Set working directory to user directory:#
setwd("~")#
#
# Read in NEXUS file:#
NEXUS <- Claddis::ReadMorphNexus(paste("~/Documents/Homepage/www.graemetlloyd.com/nexus/", FileToWorkOn, ".nex", sep = ""))#
#
# Write to user directory as TNT file:#
Claddis::WriteMorphTNT(NEXUS, paste(FileToWorkOn, ".tnt", sep = ""))#
#
# Build a TNT commands bash file (text):#
TNTCommands <- c("N=$1", "(", "for j in $(seq 0 $2); do", "((i=i%N)); ((i++==0)) && wait", paste("tnt mxram 1024, log tnt_log.$j.txt, run ", FileToWorkOn, ".tnt, echo= , timeout 24:00:00, rseed0, rseed*,hold 1000,xmult= level 10, taxname=, tsave *trees_tnt.$j.tnt, save, tsave / , scores, log / , quit &", sep = ""), "done", ")")#
#
# Write bash commands to user directory:#
write(TNTCommands, "TNTCommands")#
#
# Execute TNTCommands in terminal:#
system2(paste("bash /Users/eargtl/TNTCommands", NCores, NCores))#
LogFiles <- list.files()[grep("tnt_log", list.files())]#
#
TreesFiles <- list.files()[grep("trees_tnt", list.files())]
?system2
paste("bash /Users/eargtl/TNTCommands", NCores, NCores)
system2(paste("bash /Users/eargtl/TNTCommands", NCores, NCores))
list.files()
# Set file to work on:#
FileToWorkOn <- "Hartman_etal_2019a"#
#
# Set number of cores to use:#
NCores <- 2#
#
# Load Claddis library:#
library(Claddis)#
#
# Set working directory to user directory:#
setwd("~")#
#
# Read in NEXUS file:#
NEXUS <- Claddis::ReadMorphNexus(paste("~/Documents/Homepage/www.graemetlloyd.com/nexus/", FileToWorkOn, ".nex", sep = ""))#
#
# Write to user directory as TNT file:#
Claddis::WriteMorphTNT(NEXUS, paste(FileToWorkOn, ".tnt", sep = ""))#
#
# Build a TNT commands bash file (text):#
TNTCommands <- c("N=$1", "(", "for j in $(seq 0 $2); do", "((i=i%N)); ((i++==0)) && wait", paste("tnt mxram 1024, log tnt_log.$j.txt, run ", FileToWorkOn, ".tnt, echo= , timeout 24:00:00, rseed0, rseed*,hold 1000,xmult= level 10, taxname=, tsave *trees_tnt.$j.tnt, save, tsave / , scores, log / , quit &", sep = ""), "done", ")")#
#
# Write bash commands to user directory:#
write(TNTCommands, "TNTCommands")
system2(paste("bash /Users/eargtl/TNTCommands", NCores, NCores))
system(paste("bash /Users/eargtl/TNTCommands", NCores, NCores))
LogFiles <- list.files()[grep("tnt_log", list.files())]#
#
TreesFiles <- list.files()[grep("trees_tnt", list.files())]
LogFiles
TreesFiles
TreeFiles <- list.files()[grep("trees_tnt", list.files())]
TreeFiles
# Set file to work on:#
FileToWorkOn <- "Hartman_etal_2019a"#
#
# Set number of cores to use:#
NCores <- 2#
#
# Load Claddis library:#
library(Claddis)#
#
# Set working directory to user directory:#
setwd("~")#
#
# Read in NEXUS file:#
NEXUS <- Claddis::ReadMorphNexus(paste("~/Documents/Homepage/www.graemetlloyd.com/nexus/", FileToWorkOn, ".nex", sep = ""))#
#
# Write to user directory as TNT file:#
Claddis::WriteMorphTNT(NEXUS, paste(FileToWorkOn, ".tnt", sep = ""))#
#
# Build a TNT commands bash file (text):#
TNTCommands <- c("N=$1", "(", "for j in $(seq 0 $2); do", "((i=i%N)); ((i++==0)) && wait", paste("tnt mxram 1024, log tnt_log.$j.txt, run ", FileToWorkOn, ".tnt, echo= , timeout 24:00:00, rseed0, rseed*,hold 1000,xmult= level 10, taxname=, tsave *trees_tnt.$j.tnt, save, tsave / , scores, log / , quit &", sep = ""), "done", ")")#
#
# Write bash commands to user directory:#
write(TNTCommands, "TNTCommands")#
#
# Execute TNTCommands in terminal:#
system(paste("bash /Users/eargtl/TNTCommands", NCores, NCores))#
LogFiles <- list.files()[grep("tnt_log", list.files())]#
#
TreeFiles <- list.files()[grep("trees_tnt", list.files())]
COMMAND: TSAVE#
COMMAND: QUIT                                                                  #
Stuff
?system
# Set file to work on:#
FileToWorkOn <- "Hartman_etal_2019a"#
#
# Set number of cores to use:#
NCores <- 2#
#
# Load Claddis library:#
library(Claddis)#
#
# Set working directory to user directory:#
setwd("~")#
#
# Read in NEXUS file:#
NEXUS <- Claddis::ReadMorphNexus(paste("~/Documents/Homepage/www.graemetlloyd.com/nexus/", FileToWorkOn, ".nex", sep = ""))#
#
# Write to user directory as TNT file:#
Claddis::WriteMorphTNT(NEXUS, paste(FileToWorkOn, ".tnt", sep = ""))#
#
# Build a TNT commands bash file (text):#
TNTCommands <- c("N=$1", "(", "for j in $(seq 0 $2); do", "((i=i%N)); ((i++==0)) && wait", paste("tnt mxram 1024, log tnt_log.$j.txt, run ", FileToWorkOn, ".tnt, echo= , timeout 24:00:00, rseed0, rseed*,hold 1000,xmult= level 10, taxname=, tsave *trees_tnt.$j.tnt, save, tsave / , scores, log / , quit &", sep = ""), "done", ")")#
#
# Write bash commands to user directory:#
write(TNTCommands, "TNTCommands")#
#
# Execute TNTCommands in terminal:#
x <- system(paste("bash /Users/eargtl/TNTCommands", NCores - 1, NCores))#
LogFiles <- list.files()[grep("tnt_log", list.files())]#
#
TreeFiles <- list.files()[grep("trees_tnt", list.files())]
MRPDirectory <- "~/Dropbox/Mammal_Supertree/Primates/GraemeVersion/MRP" # MRP file directory#
XMLDirectory <- "~/Dropbox/Mammal_Supertree/Primates/GraemeVersion/XML" # XML file directory#
TargetClade <- "Primates"#
InclusiveDataList <- c()#
ExclusiveDataList <- c("Andrews_1988a", "Gebo_etal_2001a", "Averianov_inpressa", "Bravo_et_Gaete_2015a", "Brocklehurst_etal_2013a", "Brocklehurst_etal_2015aa", "Brocklehurst_etal_2015ab", "Brocklehurst_etal_2015ac", "Brocklehurst_etal_2015ad", "Brocklehurst_etal_2015ae", "Brocklehurst_etal_2015af", "Bronzati_etal_2012a", "Bronzati_etal_2015ab", "Brusatte_etal_2009ba", "Campbell_etal_2016ab", "Carr_et_Williamson_2004a", "Carr_etal_2017ab", "Frederickson_et_Tumarkin-Deratzian_2014aa", "Frederickson_et_Tumarkin-Deratzian_2014ab", "Frederickson_et_Tumarkin-Deratzian_2014ac", "Frederickson_et_Tumarkin-Deratzian_2014ad", "Garcia_etal_2006a", "Gatesy_etal_2004ab", "Grellet-Tinner_2006a", "Grellet-Tinner_et_Chiappe_2004a", "Grellet-Tinner_et_Makovicky_2006a", "Knoll_2008a", "Kurochkin_1996a", "Lopez-Martinez_et_Vicens_2012a", "Lu_etal_2014aa", "Norden_etal_inpressa", "Pisani_etal_2002a", "Ruiz-Omenaca_etal_1997a", "Ruta_etal_2003ba", "Ruta_etal_2003bb", "Ruta_etal_2007a", "Selles_et_Galobart_2016a", "Sereno_1993a",
"Sidor_2001a", "Skutschas_etal_inpressa", "Tanaka_etal_2011a", "Toljagic_et_Butler_2013a", "Tsuihiji_etal_2011aa", "Varricchio_et_Jackson_2004a", "Vila_etal_2017a", "Wilson_2005aa", "Wilson_2005ab", "Zelenitsky_et_Therrien_2008a")#
HigherTaxaToCollapse = c()#
SpeciesToExclude = c()#
MissingSpecies = "exclude"#
Interval = NULL#
VeilLine = TRUE#
IncludeSpecimenLevelOTUs = TRUE#
BackboneConstraint = NULL#
MonophylyConstraint = NULL#
RelativeWeights = c(0, 100, 10, 1)#
WeightCombination = "sum"#
ReportContradictionsToScreen = FALSE#
#
Primates <- Metatree(MRPDirectory = MRPDirectory, XMLDirectory = XMLDirectory, TargetClade = TargetClade, InclusiveDataList = c(), ExclusiveDataList = ExclusiveDataList, HigherTaxaToCollapse = HigherTaxaToCollapse, SpeciesToExclude = SpeciesToExclude, MissingSpecies = MissingSpecies, Interval = Interval, VeilLine = VeilLine, IncludeSpecimenLevelOTUs = IncludeSpecimenLevelOTUs, BackboneConstraint = BackboneConstraint, MonophylyConstraint = MonophylyConstraint, RelativeWeights = RelativeWeights, WeightCombination = WeightCombination, ReportContradictionsToScreen = ReportContradictionsToScreen)
# Load metatree library:#
library(metatree)
HypothesisOneSTRMPT <- readLines("~/HypothesisOneSTRMPTs.nex")
HypothesisOneSTRMPT)
HypothesisOneSTRMPT
HypothesisOneSTRMPT[unlist(lapply(strsplit(HypothesisOneSTRMPT, ""), function(x) x[1] == "("))]
HypothesisOneSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisOneSTRMPTs[unlist(lapply(strsplit(HypothesisOneSTRMPTs, ""), function(x) x[1] == "("))]))
HypothesisOneSTRMPTs <- readLines("~/HypothesisOneSTRMPTs.nex")
HypothesisOneSTRMPTs <- readLines("~/HypothesisOneSTRMPTs.nex", warn = FALSE)
HypothesisOneSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisOneSTRMPTs[unlist(lapply(strsplit(HypothesisOneSTRMPTs, ""), function(x) x[1] == "("))]))
HypothesisOneSTRMPTs <- unlist(lapply(strsplit(HypothesisOneSTRMPTs, ""), function(x) x[1] == "("))
unlist(lapply(strsplit(HypothesisOneSTRMPTs, ""), function(x) x[1] == "("))
lapply(strsplit(HypothesisOneSTRMPTs, ""), function(x) x[1] == "(")
HypothesisOneSTRMPTs <- readLines("~/HypothesisOneSTRMPTs.nex", warn = FALSE)
lapply(strsplit(HypothesisOneSTRMPTs, ""), function(x) x[1] == "(")
which(unlist(lapply(strsplit(HypothesisOneSTRMPTs, ""), function(x) x[1] == "(")))
HypothesisOneSTRMPTs <- readLines("~/HypothesisOneSTRMPTs.nex", warn = FALSE)
HypothesisOneSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisOneSTRMPTs[which(unlist(lapply(strsplit(HypothesisOneSTRMPTs, ""), function(x) x[1] == "(")))]))
HypothesisOneSTRMPTs
HypothesisOneSTRMPTs[[1]]
plot(HypothesisOneSTRMPTs[[1]], cex = 0.3)
# Load metatree library:#
library(metatree)#
HypothesisOneSTRMPTs <- readLines("~/HypothesisOneSTRMPTs.nex", warn = FALSE)#
HypothesisTwoSTRMPTs <- readLines("~/HypothesisTwoSTRMPTs.nex", warn = FALSE)#
HypothesisThreeSTRMPTs <- readLines("~/HypothesisThreeSTRMPTs.nex", warn = FALSE)#
HypothesisFourSTRMPTs <- readLines("~/HypothesisFourSTRMPTs.nex", warn = FALSE)#
HypothesisFiveSTRMPTs <- readLines("~/HypothesisFiveSTRMPTs.nex", warn = FALSE)#
HypothesisSixSTRMPTs <- readLines("~/HypothesisSixSTRMPTs.nex", warn = FALSE)#
HypothesisOneSTRMPTs <- ape::ladderize(ape::read.tree(text = gsub(" ", "", HypothesisOneSTRMPTs[which(unlist(lapply(strsplit(HypothesisOneSTRMPTs, ""), function(x) x[1] == "(")))])))#
HypothesisTwoSTRMPTs <- ape::ladderize(ape::read.tree(text = gsub(" ", "", HypothesisTwoSTRMPTs[which(unlist(lapply(strsplit(HypothesisTwoSTRMPTs, ""), function(x) x[1] == "(")))])))#
HypothesisThreeSTRMPTs <- ape::ladderize(ape::read.tree(text = gsub(" ", "", HypothesisThreeSTRMPTs[which(unlist(lapply(strsplit(HypothesisThreeSTRMPTs, ""), function(x) x[1] == "(")))])))#
HypothesisFourSTRMPTs <- ape::ladderize(ape::read.tree(text = gsub(" ", "", HypothesisFourSTRMPTs[which(unlist(lapply(strsplit(HypothesisFourSTRMPTs, ""), function(x) x[1] == "(")))])))#
HypothesisFiveSTRMPTs <- ape::ladderize(ape::read.tree(text = gsub(" ", "", HypothesisFiveSTRMPTs[which(unlist(lapply(strsplit(HypothesisFiveSTRMPTs, ""), function(x) x[1] == "(")))])))#
HypothesisSixSTRMPTs <- ape::ladderize(ape::read.tree(text = gsub(" ", "", HypothesisSixSTRMPTs[which(unlist(lapply(strsplit(HypothesisSixSTRMPTs, ""), function(x) x[1] == "(")))])))
HypothesisOneSTRMPTs <- readLines("~/HypothesisOneSTRMPTs.nex", warn = FALSE)
ape::ladderize(ape::read.tree(text = gsub(" ", "", HypothesisOneSTRMPTs[which(unlist(lapply(strsplit(HypothesisOneSTRMPTs, ""), function(x) x[1] == "(")))])))
x <- gsub(" ", "", HypothesisOneSTRMPTs[which(unlist(lapply(strsplit(HypothesisOneSTRMPTs, ""), function(x) x[1] == "(")))])
x
ape::read.tree(text = gsub(" ", "", HypothesisOneSTRMPTs[which(unlist(lapply(strsplit(HypothesisOneSTRMPTs, ""), function(x) x[1] == "(")))]))
HypothesisOneSTRMPTs <- readLines("~/HypothesisOneSTRMPTs.nex", warn = FALSE)#
HypothesisTwoSTRMPTs <- readLines("~/HypothesisTwoSTRMPTs.nex", warn = FALSE)#
HypothesisThreeSTRMPTs <- readLines("~/HypothesisThreeSTRMPTs.nex", warn = FALSE)#
HypothesisFourSTRMPTs <- readLines("~/HypothesisFourSTRMPTs.nex", warn = FALSE)#
HypothesisFiveSTRMPTs <- readLines("~/HypothesisFiveSTRMPTs.nex", warn = FALSE)#
HypothesisSixSTRMPTs <- readLines("~/HypothesisSixSTRMPTs.nex", warn = FALSE)#
HypothesisOneSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisOneSTRMPTs[which(unlist(lapply(strsplit(HypothesisOneSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisTwoSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisTwoSTRMPTs[which(unlist(lapply(strsplit(HypothesisTwoSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisThreeSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisThreeSTRMPTs[which(unlist(lapply(strsplit(HypothesisThreeSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisFourSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisFourSTRMPTs[which(unlist(lapply(strsplit(HypothesisFourSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisFiveSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisFiveSTRMPTs[which(unlist(lapply(strsplit(HypothesisFiveSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisSixSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisSixSTRMPTs[which(unlist(lapply(strsplit(HypothesisSixSTRMPTs, ""), function(x) x[1] == "(")))]))#
#
# MAKE PROPER NEWICKS#
# STR resinsertion#
# WRITE TO FOLDERS#
# PRUNE ALLZERO?
?ladderize
# Load metatree library:#
library(metatree)#
#
##
HypothesisOneSTRMPTs <- readLines("~/HypothesisOneSTRMPTs.nex", warn = FALSE)#
HypothesisTwoSTRMPTs <- readLines("~/HypothesisTwoSTRMPTs.nex", warn = FALSE)#
HypothesisThreeSTRMPTs <- readLines("~/HypothesisThreeSTRMPTs.nex", warn = FALSE)#
HypothesisFourSTRMPTs <- readLines("~/HypothesisFourSTRMPTs.nex", warn = FALSE)#
HypothesisFiveSTRMPTs <- readLines("~/HypothesisFiveSTRMPTs.nex", warn = FALSE)#
HypothesisSixSTRMPTs <- readLines("~/HypothesisSixSTRMPTs.nex", warn = FALSE)#
#
##
HypothesisOneSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisOneSTRMPTs[which(unlist(lapply(strsplit(HypothesisOneSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisTwoSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisTwoSTRMPTs[which(unlist(lapply(strsplit(HypothesisTwoSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisThreeSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisThreeSTRMPTs[which(unlist(lapply(strsplit(HypothesisThreeSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisFourSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisFourSTRMPTs[which(unlist(lapply(strsplit(HypothesisFourSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisFiveSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisFiveSTRMPTs[which(unlist(lapply(strsplit(HypothesisFiveSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisSixSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisSixSTRMPTs[which(unlist(lapply(strsplit(HypothesisSixSTRMPTs, ""), function(x) x[1] == "(")))]))#
#
##
write.tree(HypothesisOneSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/Trees/STRTrees.tre")#
write.tree(HypothesisTwoSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/Trees/STRTrees.tre")#
write.tree(HypothesisThreeSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/Trees/STRTrees.tre")#
write.tree(HypothesisFourSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/Trees/STRTrees.tre")#
write.tree(HypothesisFiveSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/Trees/STRTrees.tre")#
write.tree(HypothesisSixSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/Trees/STRTrees.tre")
read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MetatreeFiles/STR.txt")
read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MetatreeFiles/STR.txt", header = TRUE)
read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)
?SafeTaxonomicReinsertion
HypothesisOneSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/Trees/FullTrees.tre", str.list = HypothesisOneSTRTable, multi.placements = "random")
# Load metatree library:#
library(metatree)#
#
##
HypothesisOneSTRMPTs <- readLines("~/HypothesisOneSTRMPTs.nex", warn = FALSE)#
HypothesisTwoSTRMPTs <- readLines("~/HypothesisTwoSTRMPTs.nex", warn = FALSE)#
HypothesisThreeSTRMPTs <- readLines("~/HypothesisThreeSTRMPTs.nex", warn = FALSE)#
HypothesisFourSTRMPTs <- readLines("~/HypothesisFourSTRMPTs.nex", warn = FALSE)#
HypothesisFiveSTRMPTs <- readLines("~/HypothesisFiveSTRMPTs.nex", warn = FALSE)#
HypothesisSixSTRMPTs <- readLines("~/HypothesisSixSTRMPTs.nex", warn = FALSE)#
#
##
HypothesisOneSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisOneSTRMPTs[which(unlist(lapply(strsplit(HypothesisOneSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisTwoSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisTwoSTRMPTs[which(unlist(lapply(strsplit(HypothesisTwoSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisThreeSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisThreeSTRMPTs[which(unlist(lapply(strsplit(HypothesisThreeSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisFourSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisFourSTRMPTs[which(unlist(lapply(strsplit(HypothesisFourSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisFiveSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisFiveSTRMPTs[which(unlist(lapply(strsplit(HypothesisFiveSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisSixSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisSixSTRMPTs[which(unlist(lapply(strsplit(HypothesisSixSTRMPTs, ""), function(x) x[1] == "(")))]))#
#
##
write.tree(HypothesisOneSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/Trees/STRTrees.tre")#
write.tree(HypothesisTwoSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/Trees/STRTrees.tre")#
write.tree(HypothesisThreeSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/Trees/STRTrees.tre")#
write.tree(HypothesisFourSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/Trees/STRTrees.tre")#
write.tree(HypothesisFiveSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/Trees/STRTrees.tre")#
write.tree(HypothesisSixSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/Trees/STRTrees.tre")#
#
##
HypothesisOneSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
HypothesisTwoSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
HypothesisThreeSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
HypothesisFourSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
HypothesisFiveSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
HypothesisSixSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
#
##
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/Trees/FullTrees.tre", str.list = HypothesisOneSTRTable, multi.placements = "random")#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/Trees/FullTrees.tre", str.list = HypothesisTwoSTRTable, multi.placements = "random")#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/Trees/FullTrees.tre", str.list = HypothesisThreeSTRTable, multi.placements = "random")#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/Trees/FullTrees.tre", str.list = HypothesisFourSTRTable, multi.placements = "random")#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/Trees/FullTrees.tre", str.list = HypothesisFiveSTRTable, multi.placements = "random")#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/Trees/FullTrees.tre", str.list = HypothesisSixSTRTable, multi.placements = "random")
# Load metatree library:#
library(metatree)#
#
# Read in TNT tree output:#
HypothesisOneSTRMPTs <- readLines("~/HypothesisOneSTRMPTs.nex", warn = FALSE)#
HypothesisTwoSTRMPTs <- readLines("~/HypothesisTwoSTRMPTs.nex", warn = FALSE)#
HypothesisThreeSTRMPTs <- readLines("~/HypothesisThreeSTRMPTs.nex", warn = FALSE)#
HypothesisFourSTRMPTs <- readLines("~/HypothesisFourSTRMPTs.nex", warn = FALSE)#
HypothesisFiveSTRMPTs <- readLines("~/HypothesisFiveSTRMPTs.nex", warn = FALSE)#
HypothesisSixSTRMPTs <- readLines("~/HypothesisSixSTRMPTs.nex", warn = FALSE)#
#
# Isolate and reformat trees as ape trees:#
HypothesisOneSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisOneSTRMPTs[which(unlist(lapply(strsplit(HypothesisOneSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisTwoSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisTwoSTRMPTs[which(unlist(lapply(strsplit(HypothesisTwoSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisThreeSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisThreeSTRMPTs[which(unlist(lapply(strsplit(HypothesisThreeSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisFourSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisFourSTRMPTs[which(unlist(lapply(strsplit(HypothesisFourSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisFiveSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisFiveSTRMPTs[which(unlist(lapply(strsplit(HypothesisFiveSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisSixSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisSixSTRMPTs[which(unlist(lapply(strsplit(HypothesisSixSTRMPTs, ""), function(x) x[1] == "(")))]))#
#
# Write STR trees to file:#
write.tree(HypothesisOneSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/Trees/STRTrees.tre")#
write.tree(HypothesisTwoSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/Trees/STRTrees.tre")#
write.tree(HypothesisThreeSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/Trees/STRTrees.tre")#
write.tree(HypothesisFourSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/Trees/STRTrees.tre")#
write.tree(HypothesisFiveSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/Trees/STRTrees.tre")#
write.tree(HypothesisSixSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/Trees/STRTrees.tre")#
#
# Read in STR tables:#
HypothesisOneSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
HypothesisTwoSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
HypothesisThreeSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
HypothesisFourSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
HypothesisFiveSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
HypothesisSixSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
#
# Dafely reinsert the missing taxa to generate full trees:#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/Trees/FullTrees.tre", str.list = HypothesisOneSTRTable, multi.placements = "random")#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/Trees/FullTrees.tre", str.list = HypothesisTwoSTRTable, multi.placements = "random")#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/Trees/FullTrees.tre", str.list = HypothesisThreeSTRTable, multi.placements = "random")#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/Trees/FullTrees.tre", str.list = HypothesisFourSTRTable, multi.placements = "random")#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/Trees/FullTrees.tre", str.list = HypothesisFiveSTRTable, multi.placements = "random")#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/Trees/FullTrees.tre", str.list = HypothesisSixSTRTable, multi.placements = "random")#
#
##
HypothesisOneFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/Trees/FullTrees.tre")#
HypothesisTwoFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/Trees/FullTrees.tre")#
HypothesisThreeFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/Trees/FullTrees.tre")#
HypothesisFourFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/Trees/FullTrees.tre")#
HypothesisFiveFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/Trees/FullTrees.tre")#
HypothesisSixFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/Trees/FullTrees.tre")
HypothesisOneFullMPTs
lapply(HypothesisOneFullMPTs, function(x) ape::ladderize(x, right = FALSE)
HypothesisOneFullMPTs <- lapply(HypothesisOneFullMPTs, function(x) ape::ladderize(x, right = FALSE))#
HypothesisTwoFullMPTs <- lapply(HypothesisTwoFullMPTs, function(x) ape::ladderize(x, right = FALSE))#
HypothesisThreeFullMPTs <- lapply(HypothesisThreeFullMPTs, function(x) ape::ladderize(x, right = FALSE))#
HypothesisFourFullMPTs <- lapply(HypothesisFourFullMPTs, function(x) ape::ladderize(x, right = FALSE))#
HypothesisFiveFullMPTs <- lapply(HypothesisFiveFullMPTs, function(x) ape::ladderize(x, right = FALSE))#
HypothesisSixFullMPTs <- lapply(HypothesisSixFullMPTs, function(x) ape::ladderize(x, right = FALSE))
# Load metatree library:#
library(metatree)#
#
# Read in TNT tree output:#
HypothesisOneSTRMPTs <- readLines("~/HypothesisOneSTRMPTs.nex", warn = FALSE)#
HypothesisTwoSTRMPTs <- readLines("~/HypothesisTwoSTRMPTs.nex", warn = FALSE)#
HypothesisThreeSTRMPTs <- readLines("~/HypothesisThreeSTRMPTs.nex", warn = FALSE)#
HypothesisFourSTRMPTs <- readLines("~/HypothesisFourSTRMPTs.nex", warn = FALSE)#
HypothesisFiveSTRMPTs <- readLines("~/HypothesisFiveSTRMPTs.nex", warn = FALSE)#
HypothesisSixSTRMPTs <- readLines("~/HypothesisSixSTRMPTs.nex", warn = FALSE)#
#
# Isolate and reformat trees as ape trees:#
HypothesisOneSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisOneSTRMPTs[which(unlist(lapply(strsplit(HypothesisOneSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisTwoSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisTwoSTRMPTs[which(unlist(lapply(strsplit(HypothesisTwoSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisThreeSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisThreeSTRMPTs[which(unlist(lapply(strsplit(HypothesisThreeSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisFourSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisFourSTRMPTs[which(unlist(lapply(strsplit(HypothesisFourSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisFiveSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisFiveSTRMPTs[which(unlist(lapply(strsplit(HypothesisFiveSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisSixSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisSixSTRMPTs[which(unlist(lapply(strsplit(HypothesisSixSTRMPTs, ""), function(x) x[1] == "(")))]))#
#
# Write STR trees to file:#
write.tree(HypothesisOneSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/Trees/STRTrees.tre")#
write.tree(HypothesisTwoSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/Trees/STRTrees.tre")#
write.tree(HypothesisThreeSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/Trees/STRTrees.tre")#
write.tree(HypothesisFourSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/Trees/STRTrees.tre")#
write.tree(HypothesisFiveSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/Trees/STRTrees.tre")#
write.tree(HypothesisSixSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/Trees/STRTrees.tre")#
#
# Read in STR tables:#
HypothesisOneSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
HypothesisTwoSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
HypothesisThreeSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
HypothesisFourSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
HypothesisFiveSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
HypothesisSixSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
#
# Dafely reinsert the missing taxa to generate full trees:#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/Trees/FullTrees.tre", str.list = HypothesisOneSTRTable, multi.placements = "random")#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/Trees/FullTrees.tre", str.list = HypothesisTwoSTRTable, multi.placements = "random")#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/Trees/FullTrees.tre", str.list = HypothesisThreeSTRTable, multi.placements = "random")#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/Trees/FullTrees.tre", str.list = HypothesisFourSTRTable, multi.placements = "random")#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/Trees/FullTrees.tre", str.list = HypothesisFiveSTRTable, multi.placements = "random")#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/Trees/FullTrees.tre", str.list = HypothesisSixSTRTable, multi.placements = "random")#
#
##
HypothesisOneFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/Trees/FullTrees.tre")#
HypothesisTwoFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/Trees/FullTrees.tre")#
HypothesisThreeFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/Trees/FullTrees.tre")#
HypothesisFourFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/Trees/FullTrees.tre")#
HypothesisFiveFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/Trees/FullTrees.tre")#
HypothesisSixFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/Trees/FullTrees.tre")#
HypothesisOneFullMPTs <- lapply(HypothesisOneFullMPTs, function(x) ape::drop.tip(ape::ladderize(x, right = FALSE), "allzero"))#
HypothesisTwoFullMPTs <- lapply(HypothesisTwoFullMPTs, function(x) ape::drop.tip(ape::ladderize(x, right = FALSE), "allzero"))#
HypothesisThreeFullMPTs <- lapply(HypothesisThreeFullMPTs, function(x) ape::drop.tip(ape::ladderize(x, right = FALSE), "allzero"))#
HypothesisFourFullMPTs <- lapply(HypothesisFourFullMPTs, function(x) ape::drop.tip(ape::ladderize(x, right = FALSE), "allzero"))#
HypothesisFiveFullMPTs <- lapply(HypothesisFiveFullMPTs, function(x) ape::drop.tip(ape::ladderize(x, right = FALSE), "allzero"))#
HypothesisSixFullMPTs <- lapply(HypothesisSixFullMPTs, function(x) ape::drop.tip(ape::ladderize(x, right = FALSE), "allzero"))
# Reset class to multiPhylo:#
class(HypothesisOneFullMPTs) <- class(HypothesisTwoFullMPTs) <- class(HypothesisThreeFullMPTs) <- class(HypothesisFourFullMPTs) <- class(HypothesisFiveFullMPTs) <- class(HypothesisSixFullMPTs) <- "multiPhylo"#
#
# Write out reformatted trees:#
write.tree(HypothesisOneFullMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/Trees/FullTrees.tre")#
write.tree(HypothesisTwoFullMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/Trees/FullTrees.tre")#
write.tree(HypothesisThreeFullMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/Trees/FullTrees.tre")#
write.tree(HypothesisFourFullMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/Trees/FullTrees.tre")#
write.tree(HypothesisFiveFullMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/Trees/FullTrees.tre")#
write.tree(HypothesisSixFullMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/Trees/FullTrees.tre")
HypothesisOneFullMPTs
consensus(HypothesisOneFullMPTs)
plot(consensus(HypothesisOneFullMPTs))
AgeData <- c("Acanthostomatops_vorax", "Acheloma_cumminsi", "Acheloma_dunni", "Acroplous_vorax", "Actinodon_frossardi", "Actiobates_peabodyi", "Adamanterpeton_ohioensis", "Almasaurus_habbazi", "Amphibamus_grandiceps", "Anconastes_vesperus", "Antarctosuchus_polydon", "Apateon_caducus", "Apateon_dracyi", "Apateon_flagrifer", "Apateon_gracilis", "Apateon_kontheri", "Apateon_pedestris", "Aphaneramma_kokeni", "Aphaneramma_rostratum", "Arachana_nigra", "Archegosaurus_decheni", "Archegosaurus_dyscriton", "Aspidosaurus_binasser", "Australerpeton_cosgriffi", "Balanerpeton_woodi", "Banksiops_townrowi", "Bathignathus_poikilops", "Bathignathus_watsoni", "Batrachosuchoides_lacer", "Batrachosuchus_browni", "Batrachosuchus_concordi", "Batrachosuchus_henwoodi", "Benthosuchus_sushkini", "Boreopelta_vavilovi", "Bothriceps_australis", "Brachyops_laticeps", "Branchierpeton_amblystomum", "Branchiosaurus_salamandroides", "Brevidorsum_profundum", "Broiliellus_brevis", "Broiliellus_olsoni", "Broiliellus_reiszi", "Broiliellus_texen
sis", "Broomistega_putterilli", "Cacops_aspidephorus", "Cacops_morrisi", "Cacops_woehri", "Calamops_paludosus", "Callistomordax_kugleri", "Calmasuchus_acri", "Capetus_palustris", "Cheliderpeton_vranyi", "Chenoprosopus_milleri", "Cherninia_denwai", "Chomatobatrachus_halei", "Cochleosaurus_bohemicus", "Cochleosaurus_florensis", "Collidosuchus_tchudinovi", "Compsocerops_cosgriffi", "Conjunctio_multidens", "Cosgriffius_campi", "Cyclotosaurus_robustus", "Dasyceps_bucklandi", "Dasyceps_microphthalmus", "Deltacephalus_whitei", "Deltasaurus_kimberleyensis", "Deltasaurus_pustulatus", "Dendrerpeton_acadianum", "Dendrerpeton_confusum", "Derwentia_warreni", "Dissorophus_multicinctus", "Doleserpeton_annectens", "Dutuitosaurus_ouazzoui", "Dvinosaurus_egregius", "Dvinosaurus_primus", "Ecolsonia_cutlerensis", "Edingerella_madagascariensis", "Edops_craigi", "Eocyclotosaurus_lehmani", "Eocyclotosaurus_wellesi", "Eoscopus_lockardi", "Eryops_megacephalus", "Eryosuchus_garjainovi", "Eryosuchus_pronus", "Eryosuchus_tverdochlebov
i", "Erythrobatrachus_noonkanbahensis", "Eugyrinus_wildi", "Fedexia_striegeli", "Georgenthalia_clavinasica", "Gerobatrachus_hottoni", "Gerrothorax_pulcherrimus", "Glanochthon_angusta", "Glanochthon_latirostris", "Hadrokkosaurus_bradyi ", "Hyperokynodon_keuperinus", "Iberospondylus_schultzei", "Indobrachyops_panchetensis", "Inflectosaurus_amplus", "Intasuchus_silvicola", "Isodectes_obtusus", "Kamacops_acervalis", "Keratobrachyops_australis", "Kestrosaurus_dreyeri", "Konzhukovia_sangabrielensis", "Konzhukovia_tarda", "Konzhukovia_vetusta", "Koolasuchus_cleelandi", "Koskinonodon_perfectus", "Kuttycephalus_triangularis", "Laccosaurus_watsoni", "Laidleria_gracilis ", "Lapillopsis_nana", "Leptorophus_raischi", "Leptorophus_tener", "Limnogyrinus_elegans", "Luzocephalus_blomi", "Lydekkerina_huxleyi", "Lyrocephaliscus_euri", "Mahavisaurus_australis", "Mahavisaurus_dentatus", "Mastodonsaurus_cappelensis", "Mastodonsaurus_giganteus", "Melanerpeton_eisfeldi", "Melanerpeton_humbergense", "Melanerpeton_sembachense", "Mel
osaurus_kamaensis", "Melosaurus_platyrhinus", "Melosaurus_uralensis", "Metoposaurus_diagnosticus", "Metoposaurus_diagnosticuskrasiejowensis", "Micromelerpeton_credneri", "Micropholis_stowi", "Microposaurus_casei", "Nanolania_anatopretia", "Neldasaurus_wrightae", "Nigerpeton_ricqlesi", "Notobrachyops_picketti", "Odenwaldia_heidelbergensis", "Onchiodon_labyrinthicus", "Palatinerpeton_kraetschmeri", "Paracyclotosaurus_crookshanki", "Paracyclotosaurus_davidi", "Parapytanga_catarinensis", "Parioxys_ferricolus", "Parotosuchus_haughtoni", "Parotosuchus_nasutus", "Parotosuchus_orenburgensis", "Pasawioops_mayi", "Peltobatrachus_pustulatus", "Peltostega_erici", "Perryella_olsoni", "Phonerpeton_pricei", "Plagiosuchus_pustuliferus", "Platycepsion_wilkinsoni", "Platyhystrix_rugosus", "Platyoposaurus_stuckenbergi", "Platyoposaurus_watsoni", "Platyrhinops_lyelli", "Platystega_depressa", "Plemmyradytes_shintoni", "Pneumatostega_potamia", "Prionosuchus_plummeri", "Procochleosaurus_jarrowensis", "Quasicyclotosaurus_campi", "
Rewana_myriadens", "Rewana_quadricuneata", "Rhineceps_nyasaensis", "Rhinesuchoides_tenuiceps", "Rhinesuchus_broomianus", "Rhinesuchus_capensis", "Rhinesuchus_whaitsi", "Rhytidosteus_capensis", "Rileymillerus_cosgriffi", "Rotaryus_gothae", "Rotaurisaurus_contundo", "Rubeostratilia_texensis", "Saharastega_moradiensis ", "Sangaia_lavinai", "Scapanops_neglectus", "Schoenfelderpeton_prescheri", "Sclerocephalus_bavaricus", "Sclerocephalus_haeuseri", "Sclerocephalus_jogischneideri", "Sclerocephalus_nobilis", "Sclerocephalus_stambergi", "Sclerothorax_hypselonotus", "Siderops_kehli", "Sinobrachyops_placenticephalus", "Slaugenhopia_texensis", "Stanocephalosaurus_birdi", "Stenotosaurus_semiclausus", "Stenotosaurus_stantonensis", "Stoschiosaurus_nielseni", "Syndyodosuchus_tetricus", "Tambachia_trogallas", "Tatrasuchus_wildi", "Tersomius_dolesensis", "Tersomius_mosesi", "Tersomius_texensis", "Tertrema_acuta", "Tertremoides_madagascariensis", "Thabanchuia_oomie", "Thoosuchus_yakovlevi", "Trematolestes_hagdorni", "Tremato
saurus_brauni", "Trematosuchus_sobeyi", "Trimerorhachis_insignis", "Trimerorhachis_sandovalensis", "Trucheosaurus_major", "Tupilakosaurus_wetlugensis", "Uranocentrodon_senekalensis", "Uruyiella_liminea", "Vanastega_plurimidens", "Vigilius_wellesi", "Vladlenosaurus_alexeyevi", "Wantzosaurus_elongatus", "Warrenisuchus_aliciae", "Watsonisuchus_gunganj", "Watsonisuchus_rewanensis", "Wellesaurus_peabodyi", "Wetlugasaurus_angustifrons", "Xenobrachyops_allos", "Xenotosuchus_africanus", "Yuanansuchus_laticeps", "Zatrachys_serratus", "Zygosaurus_lucius", "Brachyopidae_indet_QMF14493", "Rhinesuchidae_indet_BPI_1_4473", "Rhinesuchidae_indet_UFRGSPV0352P_and_0235P_and_0347P_and_0348P_and_0349P_and_0350P_and_0356P", "Trematosauroidea_indet_SMNS_81772", "Cyclotosaurus_buechneri", "Cyclotosaurus_ebrachensis", "Cyclotosaurus_hemprichi", "Cyclotosaurus_intermedius", "Cyclotosaurus_mordax", "Cyclotosaurus_posthumus", "Megalophthalma_ockerti", "Plagiosternum_granulosum", "Procuhy_nazariensis", "Rhinesuchidae_indet_UFPI PV007_
and_PV003_and_PV360", "Timonya_anneae ", "Yuanansuchus_maopingchangensis", "Angusaurus_dentatus", "Clamorosaurus_nocturnus", "Pelorocephalus_mendozensis", "Glaukerpeton_avinoffi", "Compsocerops_sp_ULBRA_PVT_059a_et_059b_et_060_to_062", "Eryopiformes_indet_POL-F_2012-001", "Tomeia_witecki", "Eodiscoglossus_oxoniensis", "Shomronella_jordanica ", "Liaoxitriton_zhongjiani ", "Paranecturus_garbanii", "Habrosaurus_dilatus", "Ichthyophis_glutinosus ", "Rhinatrema_bivittatum", "Albanerpetontidae_indet_FUB_Gardies_66-67", "Suchonosaurus_minimus", "Euconcordia_cunninghami ", "Archaeothyris_florensis ", "Acanthostega_gunnari", "Acherontiscus_caledoniae", "Adelogyrinus_simorhynchus", "Adelospondylus_watsoni", "Anthracosaurus_russelli", "Archeria_crassidisca", "Ariekanerpeton_sigalovi", "Asaphestera_intermedia", "Baphetes_kirkbyi", "Batrachiderpeton_reticulatum", "Batropetes_fritschia", "Brachydectes_elongatus", "Brachydectes_newberryi", "Bruktererpeton_fiebigi", "Caerorhachis_bairdi", "Cardiocephalus_peabodyi", "Cardio
cephalus_sternbergi", "Carrolla_craddocki", "Colosteus_scutellatus", "Crassigyrinus_scoticus", "Ctenerpeton_alveolatum", "Diadectes_absitus", "Diceratosaurus_brevirostris", "Diplocaulus_magnicornis", "Diplocaulus_primus", "Diploceraspis_burkei", "Discosauriscus_austriacus", "Dolichopareias_disjectus", "Doragnathus_woodi", "Eocaecilia_micropodia", "Eoherpeton_watsoni", "Eucritta_melanolimnetes", "Euryodus_dalyae", "Euryodus_primus", "Eusthenopteron_foordi", "Gephyrostegus_bohemicus", "Greererpeton_burkemorani", "Hapsidopareion_lepton", "Hyloplesion_longicostatum", "Ichthyostega_stensioei", "Karaurus_sharovi", "Keraterpeton_galvani", "Kotlassia_prima", "Lepterpeton_dobbsii", "Leptoropha_talonophora", "Lethiscus_stocki", "Limnoscelis_paludis", "Llistrofus_pricei", "Loxomma_acutirhinus", "Loxomma_rankini", "Megalocephalus_pachycephalus", "Micraroter_erythrogeios", "Microbrachis_pelikani", "Microphon_exiguus", "Microsauria_indet_FMNH_PR_981", "Notobatrachus_degiustoi", "Occidens_portlocki", "Odonterpeton_triangu
lare", "Oestocephalus_amphiuminum", "Oestocephalus_granulosum", "Orobates_pabsti", "Ossinodus_pueri", "Paleothyris_acadiana", "Panderichthys_rhombolepis", "Pantylus_cordatus", "Pederpes_finneyae", "Pelodosotis_elongatum", "Petrolacosaurus_kansensis", "Phlegethontia_linearis", "Phlegethontia_longissima", "Pholiderpeton_attheyi", "Pholiderpeton_scutigerum", "Proterogyrinus_scheelei", "Ptyonius_marshii", "Quasicaecilia_texana", "Rhynchonkos_stovalli", "Sauropleura_bairdi", "Sauropleura_pectinata", "Sauropleura_scalaris", "Saxonerpeton_geinitzi", "Scincosaurus_crassus", "Seymouria_baylorensis", "Seymouria_sanjuanensis", "Sigournea_multidentata", "Silvanerpeton_miripedes", "Solenodonsaurus_janenschi", "Sparodus_validens", "Spathicephalus_mirus", "Stegotretus_agyrus", "Tetrapoda_indet_NMS987GF65_dot_1", "Triadobatrachus_massinoti", "Tseajaia_campi", "Tuditanus_punctulatus", "Tulerpeton_curtum", "Urocordylus_wandesfordii", "Utaherpeton_franklini", "Utegenia_shpinari", "Valdotriton_gracilis", "Ventastega_curonica",
"Vieraella_herbstii", "Westlothiana_lizziae", "Whatcheeria_deltae")
HypothesisFiveFullMPTs[[1]]
HypothesisFiveFullMPTs[[1]]$tip.label
intersect(AgeData, HypothesisFiveFullMPTs[[1]]$tip.label)
setdiff(AgeData, HypothesisFiveFullMPTs[[1]]$tip.label)
sort(HypothesisFiveFullMPTs[[1]]$tip.label)
# Install packages required for analysis only need to do this once):#
install.packages("Claddis", dependencies = TRUE)#
install.packages("devtools", dependencies = TRUE)#
install.packages("gdata", dependencies = TRUE)#
devtools::install_github("graemetlloyd/metatree")#
install.packages("paleotree", dependencies = TRUE)#
install.packages("phytools", dependencies = TRUE)#
install.packages("strap", dependencies = TRUE)#
#
########################################################################
#                                                                     ##
#                           LOADING PACKAGES                          ##
#                                                                     ##
########################################################################
#
# Load libraries into memory (need to do this at start of each R session):#
library(Claddis)#
library(gdata)#
library(metatree)#
library(phytools)#
library(paleotree)#
library(strap)#
#
########################################################################
#                                                                     ##
#                         GETTING THE DATA IN                         ##
#                                                                     ##
########################################################################
#
# Read in trees (may need to modify this path slightly for your own machine):#
MostParsimoniousTrees <- read.tree(file = "~/Dropbox/Literature Search/Tree search results/Dinosauria_MPTs_Full.tre")#
#
# Isolate just the first tree (will use this for analysis as first pass relationships look better than some other trees):#
FirstMostParsimoniousTree <- MostParsimoniousTrees[[1]]#
#
# Isolate tip names to check taxonomic coverage later:#
TipNames <- sort(FirstMostParsimoniousTree$tip.label)#
#
# Read in traits data Excel spreadsheet:#
AllTraitsData <- read.xls(xls = "~/Dropbox/Literature Search/Metatree Files/Traits.xlsx")#
#
# Isolate just the age data:#
AgeData <- AllTraitsData[, c("TaxonName", "Max", "Min")]#
#
# Remove any NA values so age data only contains taxa with age data:#
AgeData <- AgeData[!apply(cbind(is.na(AgeData[, "Max"]), is.na(AgeData[, "Min"])), 1, any), ]#
#
# Format age data further ready for use in time-scaling (two columns of "FAD" and "LAD" dates and row names corresponding to taxa):#
AgeData <- matrix(c(as.numeric(AgeData[, "Max"]), as.numeric(AgeData[, "Min"])), ncol = 2, dimnames = list(as.character(AgeData[, "TaxonName"]), c("FAD", "LAD")))#
#
########################################################################
#                                                                     ##
#  FINDING BLOCKS OF TAXA THAT ARE DEFINITVELY BIPEDAL OR QUADRUPEDAL ##
#                                                                     ##
########################################################################
#
# Get all sauropod names (definite quadrupeds):#
AllSauropodaNames <- PaleobiologyDBChildFinder(taxon_nos = "1", taxon_names = "Sauropoda", returnrank = "3")#
#
# Retain only those sauropods present in teh tree:#
SauropodsInTreeAndDefinitelyQuadrupeds <- intersect(gsub(" ", "_", AllSauropodaNames[, "TaxonName"]), FirstMostParsimoniousTree$tip.label)#
#
# Get all theropod names (mainly bipeds):#
AllTheropodaNames <- PaleobiologyDBChildFinder(taxon_nos = "1", taxon_names = "Theropoda", returnrank = "3")#
#
# Get maniraptotrans (include more complex gaits, e.g., scansorial):#
AllManiraptoraNames <- PaleobiologyDBChildFinder(taxon_nos = "1", taxon_names = "Maniraptora", returnrank = "3")#
#
# Get just the non-maniraptoran theropods (definite bipeds):#
AllNonManiraptoranTheropoda <- setdiff(AllTheropodaNames[, "TaxonName"], AllManiraptoraNames[, "TaxonName"])#
#
# Reta just those bipedal theropods found in the tree:#
TheropodsInTreeAndDefinitelyBipeds <- intersect(gsub(" ", "_", AllNonManiraptoranTheropoda), FirstMostParsimoniousTree$tip.label)#
#
# Get all pacjycephalosaur names (Definite bipeds):#
AllPachycephalosauriaNames <- PaleobiologyDBChildFinder(taxon_nos = "1", taxon_names = "Pachycephalosauria", returnrank = "3")#
#
# Retain just those present in the tree:#
PachycephalosauriaInTreeAndDefinitelyBipeds <- intersect(gsub(" ", "_", AllPachycephalosauriaNames[, "TaxonName"]), FirstMostParsimoniousTree$tip.label)#
#
# Get all troodontids (definite bipeds):#
AllTroodontidaeNames <- PaleobiologyDBChildFinder(taxon_nos = "1", taxon_names = "Troodontidae", returnrank = "3")#
#
# Retain just those found in the tree:#
TroodontidaeInTreeAndDefinitelyBipeds <- intersect(gsub(" ", "_", AllTroodontidaeNames[, "TaxonName"]), FirstMostParsimoniousTree$tip.label)#
#
# Get all thyreophora (definite quadrupeds):#
AllThyreophoraNames <- PaleobiologyDBChildFinder(taxon_nos = "1", taxon_names = "Thyreophora", returnrank = "3")#
#
# Retain just those that are in the tree:#
ThyreophoraInTreeAndDefinitelyQuadrupeds <- intersect(gsub(" ", "_", AllThyreophoraNames[, "TaxonName"]), FirstMostParsimoniousTree$tip.label)#
#
# Get all ceratopsids (Definite quadrupeds):#
AllCeratopsidaeNames <- PaleobiologyDBChildFinder(taxon_nos = "1", taxon_names = "Ceratopsidae", returnrank = "3")#
#
# Retain just those found in the tree:#
CeratopsidaeInTreeAndDefinitelyQuadrupeds <- intersect(gsub(" ", "_", AllCeratopsidaeNames[, "TaxonName"]), FirstMostParsimoniousTree$tip.label)#
#
########################################################################
#                                                                     ##
#                   TAXON PRUNING AND MISSING NAMES                   ##
#                                                                     ##
########################################################################
#
# Find any tips without age data on the tree that will need to be pruned:#
TipsToPruneDueToMissingAgeData <- setdiff(FirstMostParsimoniousTree$tip.label, rownames(AgeData))#
#
# If there are tips to prune remove these from the first most parsimonious tree:#
if(length(TipsToPruneDueToMissingAgeData) > 0) FirstMostParsimoniousTree <- drop.tip(phy = FirstMostParsimoniousTree, tip = TipsToPruneDueToMissingAgeData)#
#
# Ladderize the tree to make it prettier/easier to read:#
FirstMostParsimoniousTree <- ladderize(FirstMostParsimoniousTree)#
#
# Get the valid dinosaur species currently in the Paleobiology Database:#
ValidMesozoicDinosaursInThePaleobiologyDatabase <- PaleobiologyDBChildFinder(taxon_nos = "1", taxon_names = "Dinosauria", interval = c("Triassic", "Cretaceous"), extant = "exclude", validonly = TRUE, returnrank = "3")#
#
########################################################################
#                                                                     ##
#                       TEST TAXONOMIC COVERAGE                       ##
#                                                                     ##
########################################################################
#
# Get the number of valid dinosaur species currently in the Paleobiology Database:#
NumberOfValidMesozoicDinosaursInThePaleobiologyDatabase <- nrow(ValidMesozoicDinosaursInThePaleobiologyDatabase)#
NumberOfValidMesozoicDinosaursInThePaleobiologyDatabase#
#
# Get the number of valid dinosaur species in the metatree:#
NumberOfValidMesozoicDinosaursInTheMetatree <- length(intersect(TipNames, gsub(" ", "_", ValidMesozoicDinosaursInThePaleobiologyDatabase[, "TaxonName"])))#
NumberOfValidMesozoicDinosaursInTheMetatree#
#
# get the current percentage coverage of the tree:#
PercentageSpeciesCoverageOfTheMetatree <-  NumberOfValidMesozoicDinosaursInTheMetatree / NumberOfValidMesozoicDinosaursInThePaleobiologyDatabase * 100#
PercentageSpeciesCoverageOfTheMetatree#
#
# List species in the database but not in the metatree:#
sort(setdiff(gsub(" ", "_", ValidMesozoicDinosaursInThePaleobiologyDatabase[, "TaxonName"]), TipNames))#
#
########################################################################
#                                                                     ##
#                        TIME-SCALING THE TREE                        ##
#                                                                     ##
########################################################################
#
# Time-scale tree by using a minimum branch length of 1 million years:#
FirstMostParsimoniousTree <- timePaleoPhy(tree = FirstMostParsimoniousTree, timeData = AgeData, type = "mbl", vartime = 1)
FirstMostParsimoniousTree
FirstMostParsimoniousTree$root.time
# Time-scale tree by using a equal branch sharing and a root branch length of one million years:#
FirstMostParsimoniousTree <- timePaleoPhy(tree = FirstMostParsimoniousTree, timeData = AgeData, type = "equal", vartime = 1)
FirstMostParsimoniousTree$root.time
??timePaleoPhy
?timePaleoPhy
# Time-scale tree by using a equal branch sharing and a root branch length of one million years:#
FirstMostParsimoniousTree <- timePaleoPhy(tree = FirstMostParsimoniousTree, timeData = AgeData, type = "equal", vartime = 1, add.term=TRUE)
FirstMostParsimoniousTree
plot(FirstMostParsimoniousTree, cex = 0.3)
write.tree(FirstMostParsimoniousTree, "~/Desktop/Dino.tre")
GetNodeAges(FirstMostParsimoniousTree)
unique(GetNodeAges(FirstMostParsimoniousTree))
sort(unique(GetNodeAges(FirstMostParsimoniousTree)))
write.tree(FirstMostParsimoniousTree, "~/Desktop/Dino.tre")
# Load metatree library:#
library(metatree)#
#
# Read in TNT tree output:#
HypothesisOneSTRMPTs <- readLines("~/HypothesisOneSTRMPTs.nex", warn = FALSE)#
HypothesisTwoSTRMPTs <- readLines("~/HypothesisTwoSTRMPTs.nex", warn = FALSE)#
HypothesisThreeSTRMPTs <- readLines("~/HypothesisThreeSTRMPTs.nex", warn = FALSE)#
HypothesisFourSTRMPTs <- readLines("~/HypothesisFourSTRMPTs.nex", warn = FALSE)#
HypothesisFiveSTRMPTs <- readLines("~/HypothesisFiveSTRMPTs.nex", warn = FALSE)#
HypothesisSixSTRMPTs <- readLines("~/HypothesisSixSTRMPTs.nex", warn = FALSE)#
#
# Isolate and reformat trees as ape trees:#
HypothesisOneSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisOneSTRMPTs[which(unlist(lapply(strsplit(HypothesisOneSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisTwoSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisTwoSTRMPTs[which(unlist(lapply(strsplit(HypothesisTwoSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisThreeSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisThreeSTRMPTs[which(unlist(lapply(strsplit(HypothesisThreeSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisFourSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisFourSTRMPTs[which(unlist(lapply(strsplit(HypothesisFourSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisFiveSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisFiveSTRMPTs[which(unlist(lapply(strsplit(HypothesisFiveSTRMPTs, ""), function(x) x[1] == "(")))]))#
HypothesisSixSTRMPTs <- ape::read.tree(text = gsub(" ", "", HypothesisSixSTRMPTs[which(unlist(lapply(strsplit(HypothesisSixSTRMPTs, ""), function(x) x[1] == "(")))]))#
#
# Write STR trees to file:#
write.tree(HypothesisOneSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/Trees/STRTrees.tre")#
write.tree(HypothesisTwoSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/Trees/STRTrees.tre")#
write.tree(HypothesisThreeSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/Trees/STRTrees.tre")#
write.tree(HypothesisFourSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/Trees/STRTrees.tre")#
write.tree(HypothesisFiveSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/Trees/STRTrees.tre")#
write.tree(HypothesisSixSTRMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/Trees/STRTrees.tre")#
#
# Read in STR tables:#
HypothesisOneSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
HypothesisTwoSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
HypothesisThreeSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
HypothesisFourSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
HypothesisFiveSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
HypothesisSixSTRTable <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/MetatreeFiles/STR.txt", header = TRUE, stringsAsFactors = FALSE)#
#
# Dafely reinsert the missing taxa to generate full trees:#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/Trees/FullTrees.tre", str.list = HypothesisOneSTRTable, multi.placements = "random")#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/Trees/FullTrees.tre", str.list = HypothesisTwoSTRTable, multi.placements = "random")#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/Trees/FullTrees.tre", str.list = HypothesisThreeSTRTable, multi.placements = "random")#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/Trees/FullTrees.tre", str.list = HypothesisFourSTRTable, multi.placements = "random")#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/Trees/FullTrees.tre", str.list = HypothesisFiveSTRTable, multi.placements = "random")#
Claddis::SafeTaxonomicReinsertion(treefile.in = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/Trees/STRTrees.tre", treefile.out = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/Trees/FullTrees.tre", str.list = HypothesisSixSTRTable, multi.placements = "random")#
#
# Read full trees in:#
HypothesisOneFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/Trees/FullTrees.tre")#
HypothesisTwoFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/Trees/FullTrees.tre")#
HypothesisThreeFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/Trees/FullTrees.tre")#
HypothesisFourFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/Trees/FullTrees.tre")#
HypothesisFiveFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/Trees/FullTrees.tre")#
HypothesisSixFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/Trees/FullTrees.tre")#
#
# Ladderize each tree and drop allzero outgroup:#
HypothesisOneFullMPTs <- lapply(HypothesisOneFullMPTs, function(x) ape::drop.tip(ape::ladderize(x, right = FALSE), "allzero"))#
HypothesisTwoFullMPTs <- lapply(HypothesisTwoFullMPTs, function(x) ape::drop.tip(ape::ladderize(x, right = FALSE), "allzero"))#
HypothesisThreeFullMPTs <- lapply(HypothesisThreeFullMPTs, function(x) ape::drop.tip(ape::ladderize(x, right = FALSE), "allzero"))#
HypothesisFourFullMPTs <- lapply(HypothesisFourFullMPTs, function(x) ape::drop.tip(ape::ladderize(x, right = FALSE), "allzero"))#
HypothesisFiveFullMPTs <- lapply(HypothesisFiveFullMPTs, function(x) ape::drop.tip(ape::ladderize(x, right = FALSE), "allzero"))#
HypothesisSixFullMPTs <- lapply(HypothesisSixFullMPTs, function(x) ape::drop.tip(ape::ladderize(x, right = FALSE), "allzero"))#
#
# Reset class to multiPhylo:#
class(HypothesisOneFullMPTs) <- class(HypothesisTwoFullMPTs) <- class(HypothesisThreeFullMPTs) <- class(HypothesisFourFullMPTs) <- class(HypothesisFiveFullMPTs) <- class(HypothesisSixFullMPTs) <- "multiPhylo"#
#
# Write out reformatted trees:#
write.tree(HypothesisOneFullMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/Trees/FullTrees.tre")#
write.tree(HypothesisTwoFullMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/Trees/FullTrees.tre")#
write.tree(HypothesisThreeFullMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/Trees/FullTrees.tre")#
write.tree(HypothesisFourFullMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/Trees/FullTrees.tre")#
write.tree(HypothesisFiveFullMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/Trees/FullTrees.tre")#
write.tree(HypothesisSixFullMPTs, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/Trees/FullTrees.tre")
# Load metatree library:#
library(metatree)#
#
# Read full trees in:#
HypothesisOneFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/Trees/FullTrees.tre")#
HypothesisTwoFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/Trees/FullTrees.tre")#
HypothesisThreeFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/Trees/FullTrees.tre")#
HypothesisFourFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/Trees/FullTrees.tre")#
HypothesisFiveFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/Trees/FullTrees.tre")#
HypothesisSixFullMPTs <- read.tree("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/Trees/FullTrees.tre")#
#
# Read in first appearance ages:#
FirstAppearanceAges <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/AgeData/FirstAppearanceAgeData.txt", header = TRUE, stringsAsFactors = FALSE, row.names = 1)
FirstAppearanceAges
library(paleotree)
timePaleoPhy(tree = HypothesisOneFullMPTs[[1]], ages = FirstAppearanceAges)
timePaleoPhy(tree = HypothesisOneFullMPTs[[1]], timeData = FirstAppearanceAges)
timePaleoPhy(tree = HypothesisOneFullMPTs[[1]], timeData = FirstAppearanceAges)
colnames(FirstAppearanceAges) <- c("FAD", "LAD")
timePaleoPhy(tree = HypothesisOneFullMPTs[[1]], timeData = FirstAppearanceAges)
FirstAppearanceAges
FirstAppearanceAges[, 1] > FirstAppearanceAges[, 2]
!FirstAppearanceAges[, 1] > FirstAppearanceAges[, 2]
FirstAppearanceAges[!FirstAppearanceAges[, 1] > FirstAppearanceAges[, 2], ]
FirstAppearanceAges[!FirstAppearanceAges[, 1] < FirstAppearanceAges[, 2], ]
FirstAppearanceAges[FirstAppearanceAges[, 1] < FirstAppearanceAges[, 2], ]
FirstAppearanceAges[, 1]
hist(FirstAppearanceAges[, 1])
hist(FirstAppearanceAges[, 1], breaks = 50)
DatePhylo(HypothesisOneFullMPTs[[1]], FirstAppearanceAges)
ncol()
ncol(FirstAppearanceAges)
setdiff(rownames(FirstAppearanceAges), HypothesisOneFullMPTs[[1]]$tip.label)
setdiff(rownames(FirstAppearanceAges), HypothesisOneFullMPTs[[1]]$tip.label)#
setdiff(HypothesisOneFullMPTs[[1]]$tip.label, rownames(FirstAppearanceAges))
# Read in first appearance ages:#
FirstAppearanceAges <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/AgeData/FirstAppearanceAgeData.txt", header = TRUE, stringsAsFactors = FALSE, row.names = 1)#
#
colnames(FirstAppearanceAges) <- c("FAD", "LAD")#
#
setdiff(rownames(FirstAppearanceAges), HypothesisOneFullMPTs[[1]]$tip.label)#
setdiff(HypothesisOneFullMPTs[[1]]$tip.label, rownames(FirstAppearanceAges))
# Read in first appearance ages:#
FirstAppearanceAges <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/AgeData/FirstAppearanceAgeData.txt", header = TRUE, stringsAsFactors = FALSE, row.names = 1)#
#
colnames(FirstAppearanceAges) <- c("FAD", "LAD")#
#
setdiff(rownames(FirstAppearanceAges), HypothesisOneFullMPTs[[1]]$tip.label)#
setdiff(HypothesisOneFullMPTs[[1]]$tip.label, rownames(FirstAppearanceAges))
# Read in first appearance ages:#
FirstAppearanceAges <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/AgeData/FirstAppearanceAgeData.txt", header = TRUE, stringsAsFactors = FALSE, row.names = 1)#
#
colnames(FirstAppearanceAges) <- c("FAD", "LAD")#
#
setdiff(rownames(FirstAppearanceAges), HypothesisOneFullMPTs[[1]]$tip.label)#
setdiff(HypothesisOneFullMPTs[[1]]$tip.label, rownames(FirstAppearanceAges))
# Read in first appearance ages:#
FirstAppearanceAges <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/AgeData/FirstAppearanceAgeData.txt", header = TRUE, stringsAsFactors = FALSE, row.names = 1)#
#
colnames(FirstAppearanceAges) <- c("FAD", "LAD")#
#
setdiff(rownames(FirstAppearanceAges), HypothesisOneFullMPTs[[1]]$tip.label)#
setdiff(HypothesisOneFullMPTs[[1]]$tip.label, rownames(FirstAppearanceAges))
# Read in first appearance ages:#
FirstAppearanceAges <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/AgeData/FirstAppearanceAgeData.txt", header = TRUE, stringsAsFactors = FALSE, row.names = 1)#
#
colnames(FirstAppearanceAges) <- c("FAD", "LAD")#
#
setdiff(rownames(FirstAppearanceAges), HypothesisOneFullMPTs[[1]]$tip.label)#
setdiff(HypothesisOneFullMPTs[[1]]$tip.label, rownames(FirstAppearanceAges))
# Read in first appearance ages:#
FirstAppearanceAges <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/AgeData/FirstAppearanceAgeData.txt", header = TRUE, stringsAsFactors = FALSE, row.names = 1)#
#
colnames(FirstAppearanceAges) <- c("FAD", "LAD")#
#
setdiff(rownames(FirstAppearanceAges), HypothesisOneFullMPTs[[1]]$tip.label)#
setdiff(HypothesisOneFullMPTs[[1]]$tip.label, rownames(FirstAppearanceAges))
# Read in first appearance ages:#
FirstAppearanceAges <- read.table("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/AgeData/FirstAppearanceAgeData.txt", header = TRUE, stringsAsFactors = FALSE, row.names = 1)#
#
colnames(FirstAppearanceAges) <- c("FAD", "LAD")#
#
setdiff(rownames(FirstAppearanceAges), HypothesisOneFullMPTs[[1]]$tip.label)#
setdiff(HypothesisOneFullMPTs[[1]]$tip.label, rownames(FirstAppearanceAges))
# SCRIPT TO BUILD XML AND MRP FILES AND THEN GENERATES METATREE FILES FROM THEM#
# MAYBE ADD CODE TO CLEAR OUT PREVIOUS VERSIONS BEFORE RUNNING THIS ONE#
#
# Load metatree library:#
library(metatree)#
#
# Build inclusive data list:#
InclusiveDataList <- sort(unique(c(GetFilesForClade(c("matrsarc.html", "matramph.html")), "Gauthier_etal_1988b", "Lu_etal_2016c", "deBraga_et_Rieppel_1997a", "Giles_etal_2015a", "Davis_etal_2012a")))#
#
DirectoriesToClear <- c("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/MRP", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/XML", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/XML", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MRP", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/XML", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/MRP", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/XML", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/MRP", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/XML", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/MRP", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/XML", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/MRP", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/XML", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/MRP")#
#
lapply(as.list(DirectoriesToClear), function(x) {setwd(x); file.remove(list.files())})
# Build inclusive data list:#
InclusiveDataList <- sort(unique(c(GetFilesForClade(c("matrsarc.html", "matramph.html")), "Gauthier_etal_1988b", "Lu_etal_2016c", "deBraga_et_Rieppel_1997a", "Giles_etal_2015a", "Davis_etal_2012a")))#
#
DirectoriesToClear <- c("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/MRP", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/XML", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/XML", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MRP", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/XML", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/MRP", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/XML", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/MRP", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/XML", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/MRP", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/XML", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/MRP", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/XML", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/MRP", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MetatreeFiles", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/MetatreeFiles", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/MetatreeFiles", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/MetatreeFiles", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/MetatreeFiles", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/MetatreeFiles")#
#
x <- lapply(as.list(DirectoriesToClear), function(x) {setwd(x); file.remove(list.files())})
# SCRIPT TO BUILD XML AND MRP FILES AND THEN GENERATES METATREE FILES FROM THEM#
# MAYBE ADD CODE TO CLEAR OUT PREVIOUS VERSIONS BEFORE RUNNING THIS ONE#
#
# Load metatree library:#
library(metatree)#
#
# Build inclusive data list:#
InclusiveDataList <- sort(unique(c(GetFilesForClade(c("matrsarc.html", "matramph.html")), "Gauthier_etal_1988b", "Lu_etal_2016c", "deBraga_et_Rieppel_1997a", "Giles_etal_2015a", "Davis_etal_2012a")))#
#
DirectoriesToClear <- c("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/MRP", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/XML", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/XML", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MRP", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/XML", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/MRP", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/XML", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/MRP", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/XML", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/MRP", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/XML", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/MRP", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/XML", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/MRP", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MetatreeFiles", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/MetatreeFiles", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/MetatreeFiles", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/MetatreeFiles", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/MetatreeFiles", "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/MetatreeFiles")#
#
x <- lapply(as.list(DirectoriesToClear), function(x) {setwd(x); file.remove(list.files())})#
# Copy just inclusive XML data sets from main directory to project one:#
x <- lapply(as.list(InclusiveDataList), function(x) file.copy(from = paste("~/Documents/Homepage/www.graemetlloyd.com/xml/", x, ".xml", sep = ""), to =  paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/XML/", x, ".xml", sep = "")))#
#
# Copy just inclusive MRP data sets from main directory to project one:#
x <- lapply(as.list(InclusiveDataList), function(x) file.copy(from = paste("~/Documents/Homepage/www.graemetlloyd.com/mrp/", x, "mrp.nex", sep = ""), to =  paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/MRP/", x, "mrp.nex", sep = "")))#
#
# Standard exclusive data list (supertrees and the like):#
ExclusiveDataList <- c("Averianov_inpressa", "Bravo_et_Gaete_2015a", "Brocklehurst_etal_2013a", "Brocklehurst_etal_2015aa", "Brocklehurst_etal_2015ab", "Brocklehurst_etal_2015ac", "Brocklehurst_etal_2015ad", "Brocklehurst_etal_2015ae", "Brocklehurst_etal_2015af", "Bronzati_etal_2012a", "Bronzati_etal_2015ab", "Brusatte_etal_2009ba", "Campbell_etal_2016ab", "Carr_et_Williamson_2004a", "Carr_etal_2017ab", "Frederickson_et_Tumarkin-Deratzian_2014aa", "Frederickson_et_Tumarkin-Deratzian_2014ab", "Frederickson_et_Tumarkin-Deratzian_2014ac", "Frederickson_et_Tumarkin-Deratzian_2014ad", "Garcia_etal_2006a", "Gatesy_etal_2004ab", "Grellet-Tinner_2006a", "Grellet-Tinner_et_Chiappe_2004a", "Grellet-Tinner_et_Makovicky_2006a", "Hartman_etal_2019a", "Knoll_2008a", "Kurochkin_1996a", "Lopez-Martinez_et_Vicens_2012a", "Lu_etal_2014aa", "Norden_etal_inpressa", "Pisani_etal_2002a", "Ruiz-Omenaca_etal_1997a", "Ruta_etal_2003ba", "Ruta_etal_2003bb", "Ruta_etal_2007a", "Selles_et_Galobart_2016a", "Sereno_1993a", "Sidor_2001a", "Skutschas_etal_inpressa", "Tanaka_etal_2011a", "Toljagic_et_Butler_2013a", "Tsuihiji_etal_2011aa", "Varricchio_et_Jackson_2004a", "Vila_etal_2017a", "Wilson_2005aa", "Wilson_2005ab", "Zelenitsky_et_Therrien_2008a")#
#
# Build amphibia metatree:#
Amphibia <- Metatree(MRPDirectory = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/MRP", XMLDirectory = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/XML", TargetClade = "Tetrapoda", InclusiveDataList = InclusiveDataList, ExclusiveDataList = ExclusiveDataList, MissingSpecies = "exclude", RelativeWeights = c(0, 100, 10, 1), WeightCombination = "sum", ReportContradictionsToScreen = FALSE)#
#
# Build taxonomy tree (for basic checks ahead of building constraint trees):#
pdf("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/PDFTrees/TaxonomyTree.pdf", width = 30, height = 50)#
plot(Amphibia$TaxonomyTree, cex = 0.3)#
nodelabels(Amphibia$TaxonomyTree$node.label, cex = 0.5)#
dev.off()#
#
# Build vector of anuran (frog) taxa:#
AnuriTaxa <- Amphibia$TaxonomyTree$tip.label[strap::FindDescendants(n = Ntip(Amphibia$TaxonomyTree) + which(Amphibia$TaxonomyTree$node.label == "Anuri"), tree = Amphibia$TaxonomyTree)]#
#
# Build vector of cadudatan (salamander) taxa:#
CaudataTaxa <- Amphibia$TaxonomyTree$tip.label[strap::FindDescendants(n = Ntip(Amphibia$TaxonomyTree) + which(Amphibia$TaxonomyTree$node.label == "Caudata"), tree = Amphibia$TaxonomyTree)]#
#
# Build vector of batrachian (frog + salamander) taxa:#
BatrachiaTaxa <- Amphibia$TaxonomyTree$tip.label[strap::FindDescendants(n = Ntip(Amphibia$TaxonomyTree) + which(Amphibia$TaxonomyTree$node.label == "Batrachia"), tree = Amphibia$TaxonomyTree)]#
#
# Build vector of gymnophoniann (salamander) taxa:#
GymnophionaTaxa <- Amphibia$TaxonomyTree$tip.label[strap::FindDescendants(n = Ntip(Amphibia$TaxonomyTree) + which(Amphibia$TaxonomyTree$node.label == "Gymnophiona"), tree = Amphibia$TaxonomyTree)]#
#
# Update gymnophoniann vector to ensure Eocaecilia is included (above will potnetially fail as Eocaecilia alone won't form a clade):#
GymnophionaTaxa <- unique(c(GymnophionaTaxa, "Eocaecilia_micropodia"))#
#
# Build vector of lepospondylian taxa:#
LepospondyliTaxa <- Amphibia$TaxonomyTree$tip.label[strap::FindDescendants(n = Ntip(Amphibia$TaxonomyTree) + grep("Lepospondyli", Amphibia$TaxonomyTree$node.label), tree = Amphibia$TaxonomyTree)]#
#
# Build vector of temnospondylian taxa:#
TemnospondyliTaxa <- Amphibia$TaxonomyTree$tip.label[strap::FindDescendants(n = Ntip(Amphibia$TaxonomyTree) + grep("Eutemnospondyli", Amphibia$TaxonomyTree$node.label), tree = Amphibia$TaxonomyTree)]#
#
# Build vector of lissamphibian (crown amphibians) taxa:#
LissamphibiaTaxa <- Amphibia$TaxonomyTree$tip.label[strap::FindDescendants(n = Ntip(Amphibia$TaxonomyTree) + grep("Lissamphibia", Amphibia$TaxonomyTree$node.label), tree = Amphibia$TaxonomyTree)]#
#
# Update temnospondylian vector by removing lissamphibia:#
TemnospondyliTaxa <- setdiff(TemnospondyliTaxa, LissamphibiaTaxa)#
#
# Build vector of amniote taxa:#
AmniotaTaxa <- Amphibia$TaxonomyTree$tip.label[strap::FindDescendants(n = Ntip(Amphibia$TaxonomyTree) + grep("Amniota", Amphibia$TaxonomyTree$node.label), tree = Amphibia$TaxonomyTree)]#
#
# HYPOTHESIS CONSTRAINT TREES (From Laurin et al. http://dx.doi.org/10.1101/352609):#
#
# 1. Monophyletic lissamphibia amongst temnospondyls:#
MonophyleticLissamphibiaInsideTemnospondyli <- ape::collapse.singles(ape::read.tree(text = paste("(", paste(paste("(", paste(LepospondyliTaxa, collapse = ","), ")", sep = ""), paste("(", paste(paste(TemnospondyliTaxa, collapse = ","), paste("(", paste(LissamphibiaTaxa, collapse = ","), ")", sep = ""), sep = ","), ")", sep = ""), sep = ","), ");", sep = "")))#
#
# 2. Monophyletic lissamphibia amongst lepospondyls:#
MonophyleticLissamphibiaInsideLepospondyli <- ape::collapse.singles(ape::read.tree(text = paste("(", paste(paste("(", paste(TemnospondyliTaxa, collapse = ","), ")", sep = ""), paste("(", paste(paste(LepospondyliTaxa, collapse = ","), paste("(", paste(LissamphibiaTaxa, collapse = ","), ")", sep = ""), sep = ","), ")", sep = ""), sep = ","), ");", sep = "")))#
#
# 3. Diphyletic lissamphibia, batrachia amongst temnospondyls and gymniophona amongst lepospondyls:#
DiphyleticLissamphibiaBatrachiaInsideTemnospondyliGymnophionaInsideLepospondyli <- ape::collapse.singles(ape::read.tree(text = paste("(", paste(paste("(", paste(paste(LepospondyliTaxa, collapse = ","), paste("(", paste(GymnophionaTaxa, collapse = ","), ")", sep = ""), sep = ","), ")", sep = ""), paste("(", paste(paste(TemnospondyliTaxa, collapse = ","), paste("(", paste(BatrachiaTaxa, collapse = ","), ")", sep = ""), collapse = ","), ")", sep = ""), sep = ","), ");", sep = "")))#
#
# 4. Diphyletic lissamphibia inside temnospondyli, batrachia and gymniophona as sepaarte clades:#
DiphyleticLissamphibiaInsideTemnospondyli <- ape::collapse.singles(ape::read.tree(text = paste("(", paste(paste("(", paste(LepospondyliTaxa, collapse = ","), ")", sep = ""), paste("(", paste(paste(TemnospondyliTaxa, collapse = ","), paste("(", paste(BatrachiaTaxa, collapse = ","), ")", sep = ""), paste("(", paste(GymnophionaTaxa, collapse = ","), ")", sep = ""), sep = ","), ")", sep = ""), sep = ","), ");", sep = "")))#
#
# 5. Triphyletic Lissamphibia (Anuri and Caudata inside Temnospondyli,\nGymniophona inside Lepospondyli and Crown Lissamphibia monophyletic):#
TriphyleticLissamphibiaAnuriAndCaudataInsideTemnospondyliGymnophionaInsideLepospondyliCrownLissamphibiaMonophyletic <-  ape::collapse.singles(ape::read.tree(text = paste("(", paste(paste("(", paste(paste("(", paste(paste(LepospondyliTaxa, collapse = ","), paste("(", paste(GymnophionaTaxa, collapse = ","), ")", sep = ""), sep = ","), ")", sep = ""), paste("(", paste(paste(TemnospondyliTaxa, collapse = ","), paste("(", paste(AnuriTaxa, collapse = ","), ")", sep = ""), paste("(", paste(CaudataTaxa, collapse = ","), ")", sep = ""), sep = ","), ")", sep = ""), sep = ","), ")", sep = ""), paste("(", paste(AmniotaTaxa, collapse = ","), ")", sep = ""), sep = ","), ");", sep = "")))#
#
# 6. Triphyletic Lissamphibia (Anuri and Caudata inside Temnospondyli,\nGymniophona inside Lepospondyli and Crown Lissamphibia paraphyletic to Amniota):#
TriphyleticLissamphibiaAnuriAndCaudataInsideTemnospondyliGymnophionaInsideLepospondyliCrownLissamphibiaParaphyleticWithRespectToAmniota <- ape::collapse.singles(ape::read.tree(text = paste("(", paste(paste("(", paste(paste("(", paste(paste(LepospondyliTaxa, collapse = ","), paste("(", paste(GymnophionaTaxa, collapse = ","), ")", sep = ""), sep = ","), ")", sep = ""), paste("(", paste(AmniotaTaxa, collapse = ","), ")", sep = ""), sep = ","), ")", sep = ""), paste("(", paste(paste(TemnospondyliTaxa, collapse = ","), paste("(", paste(AnuriTaxa, collapse = ","), ")", sep = ""), paste("(", paste(CaudataTaxa, collapse = ","), ")", sep = ""), sep = ","), ")", sep = ""), sep = ","), ");", sep = "")))#
#
# Build PDF of constraint trees for visualisation:#
pdf("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/PDFTrees/ConstraintTrees.pdf", width = 10, height = 20)#
plot(MonophyleticLissamphibiaInsideTemnospondyli, cex = 0.3, main = "1. Monophyletic Lissamphibia inside Temnospondyli")#
plot(MonophyleticLissamphibiaInsideLepospondyli, cex = 0.3, main = "2. Monophyletic Lissamphibia inside Lepospondyli")#
plot(DiphyleticLissamphibiaBatrachiaInsideTemnospondyliGymnophionaInsideLepospondyli, cex = 0.3, main = "3. Diphyletic Lissamphibia (Batrachia inside Temnospondyli and Gymnophiona inside Lepospondyli)")#
plot(DiphyleticLissamphibiaInsideTemnospondyli, cex = 0.3, main = "4. Diphyletic Lissamphibia inside Temnospondyli (Batrachia and Gymnophiona as separate clades)")#
plot(TriphyleticLissamphibiaAnuriAndCaudataInsideTemnospondyliGymnophionaInsideLepospondyliCrownLissamphibiaMonophyletic, cex = 0.3, main = "5. Triphyletic Lissamphibia (Anuri and Caudata inside Temnospondyli,\nGymniophona inside Lepospondyli and Crown Lissamphibia monophyletic)")#
plot(TriphyleticLissamphibiaAnuriAndCaudataInsideTemnospondyliGymnophionaInsideLepospondyliCrownLissamphibiaParaphyleticWithRespectToAmniota, cex = 0.3, main = "6. Triphyletic Lissamphibia (Anuri and Caudata inside Temnospondyli,\nGymniophona inside Lepospondyli and Crown Lissamphibia paraphyletic to Amniota)")#
dev.off()#
#
# Build hypothees into MRP trees:#
HypothesisOneMRP <- Tree2MRP(MonophyleticLissamphibiaInsideTemnospondyli)#
HypothesisTwoMRP <- Tree2MRP(MonophyleticLissamphibiaInsideLepospondyli)#
HypothesisThreeMRP <- Tree2MRP(DiphyleticLissamphibiaBatrachiaInsideTemnospondyliGymnophionaInsideLepospondyli)#
HypothesisFourMRP <- Tree2MRP(DiphyleticLissamphibiaInsideTemnospondyli)#
HypothesisFiveMRP <- Tree2MRP(TriphyleticLissamphibiaAnuriAndCaudataInsideTemnospondyliGymnophionaInsideLepospondyliCrownLissamphibiaMonophyletic)#
HypothesisSixMRP <- Tree2MRP(TriphyleticLissamphibiaAnuriAndCaudataInsideTemnospondyliGymnophionaInsideLepospondyliCrownLissamphibiaParaphyleticWithRespectToAmniota)#
#
# Update outgroup from allzero to a real tetrapod taxon (Westlothiana_lizziae):#
rownames(HypothesisOneMRP$Matrix_1$Matrix) <- gsub("allzero", "Westlothiana_lizziae", rownames(HypothesisOneMRP$Matrix_1$Matrix))#
rownames(HypothesisTwoMRP$Matrix_1$Matrix) <- gsub("allzero", "Westlothiana_lizziae", rownames(HypothesisTwoMRP$Matrix_1$Matrix))#
rownames(HypothesisThreeMRP$Matrix_1$Matrix) <- gsub("allzero", "Westlothiana_lizziae", rownames(HypothesisThreeMRP$Matrix_1$Matrix))#
rownames(HypothesisFourMRP$Matrix_1$Matrix) <- gsub("allzero", "Westlothiana_lizziae", rownames(HypothesisFourMRP$Matrix_1$Matrix))#
rownames(HypothesisFiveMRP$Matrix_1$Matrix) <- gsub("allzero", "Westlothiana_lizziae", rownames(HypothesisFiveMRP$Matrix_1$Matrix))#
rownames(HypothesisSixMRP$Matrix_1$Matrix) <- gsub("allzero", "Westlothiana_lizziae", rownames(HypothesisSixMRP$Matrix_1$Matrix))#
#
# Get vector of indeterminate OTUs:#
IndeterminateOTUs <- rownames(Amphibia$FullMRPMatrix$Matrix_1$Matrix)[unlist(lapply(as.list(rownames(Amphibia$FullMRPMatrix$Matrix_1$Matrix)), function(x) length(strsplit(x, "_")[[1]]))) > 2]#
#
# Get vector of OTUs with subgenera in them:#
SubgeneraOTUs <- setdiff(unique(c(rownames(HypothesisOneMRP$Matrix_1$Matrix), rownames(HypothesisTwoMRP$Matrix_1$Matrix), rownames(HypothesisThreeMRP$Matrix_1$Matrix), rownames(HypothesisFourMRP$Matrix_1$Matrix), rownames(HypothesisFiveMRP$Matrix_1$Matrix), rownames(HypothesisSixMRP$Matrix_1$Matrix))), IndeterminateOTUs)[unlist(lapply(as.list(setdiff(rownames(HypothesisOneMRP$Matrix_1$Matrix), IndeterminateOTUs)), function(x) nchar(gsub("[:a-z:]|_", "", x)))) > 1]#
#
# Get correctly formatted version of subgenus names:#
FormattedSubgeneraOTUNames <- unlist(lapply(as.list(SubgeneraOTUs), function(x) {SplitName <- strsplit(x, "")[[1]]; SubgenusPosition <- grep("[:A-Z:]", SplitName)[2]; SplitName[SubgenusPosition] <- paste("_(", SplitName[SubgenusPosition], sep = ""); SpeciesPosition <- which(SplitName == "_"); SplitName[SpeciesPosition] <- ")_"; paste(SplitName, collapse = "")}))#
#
# Get vector of all other (regular) OTUs:#
RegularOTUs <- sort(setdiff(unique(c(rownames(HypothesisOneMRP$Matrix_1$Matrix), rownames(HypothesisTwoMRP$Matrix_1$Matrix), rownames(HypothesisThreeMRP$Matrix_1$Matrix), rownames(HypothesisFourMRP$Matrix_1$Matrix), rownames(HypothesisFiveMRP$Matrix_1$Matrix), rownames(HypothesisSixMRP$Matrix_1$Matrix))), c(IndeterminateOTUs, SubgeneraOTUs)))#
#
# Build matrix of al taxonomic reconciliation from XML:#
AllXML <- do.call(rbind, lapply(as.list(InclusiveDataList), function(x) metatree::ReadMetatreeXML(paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/XML/", x, ".xml", sep = ""))$SourceTree$Taxa$TagContents))#
#
# Get vector of recon numbers for OTU names:#
IndeterminateOTUReconNumbers <- AllXML[match(IndeterminateOTUs, AllXML[, "recon_name"]), "recon_no"]#
#
# Perform a database query to get the recon numbers for the non-indeterminate taxa:#
DatabaseQuery <- PaleobiologyDBTaxaQuerier("1", c(RegularOTUs, FormattedSubgeneraOTUNames))#
#
# Build recon table to draw from in building constraint tree XMLs:#
ReconTable <- cbind(c(RegularOTUs, SubgeneraOTUs, IndeterminateOTUs), c(unlist(lapply(apply(DatabaseQuery[, 1:2], 1, as.list), function(x) {x <- gsub("txn:|var:", "", unlist(x)); unname(x[!is.na(x)][1])})), IndeterminateOTUReconNumbers), c(RegularOTUs, FormattedSubgeneraOTUNames, IndeterminateOTUs))#
#
# Add column names to table:#
colnames(ReconTable) <- c("OTUName", "ReconNumber", "ReconName")#
#
# Setw working directory to XMLs:#
setwd("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/XML")#
#
# Read in first XML to use as template:#
EmptyXML <- metatree::ReadMetatreeXML(list.files()[1])#
#
# Make an empty XML by deleting most of the existing information:#
EmptyXML$SourceTree$Source$Author <- list(TagContents = matrix("NA", nrow = 1, ncol = 1, dimnames = list(c(), c("ListValue"))), TagSupplement = list(NULL))#
EmptyXML$SourceTree$Source$Year <- list(NULL)#
EmptyXML$SourceTree$Source$Title <- list(NULL)#
EmptyXML$SourceTree$Source$Journal <- list(NULL)#
EmptyXML$SourceTree$Source$Volume <- list(NULL)#
EmptyXML$SourceTree$Source$Pages <- list(NULL)#
EmptyXML$SourceTree$Source$Booktitle <- list(NULL)#
EmptyXML$SourceTree$Source$Publisher <- list(NULL)#
EmptyXML$SourceTree$Source$City <- list(NULL)#
EmptyXML$SourceTree$Source$Editor <- list(NULL)#
EmptyXML$SourceTree$Characters$Molecular <- list(NULL)#
EmptyXML$SourceTree$Characters$Morphological <- list(NULL)#
EmptyXML$SourceTree$Characters$Behavioural <- list(NULL)#
EmptyXML$SourceTree$Characters$Other <- list(TagContents = matrix("MRP", nrow = 1, ncol = 1, dimnames = list(c(), c("TypeValue"))), TagSupplement = matrix(c("Measure", "1"), nrow = 1, ncol = 2, dimnames = list(c(), c("Measure", "Value"))))#
EmptyXML$SourceTree$Notes <- list(TagContents = "Constraint tree.", TagSupplement = list(NULL))#
EmptyXML$SourceTree$Parent <- list(NULL)#
EmptyXML$SourceTree$Sibling <- list(NULL)#
#
# Copy empty XML to create each hypothesis XML:#
HypothesisOneXML <- HypothesisTwoXML <- HypothesisThreeXML <- HypothesisFourXML <- HypothesisFiveXML <- HypothesisSixXML <- EmptyXML#
#
# Build XMLs for every hypothesis:#
HypothesisOneXML$SourceTree$Taxa <- list(TagContents = matrix(as.vector(ReconTable[match(rownames(HypothesisOneMRP$Matrix_1$Matrix), ReconTable[, "OTUName"]), c("ReconName", "ReconNumber", "OTUName")]), ncol = 3, byrow = FALSE, dimnames = list(c(), c("recon_name", "recon_no", "ListValue"))), TagSupplement = matrix(c("number", as.character(nrow(HypothesisOneMRP$Matrix_1$Matrix))), nrow = 1, ncol = 2, dimnames = list(c(), c("Measure", "Value"))))#
HypothesisTwoXML$SourceTree$Taxa <- list(TagContents = matrix(as.vector(ReconTable[match(rownames(HypothesisTwoMRP$Matrix_1$Matrix), ReconTable[, "OTUName"]), c("ReconName", "ReconNumber", "OTUName")]), ncol = 3, byrow = FALSE, dimnames = list(c(), c("recon_name", "recon_no", "ListValue"))), TagSupplement = matrix(c("number", as.character(nrow(HypothesisTwoMRP$Matrix_1$Matrix))), nrow = 1, ncol = 2, dimnames = list(c(), c("Measure", "Value"))))#
HypothesisThreeXML$SourceTree$Taxa <- list(TagContents = matrix(as.vector(ReconTable[match(rownames(HypothesisThreeMRP$Matrix_1$Matrix), ReconTable[, "OTUName"]), c("ReconName", "ReconNumber", "OTUName")]), ncol = 3, byrow = FALSE, dimnames = list(c(), c("recon_name", "recon_no", "ListValue"))), TagSupplement = matrix(c("number", as.character(nrow(HypothesisThreeMRP$Matrix_1$Matrix))), nrow = 1, ncol = 2, dimnames = list(c(), c("Measure", "Value"))))#
HypothesisFourXML$SourceTree$Taxa <- list(TagContents = matrix(as.vector(ReconTable[match(rownames(HypothesisFourMRP$Matrix_1$Matrix), ReconTable[, "OTUName"]), c("ReconName", "ReconNumber", "OTUName")]), ncol = 3, byrow = FALSE, dimnames = list(c(), c("recon_name", "recon_no", "ListValue"))), TagSupplement = matrix(c("number", as.character(nrow(HypothesisFourMRP$Matrix_1$Matrix))), nrow = 1, ncol = 2, dimnames = list(c(), c("Measure", "Value"))))#
HypothesisFiveXML$SourceTree$Taxa <- list(TagContents = matrix(as.vector(ReconTable[match(rownames(HypothesisFiveMRP$Matrix_1$Matrix), ReconTable[, "OTUName"]), c("ReconName", "ReconNumber", "OTUName")]), ncol = 3, byrow = FALSE, dimnames = list(c(), c("recon_name", "recon_no", "ListValue"))), TagSupplement = matrix(c("number", as.character(nrow(HypothesisFiveMRP$Matrix_1$Matrix))), nrow = 1, ncol = 2, dimnames = list(c(), c("Measure", "Value"))))#
HypothesisSixXML$SourceTree$Taxa <- list(TagContents = matrix(as.vector(ReconTable[match(rownames(HypothesisSixMRP$Matrix_1$Matrix), ReconTable[, "OTUName"]), c("ReconName", "ReconNumber", "OTUName")]), ncol = 3, byrow = FALSE, dimnames = list(c(), c("recon_name", "recon_no", "ListValue"))), TagSupplement = matrix(c("number", as.character(nrow(HypothesisSixMRP$Matrix_1$Matrix))), nrow = 1, ncol = 2, dimnames = list(c(), c("Measure", "Value"))))#
#
# Update character number in XMLs:#
HypothesisOneXML$SourceTree$Characters$Other$TagSupplement[, "Value"] <- as.character(ncol(HypothesisOneMRP$Matrix_1$Matrix))#
HypothesisTwoXML$SourceTree$Characters$Other$TagSupplement[, "Value"] <- as.character(ncol(HypothesisTwoMRP$Matrix_1$Matrix))#
HypothesisThreeXML$SourceTree$Characters$Other$TagSupplement[, "Value"] <- as.character(ncol(HypothesisThreeMRP$Matrix_1$Matrix))#
HypothesisFourXML$SourceTree$Characters$Other$TagSupplement[, "Value"] <- as.character(ncol(HypothesisFourMRP$Matrix_1$Matrix))#
HypothesisFiveXML$SourceTree$Characters$Other$TagSupplement[, "Value"] <- as.character(ncol(HypothesisFiveMRP$Matrix_1$Matrix))#
HypothesisSixXML$SourceTree$Characters$Other$TagSupplement[, "Value"] <- as.character(ncol(HypothesisSixMRP$Matrix_1$Matrix))#
#
# Update file names in XMLs:#
HypothesisOneXML$SourceTree$Filename <- HypothesisTwoXML$SourceTree$Filename <- HypothesisThreeXML$SourceTree$Filename <- HypothesisFourXML$SourceTree$Filename <- HypothesisFiveXML$SourceTree$Filename <- HypothesisSixXML$SourceTree$Filename <- list(TagContents = paste("Constraint_", strsplit(as.character(Sys.Date()), split = "-")[[1]][1], "a", sep = ""), TagSupplements = list(NULL))#
#
# Create copies of XML files to each hypothesis folder:#
x <- lapply(as.list(InclusiveDataList), function(x) file.copy(from = paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/XML/", x, ".xml", sep = ""), to =  paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/XML/", x, ".xml", sep = "")))#
x <- lapply(as.list(InclusiveDataList), function(x) file.copy(from = paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/XML/", x, ".xml", sep = ""), to =  paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/XML/", x, ".xml", sep = "")))#
x <- lapply(as.list(InclusiveDataList), function(x) file.copy(from = paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/XML/", x, ".xml", sep = ""), to =  paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/XML/", x, ".xml", sep = "")))#
x <- lapply(as.list(InclusiveDataList), function(x) file.copy(from = paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/XML/", x, ".xml", sep = ""), to =  paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/XML/", x, ".xml", sep = "")))#
x <- lapply(as.list(InclusiveDataList), function(x) file.copy(from = paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/XML/", x, ".xml", sep = ""), to =  paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/XML/", x, ".xml", sep = "")))#
x <- lapply(as.list(InclusiveDataList), function(x) file.copy(from = paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/XML/", x, ".xml", sep = ""), to =  paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/XML/", x, ".xml", sep = "")))#
#
# Create copies of MRP files to each hypothesis folder:#
x <- lapply(as.list(InclusiveDataList), function(x) file.copy(from = paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/MRP/", x, "mrp.nex", sep = ""), to = paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MRP/", x, "mrp.nex", sep = "")))#
x <- lapply(as.list(InclusiveDataList), function(x) file.copy(from = paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/MRP/", x, "mrp.nex", sep = ""), to = paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/MRP/", x, "mrp.nex", sep = "")))#
x <- lapply(as.list(InclusiveDataList), function(x) file.copy(from = paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/MRP/", x, "mrp.nex", sep = ""), to = paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/MRP/", x, "mrp.nex", sep = "")))#
x <- lapply(as.list(InclusiveDataList), function(x) file.copy(from = paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/MRP/", x, "mrp.nex", sep = ""), to = paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/MRP/", x, "mrp.nex", sep = "")))#
x <- lapply(as.list(InclusiveDataList), function(x) file.copy(from = paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/MRP/", x, "mrp.nex", sep = ""), to = paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/MRP/", x, "mrp.nex", sep = "")))#
x <- lapply(as.list(InclusiveDataList), function(x) file.copy(from = paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/MRP/", x, "mrp.nex", sep = ""), to = paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/MRP/", x, "mrp.nex", sep = "")))#
#
# Write out constraint MRPs:#
Claddis::WriteMorphNexus(HypothesisOneMRP, paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MRP/", paste("Constraint_", strsplit(as.character(Sys.Date()), split = "-")[[1]][1], "a", sep = ""), "mrp.nex", sep = ""))#
Claddis::WriteMorphNexus(HypothesisTwoMRP, paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/MRP/", paste("Constraint_", strsplit(as.character(Sys.Date()), split = "-")[[1]][1], "a", sep = ""), "mrp.nex", sep = ""))#
Claddis::WriteMorphNexus(HypothesisThreeMRP, paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/MRP/", paste("Constraint_", strsplit(as.character(Sys.Date()), split = "-")[[1]][1], "a", sep = ""), "mrp.nex", sep = ""))#
Claddis::WriteMorphNexus(HypothesisFourMRP, paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/MRP/", paste("Constraint_", strsplit(as.character(Sys.Date()), split = "-")[[1]][1], "a", sep = ""), "mrp.nex", sep = ""))#
Claddis::WriteMorphNexus(HypothesisFiveMRP, paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/MRP/", paste("Constraint_", strsplit(as.character(Sys.Date()), split = "-")[[1]][1], "a", sep = ""), "mrp.nex", sep = ""))#
Claddis::WriteMorphNexus(HypothesisSixMRP, paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/MRP/", paste("Constraint_", strsplit(as.character(Sys.Date()), split = "-")[[1]][1], "a", sep = ""), "mrp.nex", sep = ""))#
#
# Write out XML files for each hypthesis:#
metatree::WriteMetatreeXML(HypothesisOneXML, paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/XML/", paste("Constraint_", strsplit(as.character(Sys.Date()), split = "-")[[1]][1], "a", sep = ""), ".xml", sep = ""))#
metatree::WriteMetatreeXML(HypothesisTwoXML, paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/XML/", paste("Constraint_", strsplit(as.character(Sys.Date()), split = "-")[[1]][1], "a", sep = ""), ".xml", sep = ""))#
metatree::WriteMetatreeXML(HypothesisThreeXML, paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/XML/", paste("Constraint_", strsplit(as.character(Sys.Date()), split = "-")[[1]][1], "a", sep = ""), ".xml", sep = ""))#
metatree::WriteMetatreeXML(HypothesisFourXML, paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/XML/", paste("Constraint_", strsplit(as.character(Sys.Date()), split = "-")[[1]][1], "a", sep = ""), ".xml", sep = ""))#
metatree::WriteMetatreeXML(HypothesisFiveXML, paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/XML/", paste("Constraint_", strsplit(as.character(Sys.Date()), split = "-")[[1]][1], "a", sep = ""), ".xml", sep = ""))#
metatree::WriteMetatreeXML(HypothesisSixXML, paste("~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/XML/", paste("Constraint_", strsplit(as.character(Sys.Date()), split = "-")[[1]][1], "a", sep = ""), ".xml", sep = ""))#
#
# Build meattree datasets for each hypothesis:#
HypothesisOne <- metatree::Metatree(MRPDirectory = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MRP", XMLDirectory = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/XML", TargetClade = "Tetrapoda", InclusiveDataList = c(), ExclusiveDataList = ExclusiveDataList, MissingSpecies = "exclude", RelativeWeights = c(0, 100, 10, 1), WeightCombination = "sum", ReportContradictionsToScreen = FALSE, BackboneConstraint = paste("Constraint_", strsplit(as.character(Sys.Date()), split = "-")[[1]][1], "a", sep = ""))#
HypothesisTwo <- metatree::Metatree(MRPDirectory = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/MRP", XMLDirectory = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/XML", TargetClade = "Tetrapoda", InclusiveDataList = c(), ExclusiveDataList = ExclusiveDataList, MissingSpecies = "exclude", RelativeWeights = c(0, 100, 10, 1), WeightCombination = "sum", ReportContradictionsToScreen = FALSE, BackboneConstraint = paste("Constraint_", strsplit(as.character(Sys.Date()), split = "-")[[1]][1], "a", sep = ""))#
HypothesisThree <- metatree::Metatree(MRPDirectory = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/MRP", XMLDirectory = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/XML", TargetClade = "Tetrapoda", InclusiveDataList = c(), ExclusiveDataList = ExclusiveDataList, MissingSpecies = "exclude", RelativeWeights = c(0, 100, 10, 1), WeightCombination = "sum", ReportContradictionsToScreen = FALSE, BackboneConstraint = paste("Constraint_", strsplit(as.character(Sys.Date()), split = "-")[[1]][1], "a", sep = ""))#
HypothesisFour <- metatree::Metatree(MRPDirectory = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/MRP", XMLDirectory = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/XML", TargetClade = "Tetrapoda", InclusiveDataList = c(), ExclusiveDataList = ExclusiveDataList, MissingSpecies = "exclude", RelativeWeights = c(0, 100, 10, 1), WeightCombination = "sum", ReportContradictionsToScreen = FALSE, BackboneConstraint = paste("Constraint_", strsplit(as.character(Sys.Date()), split = "-")[[1]][1], "a", sep = ""))#
HypothesisFive <- metatree::Metatree(MRPDirectory = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/MRP", XMLDirectory = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/XML", TargetClade = "Tetrapoda", InclusiveDataList = c(), ExclusiveDataList = ExclusiveDataList, MissingSpecies = "exclude", RelativeWeights = c(0, 100, 10, 1), WeightCombination = "sum", ReportContradictionsToScreen = FALSE, BackboneConstraint = paste("Constraint_", strsplit(as.character(Sys.Date()), split = "-")[[1]][1], "a", sep = ""))#
HypothesisSix <- metatree::Metatree(MRPDirectory = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/MRP", XMLDirectory = "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/XML", TargetClade = "Tetrapoda", InclusiveDataList = c(), ExclusiveDataList = ExclusiveDataList, MissingSpecies = "exclude", RelativeWeights = c(0, 100, 10, 1), WeightCombination = "sum", ReportContradictionsToScreen = FALSE, BackboneConstraint = paste("Constraint_", strsplit(as.character(Sys.Date()), split = "-")[[1]][1], "a", sep = ""))#
#
# Write out full matrix as NEXUS:#
Claddis::WriteMorphNexus(HypothesisOne$FullMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MetatreeFiles/TetrapodaFull.nex")#
Claddis::WriteMorphNexus(HypothesisTwo$FullMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/MetatreeFiles/TetrapodaFull.nex")#
Claddis::WriteMorphNexus(HypothesisThree$FullMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/MetatreeFiles/TetrapodaFull.nex")#
Claddis::WriteMorphNexus(HypothesisFour$FullMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/MetatreeFiles/TetrapodaFull.nex")#
Claddis::WriteMorphNexus(HypothesisFive$FullMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/MetatreeFiles/TetrapodaFull.nex")#
Claddis::WriteMorphNexus(HypothesisSix$FullMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/MetatreeFiles/TetrapodaFull.nex")#
#
# Write out full matrix as TNT:#
Claddis::WriteMorphTNT(HypothesisOne$FullMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MetatreeFiles/TetrapodaFull.tnt")#
Claddis::WriteMorphTNT(HypothesisTwo$FullMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/MetatreeFiles/TetrapodaFull.tnt")#
Claddis::WriteMorphTNT(HypothesisThree$FullMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/MetatreeFiles/TetrapodaFull.tnt")#
Claddis::WriteMorphTNT(HypothesisFour$FullMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/MetatreeFiles/TetrapodaFull.tnt")#
Claddis::WriteMorphTNT(HypothesisFive$FullMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/MetatreeFiles/TetrapodaFull.tnt")#
Claddis::WriteMorphTNT(HypothesisSix$FullMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/MetatreeFiles/TetrapodaFull.tnt")#
#
# Write out STR matrix as NEXUS:#
Claddis::WriteMorphNexus(HypothesisOne$STRMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MetatreeFiles/TetrapodaSTR.nex")#
Claddis::WriteMorphNexus(HypothesisTwo$STRMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/MetatreeFiles/TetrapodaSTR.nex")#
Claddis::WriteMorphNexus(HypothesisThree$STRMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/MetatreeFiles/TetrapodaSTR.nex")#
Claddis::WriteMorphNexus(HypothesisFour$STRMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/MetatreeFiles/TetrapodaSTR.nex")#
Claddis::WriteMorphNexus(HypothesisFive$STRMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/MetatreeFiles/TetrapodaSTR.nex")#
Claddis::WriteMorphNexus(HypothesisSix$STRMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/MetatreeFiles/TetrapodaSTR.nex")#
#
# Write out STR matrix as TNT:#
Claddis::WriteMorphTNT(HypothesisOne$STRMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MetatreeFiles/TetrapodaSTR.tnt")#
Claddis::WriteMorphTNT(HypothesisTwo$STRMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/MetatreeFiles/TetrapodaSTR.tnt")#
Claddis::WriteMorphTNT(HypothesisThree$STRMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/MetatreeFiles/TetrapodaSTR.tnt")#
Claddis::WriteMorphTNT(HypothesisFour$STRMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/MetatreeFiles/TetrapodaSTR.tnt")#
Claddis::WriteMorphTNT(HypothesisFive$STRMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/MetatreeFiles/TetrapodaSTR.tnt")#
Claddis::WriteMorphTNT(HypothesisSix$STRMRPMatrix, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/MetatreeFiles/TetrapodaSTR.tnt")#
#
# Write out taxonomy trees:#
ape::write.tree(HypothesisOne$TaxonomyTree, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MetatreeFiles/Taxonomy.tre")#
ape::write.tree(HypothesisTwo$TaxonomyTree, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/MetatreeFiles/Taxonomy.tre")#
ape::write.tree(HypothesisThree$TaxonomyTree, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/MetatreeFiles/Taxonomy.tre")#
ape::write.tree(HypothesisFour$TaxonomyTree, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/MetatreeFiles/Taxonomy.tre")#
ape::write.tree(HypothesisFive$TaxonomyTree, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/MetatreeFiles/Taxonomy.tre")#
ape::write.tree(HypothesisSix$TaxonomyTree, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/MetatreeFiles/Taxonomy.tre")#
#
# Write out STR data:#
write.table(HypothesisOne$SafelyRemovedTaxa, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MetatreeFiles/STR.txt", row.names = FALSE)#
write.table(HypothesisTwo$SafelyRemovedTaxa, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/MetatreeFiles/STR.txt", row.names = FALSE)#
write.table(HypothesisThree$SafelyRemovedTaxa, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/MetatreeFiles/STR.txt", row.names = FALSE)#
write.table(HypothesisFour$SafelyRemovedTaxa, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/MetatreeFiles/STR.txt", row.names = FALSE)#
write.table(HypothesisFive$SafelyRemovedTaxa, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/MetatreeFiles/STR.txt", row.names = FALSE)#
write.table(HypothesisSix$SafelyRemovedTaxa, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/MetatreeFiles/STR.txt", row.names = FALSE)#
#
# Write out removed data sets:#
write(HypothesisOne$RemovedSourceData, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MetatreeFiles/RemovedSourceData.txt")#
write(HypothesisTwo$RemovedSourceData, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/MetatreeFiles/RemovedSourceData.txt")#
write(HypothesisThree$RemovedSourceData, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/MetatreeFiles/RemovedSourceData.txt")#
write(HypothesisFour$RemovedSourceData, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/MetatreeFiles/RemovedSourceData.txt")#
write(HypothesisFive$RemovedSourceData, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/MetatreeFiles/RemovedSourceData.txt")#
write(HypothesisSix$RemovedSourceData, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/MetatreeFiles/RemovedSourceData.txt")#
#
# Write out veil years:#
write(HypothesisOne$CurrentVeilYear, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisOne/MetatreeFiles/VeilYear.txt")#
write(HypothesisTwo$CurrentVeilYear, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisTwo/MetatreeFiles/VeilYear.txt")#
write(HypothesisThree$CurrentVeilYear, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisThree/MetatreeFiles/VeilYear.txt")#
write(HypothesisFour$CurrentVeilYear, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFour/MetatreeFiles/VeilYear.txt")#
write(HypothesisFive$CurrentVeilYear, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisFive/MetatreeFiles/VeilYear.txt")#
write(HypothesisSix$CurrentVeilYear, "~/Documents/Publications/in prep/Temnospondyl Supertree 2 - Dan/Metatree/HypothesisSix/MetatreeFiles/VeilYear.txt")#
#
# Write out STR matrix as TNT:#
Claddis::WriteMorphTNT(HypothesisOne$STRMRPMatrix, "~/HypothesisOneSTR.tnt", add.analysis.block = FALSE)#
Claddis::WriteMorphTNT(HypothesisTwo$STRMRPMatrix, "~/HypothesisTwoSTR.tnt", add.analysis.block = FALSE)#
Claddis::WriteMorphTNT(HypothesisThree$STRMRPMatrix, "~/HypothesisThreeSTR.tnt", add.analysis.block = FALSE)#
Claddis::WriteMorphTNT(HypothesisFour$STRMRPMatrix, "~/HypothesisFourSTR.tnt", add.analysis.block = FALSE)#
Claddis::WriteMorphTNT(HypothesisFive$STRMRPMatrix, "~/HypothesisFiveSTR.tnt", add.analysis.block = FALSE)#
Claddis::WriteMorphTNT(HypothesisSix$STRMRPMatrix, "~/HypothesisSixSTR.tnt", add.analysis.block = FALSE)#
#
# Read in raw text of TNT files:#
HypothesisOneSTR <- readLines("~/HypothesisOneSTR.tnt")#
HypothesisTwoSTR <- readLines("~/HypothesisTwoSTR.tnt")#
HypothesisThreeSTR <- readLines("~/HypothesisThreeSTR.tnt")#
HypothesisFourSTR <- readLines("~/HypothesisFourSTR.tnt")#
HypothesisFiveSTR <- readLines("~/HypothesisFiveSTR.tnt")#
HypothesisSixSTR <- readLines("~/HypothesisSixSTR.tnt")#
#
# Add analysis block to TNT text:#
HypothesisOneSTR <- gsub("proc/;", "rseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch1.tre;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch1.tre +;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch1.tre +;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch1.tre +;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch1.tre +;\nsave;\ntsave /;\nhold 1000;\nshortread scratch1.tre;\nbbreak=tbr;\nexport -HypothesisOneSTRMPTs.nex;\nproc/;", HypothesisOneSTR)#
HypothesisTwoSTR <- gsub("proc/;", "rseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch2.tre;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch2.tre +;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch2.tre +;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch2.tre +;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch2.tre +;\nsave;\ntsave /;\nhold 1000;\nshortread scratch2.tre;\nbbreak=tbr;\nexport -HypothesisTwoSTRMPTs.nex;\nproc/;", HypothesisTwoSTR)#
HypothesisThreeSTR <- gsub("proc/;", "rseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch3.tre;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch3.tre +;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch3.tre +;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch3.tre +;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch3.tre +;\nsave;\ntsave /;\nhold 1000;\nshortread scratch3.tre;\nbbreak=tbr;\nexport -HypothesisThreeSTRMPTs.nex;\nproc/;", HypothesisThreeSTR)#
HypothesisFourSTR <- gsub("proc/;", "rseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch4.tre;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch4.tre +;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch4.tre +;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch4.tre +;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch4.tre +;\nsave;\ntsave /;\nhold 1000;\nshortread scratch4.tre;\nbbreak=tbr;\nexport -HypothesisFourSTRMPTs.nex;\nproc/;", HypothesisFourSTR)#
HypothesisFiveSTR <- gsub("proc/;", "rseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch5.tre;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch5.tre +;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch5.tre +;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch5.tre +;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch5.tre +;\nsave;\ntsave /;\nhold 1000;\nshortread scratch5.tre;\nbbreak=tbr;\nexport -HypothesisFiveSTRMPTs.nex;\nproc/;", HypothesisFiveSTR)#
HypothesisSixSTR <- gsub("proc/;", "rseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch6.tre;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch6.tre +;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch6.tre +;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch6.tre +;\nsave;\ntsave /;\nrseed*;\nhold 10;\nxmult=rss fuse 10 drift 10 ratchet 10;\ntsave scratch6.tre +;\nsave;\ntsave /;\nhold 1000;\nshortread scratch6.tre;\nbbreak=tbr;\nexport -HypothesisSixSTRMPTs.nex;\nproc/;", HypothesisSixSTR)#
#
# Write TNT back out to file:#
write(HypothesisOneSTR, "~/HypothesisOneSTR.tnt")#
write(HypothesisTwoSTR, "~/HypothesisTwoSTR.tnt")#
write(HypothesisThreeSTR, "~/HypothesisThreeSTR.tnt")#
write(HypothesisFourSTR, "~/HypothesisFourSTR.tnt")#
write(HypothesisFiveSTR, "~/HypothesisFiveSTR.tnt")#
write(HypothesisSixSTR, "~/HypothesisSixSTR.tnt")
